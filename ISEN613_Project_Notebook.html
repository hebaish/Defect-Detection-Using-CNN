<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>ISEN613_Project_Notebook</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1.-Loading-Necessary-Libraries">1. Loading Necessary Libraries<a class="anchor-link" href="#1.-Loading-Necessary-Libraries">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Mount Google Drive</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
<span class="o">!</span>ls <span class="s2">&quot;/content/drive/Shareddrives/ISEN 613 Final Project/ISEN613-Engineering-Data-Analysis-CourseProject-main&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/drive
&#39;CNN code and input&#39;
 CNN_Implementation_Code.ipynb
 Ground_Truth_Sample1
 Ground_Truth_Sample4
&#39;~$Ground Truth - Voxel Tensor Index_ Sample1.xlsx&#39;
&#39;Ground Truth - Voxel Tensor Index_ Sample1.xlsx&#39;
&#39;*.mat&#39;
 README.md
 Spectrogram_Tensors_Sample1.mat
 Spectrogram_Tensors_Sample4.mat
 test.ipynb
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># cnn model and accuracy - porosity tensor dataset</span>
<span class="c1"># Import packages / libraries</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">dirname</span><span class="p">,</span> <span class="n">join</span> <span class="k">as</span> <span class="n">pjoin</span>
<span class="kn">import</span> <span class="nn">scipy.io</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;3&#39;</span>

<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">makedirs</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">listdir</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">seed</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>

<span class="c1"># baseline model for the classification dataset</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>

<span class="o">!</span>pip install opencv-python
<span class="o">!</span>pip install lime 
<span class="o">!</span>pip install lazypredict

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">skimage.color</span> <span class="kn">import</span> <span class="n">gray2rgb</span>
<span class="kn">from</span> <span class="nn">skimage.color</span> <span class="kn">import</span> <span class="n">rgb2gray</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.applications</span> <span class="kn">import</span> <span class="n">inception_v3</span> <span class="k">as</span> <span class="n">inc_net</span>
<span class="kn">from</span> <span class="nn">lime</span> <span class="kn">import</span> <span class="n">lime_image</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">skimage.segmentation</span> <span class="kn">import</span> <span class="n">mark_boundaries</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)
Requirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.6)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting lime
  Downloading lime-0.2.0.1.tar.gz (275 kB)
     || 275 kB 5.6 MB/s 
Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from lime) (3.2.2)
Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lime) (1.21.6)
Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from lime) (1.7.3)
Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from lime) (4.64.1)
Requirement already satisfied: scikit-learn&gt;=0.18 in /usr/local/lib/python3.8/dist-packages (from lime) (1.0.2)
Requirement already satisfied: scikit-image&gt;=0.12 in /usr/local/lib/python3.8/dist-packages (from lime) (0.18.3)
Requirement already satisfied: imageio&gt;=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image&gt;=0.12-&gt;lime) (2.9.0)
Requirement already satisfied: pillow!=7.1.0,!=7.1.1,&gt;=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image&gt;=0.12-&gt;lime) (7.1.2)
Requirement already satisfied: networkx&gt;=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image&gt;=0.12-&gt;lime) (2.8.8)
Requirement already satisfied: tifffile&gt;=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image&gt;=0.12-&gt;lime) (2022.10.10)
Requirement already satisfied: PyWavelets&gt;=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image&gt;=0.12-&gt;lime) (1.4.1)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;lime) (0.11.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;lime) (2.8.2)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;lime) (1.4.4)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib-&gt;lime) (3.0.9)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;lime) (1.15.0)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn&gt;=0.18-&gt;lime) (1.2.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn&gt;=0.18-&gt;lime) (3.1.0)
Building wheels for collected packages: lime
  Building wheel for lime (setup.py) ... done
  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=2b553737f36af1fb869b644fb25d6d9d7e05a56d2375011c87491dbd1df1f884
  Stored in directory: /root/.cache/pip/wheels/e6/a6/20/cc1e293fcdb67ede666fed293cb895395e7ecceb4467779546
Successfully built lime
Installing collected packages: lime
Successfully installed lime-0.2.0.1
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Collecting lazypredict
  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from lazypredict) (1.0.2)
Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from lazypredict) (7.1.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from lazypredict) (1.2.0)
Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from lazypredict) (1.3.5)
Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from lazypredict) (4.64.1)
Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (from lazypredict) (0.90)
Requirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (from lazypredict) (2.2.3)
Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lightgbm-&gt;lazypredict) (1.21.6)
Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from lightgbm-&gt;lazypredict) (1.7.3)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas-&gt;lazypredict) (2022.6)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas-&gt;lazypredict) (2.8.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;lazypredict) (1.15.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn-&gt;lazypredict) (3.1.0)
Installing collected packages: lazypredict
Successfully installed lazypredict-0.2.12
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">## LIME ANALYSIS</span>
<span class="c1">## Import required libraries / packages</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">scipy.io</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">plot_model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="c1"># import tensorflow_addons as tfa</span>
<span class="kn">import</span> <span class="nn">pydot</span>
<span class="kn">import</span> <span class="nn">pydotplus</span>
<span class="kn">import</span> <span class="nn">graphviz</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">load_img</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">img_to_array</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">from</span> <span class="nn">lime.utils.generic_utils</span> <span class="kn">import</span> <span class="n">has_arg</span>
<span class="kn">from</span> <span class="nn">skimage.segmentation</span> <span class="kn">import</span> <span class="n">felzenszwalb</span><span class="p">,</span> <span class="n">slic</span><span class="p">,</span> <span class="n">quickshift</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">sklearn.preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">skimage.color</span> <span class="kn">import</span> <span class="n">gray2rgb</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="nn">scipy.ndimage</span> <span class="k">as</span> <span class="nn">ndi</span>
<span class="kn">from</span> <span class="nn">skimage.segmentation._quickshift_cy</span> <span class="kn">import</span> <span class="n">_quickshift_cython</span>

<span class="kn">from</span> <span class="nn">lime</span> <span class="kn">import</span> <span class="n">lime_base</span>
<span class="kn">from</span> <span class="nn">lime.wrappers.scikit_image</span> <span class="kn">import</span> <span class="n">SegmentationAlgorithm</span>

<span class="kn">import</span> <span class="nn">skimage</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">colors</span>
<span class="kn">from</span> <span class="nn">skimage.segmentation</span> <span class="kn">import</span> <span class="n">mark_boundaries</span><span class="p">,</span> <span class="n">find_boundaries</span>
<span class="kn">from</span> <span class="nn">skimage.morphology</span> <span class="kn">import</span> <span class="n">dilation</span><span class="p">,</span><span class="n">square</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="2.-Input-Processing">2. Input Processing<a class="anchor-link" href="#2.-Input-Processing">&#182;</a></h1><p>In this section, inputs are loaded into tensor-type variables and converted to numpy-type.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.core.fromnumeric</span> <span class="kn">import</span> <span class="n">shape</span>
<span class="c1"># organize dataset into a numpy structure</span>
<span class="c1"># Extract input spectrogram data from .mat files </span>
<span class="c1"># Loading the ground truth xlsx file</span>
<span class="n">gt</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;/content/drive/Shareddrives/ISEN 613 Final Project/ISEN613-Engineering-Data-Analysis-CourseProject-main/CNN code and input/Ground Truth - Voxel Tensor Index_ Sample1.xlsx&quot;</span><span class="p">)</span>
<span class="n">perc_area</span> <span class="o">=</span> <span class="n">gt</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">90</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">]]</span>
<span class="n">pore_count</span> <span class="o">=</span> <span class="n">gt</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">90</span><span class="p">,[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]]</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">formatter</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;float&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">{0:0.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">)})</span>
<span class="c1"># sets print options to 5 decimal places</span>

<span class="n">TENSOR_INPUT_DATA_COMBINED</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">72</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">129</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">TENSOR_INPUT_DATA_PRINTING</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">72</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">129</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">TENSOR_INPUT_DATA_MILLING</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">72</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">129</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
    
    <span class="c1"># 72 - Total number of data points for binary classification</span>
    <span class="c1"># 6 - Channels (pertaining to each spectrogram)</span>
    <span class="c1"># 129  - Freuqency bands for each spectrogram</span>
    <span class="c1"># 15 - Time steps</span>

<span class="n">voxel_number</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># assign directory</span>
<span class="c1"># directory = &#39;files&#39;</span>
<span class="c1"># iterate over files in that directory</span>
<span class="c1"># for filename in os.listdir(directory):</span>


<span class="n">directory</span> <span class="o">=</span> <span class="p">(</span><span class="sa">r</span><span class="s2">&quot;/content/drive/Shareddrives/ISEN 613 Final Project/ISEN613-Engineering-Data-Analysis-CourseProject-main/CNN code and input/Tensor_data_72_voxels_sample1&quot;</span><span class="p">)</span>
<span class="c1"># Change this directory location to your folder that contains the 72 .mat files from Tensor_data_72_voxels.zip corresponding to Sample 1.</span>
<span class="c1"># When working with Sample 4 (Tensor_data_90_voxels_sample4.zip), extract the 90 files in a folder, and update the directory. In addition, </span>
<span class="c1"># update the dimensions in the below for loop (and in other places as required) as each tensor in Sample 4 is of dimension 129x6x4, </span>
<span class="c1"># ie, 129 frequency bands, 6 time steps, 4 spectrograms pertaining to only printing cycle. </span>

<span class="n">voxel_perc_area</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">voxel_pore_count</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">class_comb_area</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">72</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">class_comb_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">72</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">reg_comb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">72</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>

<span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">directory</span><span class="p">):</span>
    <span class="c1"># print(filename)</span>
    <span class="n">mat_fname</span> <span class="o">=</span> <span class="n">pjoin</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="n">Tensor_data_voxel</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="n">mat_fname</span><span class="p">)</span>

    <span class="n">data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Tensor_data_voxel</span><span class="o">.</span> <span class="n">items</span><span class="p">())</span>
    <span class="n">tensor_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>

    <span class="c1"># The spectrogram data is captured in a list from one of the elements of tensor_array</span>
    <span class="c1"># Shape of tensor_array is (4,2) and all spectrogram data (129x15x6) is stored in tensor_array[3][1]</span>

    <span class="n">spec_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensor_array</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
    
    <span class="c1"># Extracting the desired output to build the different datasets</span>
    <span class="n">voxel_name</span> <span class="o">=</span> <span class="n">tensor_array</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">voxel_ind</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\d+&#39;</span><span class="p">,</span> <span class="n">voxel_name</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">voxel_perc_area</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">perc_area</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">perc_area</span><span class="p">[</span><span class="s1">&#39;Tensor_voxel _index&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">voxel_ind</span><span class="p">,</span> <span class="s1">&#39;%Area Porosity&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">voxel_pore_count</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pore_count</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">perc_area</span><span class="p">[</span><span class="s1">&#39;Tensor_voxel _index&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">voxel_ind</span><span class="p">,</span> <span class="s1">&#39;Pore Count&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">spec_list</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">15</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
                <span class="n">TENSOR_INPUT_DATA_COMBINED</span><span class="p">[</span><span class="n">voxel_number</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">spec_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>
                    
    <span class="n">TENSOR_INPUT_DATA_PRINTING</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_COMBINED</span><span class="p">[:,(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">),:,:]</span>
    <span class="n">TENSOR_INPUT_DATA_MILLING</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_COMBINED</span><span class="p">[:,(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">),:,:]</span>                

    <span class="n">voxel_number</span> <span class="o">=</span> <span class="n">voxel_number</span> <span class="o">+</span> <span class="mi">1</span>

<span class="c1"># for i in range(72):</span>
<span class="c1">#   class_comb_area[i][0] = tensor_np[i]</span>
<span class="c1">#   class_comb_count[i][0] = tensor_np[i]</span>
<span class="c1">#   reg_comb[i][0] = tensor_np[i]</span>

<span class="c1">#   class_comb_area[i][1] = voxel_perc_area[i]</span>
<span class="c1">#   class_comb_count[i][1] = voxel_pore_count[i]</span>
<span class="c1">#   reg_comb[i][1] = voxel_perc_area[i]</span>


<span class="n">y_target_area</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">voxel_perc_area</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">72</span><span class="p">)])</span>
<span class="n">y_target_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">voxel_pore_count</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">72</span><span class="p">)])</span>

<span class="c1"># y_target[4:10] = 1</span>
<span class="c1"># y_target[13:18] = 1</span>
<span class="c1"># y_target[22:34] = 1</span>
<span class="c1"># y_target[37:41] = 1</span>
<span class="c1"># y_target[43:46] = 1</span>
<span class="c1"># y_target[47] = 1</span>
<span class="c1"># y_target[57] = 1</span>
<span class="c1"># y_target[59] = 1</span>
<span class="c1"># y_target[70] = 1</span>

<span class="n">data_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">72</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data_order</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">print(&quot;---------------------&quot;)</span>
<span class="sd">print(TENSOR_INPUT_DATA_COMBINED.shape)</span>
<span class="sd">print(TENSOR_INPUT_DATA_COMBINED)</span>
<span class="sd">print(TENSOR_INPUT_DATA_PRINTING.shape)</span>
<span class="sd">print(TENSOR_INPUT_DATA_PRINTING)</span>
<span class="sd">print(TENSOR_INPUT_DATA_MILLING.shape)</span>
<span class="sd">print(TENSOR_INPUT_DATA_MILLING)</span>
<span class="sd">print(&quot;---------------------&quot;)</span>
<span class="sd">print(y_target)</span>
<span class="sd">print(&quot;---------------------&quot;)</span>
<span class="sd">data_order = np.arange(72)</span>
<span class="sd">np.random.shuffle(data_order)</span>
<span class="sd">print(data_order)</span>
<span class="sd">&#39;&#39;&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[4]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&#39;\nprint(&#34;---------------------&#34;)\nprint(TENSOR_INPUT_DATA_COMBINED.shape)\nprint(TENSOR_INPUT_DATA_COMBINED)\nprint(TENSOR_INPUT_DATA_PRINTING.shape)\nprint(TENSOR_INPUT_DATA_PRINTING)\nprint(TENSOR_INPUT_DATA_MILLING.shape)\nprint(TENSOR_INPUT_DATA_MILLING)\nprint(&#34;---------------------&#34;)\nprint(y_target)\nprint(&#34;---------------------&#34;)\ndata_order = np.arange(72)\nnp.random.shuffle(data_order)\nprint(data_order)\n&#39;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Saving data as .npy files</span>
<span class="n">NUMPY_INPUT_DATA</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_COMBINED</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">NUMPY_INPUT_DATA_printing</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_PRINTING</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">NUMPY_INPUT_DATA_milling</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_MILLING</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;/content/drive/Shareddrives/ISEN 613 Final Project/ISEN613-Engineering-Data-Analysis-CourseProject-main/CNN code and input/Saved Inputs_Outputs/Comb_Inputs&quot;</span><span class="p">,</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;/content/drive/Shareddrives/ISEN 613 Final Project/ISEN613-Engineering-Data-Analysis-CourseProject-main/CNN code and input/Saved Inputs_Outputs/Print_Inputs&quot;</span><span class="p">,</span> <span class="n">NUMPY_INPUT_DATA_printing</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;/content/drive/Shareddrives/ISEN 613 Final Project/ISEN613-Engineering-Data-Analysis-CourseProject-main/CNN code and input/Saved Inputs_Outputs/Mill_Inputs&quot;</span><span class="p">,</span> <span class="n">NUMPY_INPUT_DATA_milling</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;/content/drive/Shareddrives/ISEN 613 Final Project/ISEN613-Engineering-Data-Analysis-CourseProject-main/CNN code and input/Saved Inputs_Outputs/Target_Area&quot;</span><span class="p">,</span> <span class="n">y_target_area</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;/content/drive/Shareddrives/ISEN 613 Final Project/ISEN613-Engineering-Data-Analysis-CourseProject-main/CNN code and input/Saved Inputs_Outputs/Target_Count&quot;</span><span class="p">,</span> <span class="n">y_target_count</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="3.-Regression">3. Regression<a class="anchor-link" href="#3.-Regression">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.1.-Combined-Data">3.1. Combined Data<a class="anchor-link" href="#3.1.-Combined-Data">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">NUMPY_INPUT_DATA</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_COMBINED</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">X_train_reg</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">],:,:,:]</span>
<span class="n">y_train_reg</span> <span class="o">=</span> <span class="n">y_target_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]]</span>
<span class="n">X_test_reg</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test_reg</span> <span class="o">=</span> <span class="n">y_target_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>
    
<span class="c1"># Define the model architecture</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="c1"># model.add(Conv2D(128, (3, 3), activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;, padding=&#39;same&#39;))</span>
<span class="c1"># model.add(MaxPooling2D((2, 2)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="c1"># Compile the model</span>
<span class="c1">#opt = SGD(lr=0.001, momentum=0.9)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reg</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">,</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_reg</span><span class="p">,</span> <span class="n">y_test_reg</span><span class="p">))</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_reg</span><span class="p">,</span> <span class="n">y_test_reg</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model MSE:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/200
2/2 [==============================] - 3s 2s/step - loss: 3.0709 - mse: 3.0709 - val_loss: 1.7817 - val_mse: 1.7817
Epoch 2/200
2/2 [==============================] - 0s 146ms/step - loss: 2.9411 - mse: 2.9411 - val_loss: 1.7695 - val_mse: 1.7695
Epoch 3/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9277 - mse: 2.9277 - val_loss: 1.7669 - val_mse: 1.7669
Epoch 4/200
2/2 [==============================] - 0s 168ms/step - loss: 2.9252 - mse: 2.9252 - val_loss: 1.7661 - val_mse: 1.7661
Epoch 5/200
2/2 [==============================] - 1s 962ms/step - loss: 2.9241 - mse: 2.9241 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 6/200
2/2 [==============================] - 1s 859ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 7/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 8/200
2/2 [==============================] - 1s 708ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 9/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 10/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 11/200
2/2 [==============================] - 0s 162ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 12/200
2/2 [==============================] - 0s 255ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 13/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 14/200
2/2 [==============================] - 0s 143ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 15/200
2/2 [==============================] - 0s 280ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 16/200
2/2 [==============================] - 0s 148ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 17/200
2/2 [==============================] - 0s 154ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 18/200
2/2 [==============================] - 0s 316ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 19/200
2/2 [==============================] - 0s 155ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 20/200
2/2 [==============================] - 0s 145ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 21/200
2/2 [==============================] - 0s 328ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 22/200
2/2 [==============================] - 1s 707ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 23/200
2/2 [==============================] - 0s 165ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 24/200
2/2 [==============================] - 0s 144ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 25/200
2/2 [==============================] - 0s 348ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 26/200
2/2 [==============================] - 1s 754ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 27/200
2/2 [==============================] - 0s 148ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 28/200
2/2 [==============================] - 0s 155ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 29/200
2/2 [==============================] - 0s 169ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 30/200
2/2 [==============================] - 0s 307ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 31/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 32/200
2/2 [==============================] - 0s 155ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 33/200
2/2 [==============================] - 1s 788ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 34/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 35/200
2/2 [==============================] - 0s 160ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 36/200
2/2 [==============================] - 0s 155ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 37/200
2/2 [==============================] - 0s 260ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 38/200
2/2 [==============================] - 1s 748ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 39/200
2/2 [==============================] - 0s 156ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 40/200
2/2 [==============================] - 0s 145ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 41/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 42/200
2/2 [==============================] - 1s 366ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 43/200
2/2 [==============================] - 0s 144ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 44/200
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 45/200
2/2 [==============================] - 1s 146ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 46/200
2/2 [==============================] - 0s 165ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 47/200
2/2 [==============================] - 0s 213ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 48/200
2/2 [==============================] - 1s 748ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 49/200
2/2 [==============================] - 1s 792ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 50/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 51/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 52/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 53/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 54/200
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 55/200
2/2 [==============================] - 1s 757ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 56/200
2/2 [==============================] - 1s 771ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 57/200
2/2 [==============================] - 0s 155ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 58/200
2/2 [==============================] - 1s 685ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 59/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 60/200
2/2 [==============================] - 0s 143ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 61/200
2/2 [==============================] - 0s 149ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 62/200
2/2 [==============================] - 0s 157ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 63/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 64/200
2/2 [==============================] - 0s 276ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 65/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 66/200
2/2 [==============================] - 0s 144ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 67/200
2/2 [==============================] - 0s 146ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 68/200
2/2 [==============================] - 0s 278ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 69/200
2/2 [==============================] - 0s 156ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 70/200
2/2 [==============================] - 0s 154ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 71/200
2/2 [==============================] - 0s 248ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 72/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 73/200
2/2 [==============================] - 1s 813ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 74/200
2/2 [==============================] - 1s 752ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 75/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 76/200
2/2 [==============================] - 1s 723ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 77/200
2/2 [==============================] - 1s 755ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 78/200
2/2 [==============================] - 0s 154ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 79/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 80/200
2/2 [==============================] - 0s 180ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 81/200
2/2 [==============================] - 0s 273ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 82/200
2/2 [==============================] - 0s 146ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 83/200
2/2 [==============================] - 0s 158ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 84/200
2/2 [==============================] - 0s 171ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 85/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 86/200
2/2 [==============================] - 0s 158ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 87/200
2/2 [==============================] - 0s 246ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 88/200
2/2 [==============================] - 0s 161ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 89/200
2/2 [==============================] - 0s 144ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 90/200
2/2 [==============================] - 1s 923ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 91/200
2/2 [==============================] - 0s 157ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 92/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 93/200
2/2 [==============================] - 0s 164ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 94/200
2/2 [==============================] - 0s 156ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 95/200
2/2 [==============================] - 0s 185ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 96/200
2/2 [==============================] - 0s 165ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 97/200
2/2 [==============================] - 0s 157ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 98/200
2/2 [==============================] - 1s 836ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 99/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 100/200
2/2 [==============================] - 0s 147ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 101/200
2/2 [==============================] - 0s 158ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 102/200
2/2 [==============================] - 1s 752ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 103/200
2/2 [==============================] - 0s 146ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 104/200
2/2 [==============================] - 0s 147ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 105/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 106/200
2/2 [==============================] - 0s 238ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 107/200
2/2 [==============================] - 0s 154ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 108/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 109/200
2/2 [==============================] - 0s 226ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 110/200
2/2 [==============================] - 0s 150ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 111/200
2/2 [==============================] - 0s 155ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 112/200
2/2 [==============================] - 0s 176ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 113/200
2/2 [==============================] - 0s 149ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 114/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 115/200
2/2 [==============================] - 0s 273ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 116/200
2/2 [==============================] - 0s 157ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 117/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 118/200
2/2 [==============================] - 0s 335ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 119/200
2/2 [==============================] - 1s 782ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 120/200
2/2 [==============================] - 0s 155ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 121/200
2/2 [==============================] - 0s 158ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 122/200
2/2 [==============================] - 0s 149ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 123/200
2/2 [==============================] - 1s 818ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 124/200
2/2 [==============================] - 1s 809ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 125/200
2/2 [==============================] - 0s 155ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 126/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 127/200
2/2 [==============================] - 0s 160ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 128/200
2/2 [==============================] - 1s 771ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 129/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 130/200
2/2 [==============================] - 0s 157ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 131/200
2/2 [==============================] - 1s 745ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 132/200
2/2 [==============================] - 0s 157ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 133/200
2/2 [==============================] - 0s 164ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 134/200
2/2 [==============================] - 0s 302ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 135/200
2/2 [==============================] - 0s 154ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 136/200
2/2 [==============================] - 0s 154ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 137/200
2/2 [==============================] - 0s 157ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 138/200
2/2 [==============================] - 1s 833ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 139/200
2/2 [==============================] - 0s 148ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 140/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 141/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 142/200
2/2 [==============================] - 0s 250ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 143/200
2/2 [==============================] - 0s 158ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 144/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 145/200
2/2 [==============================] - 0s 148ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 146/200
2/2 [==============================] - 2s 2s/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 147/200
2/2 [==============================] - 1s 798ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 148/200
2/2 [==============================] - 1s 754ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 149/200
2/2 [==============================] - 0s 141ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 150/200
2/2 [==============================] - 0s 157ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 151/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 152/200
2/2 [==============================] - 0s 309ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 153/200
2/2 [==============================] - 1s 727ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 154/200
2/2 [==============================] - 0s 149ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 155/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 156/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 157/200
2/2 [==============================] - 1s 1s/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 158/200
2/2 [==============================] - 0s 171ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 159/200
2/2 [==============================] - 0s 162ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 160/200
2/2 [==============================] - 1s 163ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 161/200
2/2 [==============================] - 0s 163ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 162/200
2/2 [==============================] - 1s 971ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 163/200
2/2 [==============================] - 0s 333ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 164/200
2/2 [==============================] - 0s 160ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 165/200
2/2 [==============================] - 1s 403ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 166/200
2/2 [==============================] - 0s 148ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 167/200
2/2 [==============================] - 0s 160ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 168/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 169/200
2/2 [==============================] - 1s 181ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 170/200
2/2 [==============================] - 0s 157ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 171/200
2/2 [==============================] - 1s 1s/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 172/200
2/2 [==============================] - 0s 159ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 173/200
2/2 [==============================] - 0s 158ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 174/200
2/2 [==============================] - 0s 161ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 175/200
2/2 [==============================] - 1s 922ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 176/200
2/2 [==============================] - 1s 930ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 177/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 178/200
2/2 [==============================] - 0s 170ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 179/200
2/2 [==============================] - 0s 161ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 180/200
2/2 [==============================] - 0s 357ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 181/200
2/2 [==============================] - 0s 154ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 182/200
2/2 [==============================] - 0s 175ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 183/200
2/2 [==============================] - 0s 353ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 184/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 185/200
2/2 [==============================] - 1s 423ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 186/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 187/200
2/2 [==============================] - 0s 151ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 188/200
2/2 [==============================] - 0s 159ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 189/200
2/2 [==============================] - 0s 329ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 190/200
2/2 [==============================] - 0s 159ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 191/200
2/2 [==============================] - 1s 402ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 192/200
2/2 [==============================] - 0s 149ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 193/200
2/2 [==============================] - 0s 152ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 194/200
2/2 [==============================] - 0s 179ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 195/200
2/2 [==============================] - 0s 274ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 196/200
2/2 [==============================] - 0s 158ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 197/200
2/2 [==============================] - 0s 168ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 198/200
2/2 [==============================] - 0s 167ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 199/200
2/2 [==============================] - 0s 153ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 200/200
2/2 [==============================] - 0s 265ms/step - loss: 2.9233 - mse: 2.9233 - val_loss: 1.7656 - val_mse: 1.7656
Model MSE: 1.7655919790267944
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.2.-Printing">3.2. Printing<a class="anchor-link" href="#3.2.-Printing">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">NUMPY_INPUT_DATA_printing</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_PRINTING</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">X_train_reg_printing</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_printing</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">],:,:,:]</span>
<span class="n">y_train_reg</span> <span class="o">=</span> <span class="n">y_target_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]]</span>
<span class="n">X_test_reg_printing</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_printing</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test_reg</span> <span class="o">=</span> <span class="n">y_target_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>
    
<span class="c1"># Define the model architecture</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="c1"># model.add(Conv2D(128, (3, 3), activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;, padding=&#39;same&#39;))</span>
<span class="c1"># model.add(MaxPooling2D((2, 2)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="c1"># Compile the model</span>
<span class="c1">#opt = SGD(lr=0.001, momentum=0.9)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reg_printing</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">,</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_reg_printing</span><span class="p">,</span> <span class="n">y_test_reg</span><span class="p">))</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_reg_printing</span><span class="p">,</span> <span class="n">y_test_reg</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model MSE:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/500
2/2 [==============================] - 3s 1s/step - loss: 4.1393 - mse: 4.1393 - val_loss: 2.3610 - val_mse: 2.3610
Epoch 2/500
2/2 [==============================] - 0s 192ms/step - loss: 3.7438 - mse: 3.7438 - val_loss: 2.1643 - val_mse: 2.1643
Epoch 3/500
2/2 [==============================] - 1s 1s/step - loss: 3.4323 - mse: 3.4323 - val_loss: 2.0515 - val_mse: 2.0515
Epoch 4/500
2/2 [==============================] - 2s 2s/step - loss: 3.2496 - mse: 3.2496 - val_loss: 1.9399 - val_mse: 1.9399
Epoch 5/500
2/2 [==============================] - 1s 910ms/step - loss: 3.1326 - mse: 3.1326 - val_loss: 1.8664 - val_mse: 1.8664
Epoch 6/500
2/2 [==============================] - 0s 110ms/step - loss: 3.0513 - mse: 3.0513 - val_loss: 1.8215 - val_mse: 1.8215
Epoch 7/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9969 - mse: 2.9969 - val_loss: 1.7973 - val_mse: 1.7973
Epoch 8/500
2/2 [==============================] - 0s 116ms/step - loss: 2.9657 - mse: 2.9657 - val_loss: 1.7840 - val_mse: 1.7840
Epoch 9/500
2/2 [==============================] - 0s 111ms/step - loss: 2.9483 - mse: 2.9483 - val_loss: 1.7763 - val_mse: 1.7763
Epoch 10/500
2/2 [==============================] - 0s 231ms/step - loss: 2.9392 - mse: 2.9392 - val_loss: 1.7720 - val_mse: 1.7720
Epoch 11/500
2/2 [==============================] - 0s 130ms/step - loss: 2.9332 - mse: 2.9332 - val_loss: 1.7696 - val_mse: 1.7696
Epoch 12/500
2/2 [==============================] - 0s 110ms/step - loss: 2.9299 - mse: 2.9299 - val_loss: 1.7682 - val_mse: 1.7682
Epoch 13/500
2/2 [==============================] - 0s 111ms/step - loss: 2.9278 - mse: 2.9278 - val_loss: 1.7674 - val_mse: 1.7674
Epoch 14/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9265 - mse: 2.9265 - val_loss: 1.7669 - val_mse: 1.7669
Epoch 15/500
2/2 [==============================] - 1s 437ms/step - loss: 2.9257 - mse: 2.9257 - val_loss: 1.7666 - val_mse: 1.7666
Epoch 16/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9252 - mse: 2.9252 - val_loss: 1.7663 - val_mse: 1.7663
Epoch 17/500
2/2 [==============================] - 0s 113ms/step - loss: 2.9248 - mse: 2.9248 - val_loss: 1.7662 - val_mse: 1.7662
Epoch 18/500
2/2 [==============================] - 1s 1s/step - loss: 2.9245 - mse: 2.9245 - val_loss: 1.7661 - val_mse: 1.7661
Epoch 19/500
2/2 [==============================] - 1s 895ms/step - loss: 2.9244 - mse: 2.9244 - val_loss: 1.7660 - val_mse: 1.7660
Epoch 20/500
2/2 [==============================] - 0s 108ms/step - loss: 2.9242 - mse: 2.9242 - val_loss: 1.7660 - val_mse: 1.7660
Epoch 21/500
2/2 [==============================] - 0s 130ms/step - loss: 2.9241 - mse: 2.9241 - val_loss: 1.7659 - val_mse: 1.7659
Epoch 22/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9240 - mse: 2.9240 - val_loss: 1.7659 - val_mse: 1.7659
Epoch 23/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9240 - mse: 2.9240 - val_loss: 1.7659 - val_mse: 1.7659
Epoch 24/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9239 - mse: 2.9239 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 25/500
2/2 [==============================] - 0s 333ms/step - loss: 2.9239 - mse: 2.9239 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 26/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9238 - mse: 2.9238 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 27/500
2/2 [==============================] - 0s 111ms/step - loss: 2.9238 - mse: 2.9238 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 28/500
2/2 [==============================] - 0s 400ms/step - loss: 2.9238 - mse: 2.9238 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 29/500
2/2 [==============================] - 0s 121ms/step - loss: 2.9238 - mse: 2.9238 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 30/500
2/2 [==============================] - 0s 130ms/step - loss: 2.9238 - mse: 2.9238 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 31/500
2/2 [==============================] - 0s 369ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 32/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 33/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 34/500
2/2 [==============================] - 0s 107ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 35/500
2/2 [==============================] - 0s 343ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 36/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 37/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 38/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7658 - val_mse: 1.7658
Epoch 39/500
2/2 [==============================] - 0s 321ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 40/500
2/2 [==============================] - 0s 142ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 41/500
2/2 [==============================] - 0s 108ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 42/500
2/2 [==============================] - 0s 138ms/step - loss: 2.9237 - mse: 2.9237 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 43/500
2/2 [==============================] - 1s 865ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 44/500
2/2 [==============================] - 0s 298ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 45/500
2/2 [==============================] - 0s 107ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 46/500
2/2 [==============================] - 1s 1s/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 47/500
2/2 [==============================] - 0s 258ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 48/500
2/2 [==============================] - 0s 133ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 49/500
2/2 [==============================] - 1s 1s/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 50/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 51/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 52/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 53/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 54/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 55/500
2/2 [==============================] - 0s 114ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 56/500
2/2 [==============================] - 0s 111ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 57/500
2/2 [==============================] - 0s 121ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 58/500
2/2 [==============================] - 0s 372ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 59/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 60/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 61/500
2/2 [==============================] - 0s 107ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 62/500
2/2 [==============================] - 1s 875ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 63/500
2/2 [==============================] - 0s 351ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 64/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 65/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 66/500
2/2 [==============================] - 0s 390ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 67/500
2/2 [==============================] - 1s 672ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 68/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 69/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 70/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9236 - mse: 2.9236 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 71/500
2/2 [==============================] - 0s 136ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 72/500
2/2 [==============================] - 0s 333ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 73/500
2/2 [==============================] - 1s 665ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 74/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 75/500
2/2 [==============================] - 0s 116ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 76/500
2/2 [==============================] - 0s 114ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 77/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 78/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 79/500
2/2 [==============================] - 1s 799ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 80/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 81/500
2/2 [==============================] - 0s 113ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 82/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 83/500
2/2 [==============================] - 0s 377ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 84/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 85/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 86/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 87/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 88/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 89/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 90/500
2/2 [==============================] - 0s 138ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 91/500
2/2 [==============================] - 0s 110ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 92/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 93/500
2/2 [==============================] - 0s 283ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 94/500
2/2 [==============================] - 1s 773ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 95/500
2/2 [==============================] - 0s 113ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 96/500
2/2 [==============================] - 0s 107ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 97/500
2/2 [==============================] - 0s 114ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 98/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 99/500
2/2 [==============================] - 1s 447ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 100/500
2/2 [==============================] - 0s 109ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 101/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 102/500
2/2 [==============================] - 1s 1s/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 103/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 104/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 105/500
2/2 [==============================] - 0s 111ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 106/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 107/500
2/2 [==============================] - 0s 374ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 108/500
2/2 [==============================] - 0s 112ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 109/500
2/2 [==============================] - 0s 116ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 110/500
2/2 [==============================] - 0s 283ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 111/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 112/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 113/500
2/2 [==============================] - 0s 386ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 114/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 115/500
2/2 [==============================] - 0s 109ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 116/500
2/2 [==============================] - 0s 111ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7657 - val_mse: 1.7657
Epoch 117/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 118/500
2/2 [==============================] - 0s 325ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 119/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 120/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 121/500
2/2 [==============================] - 0s 369ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 122/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 123/500
2/2 [==============================] - 0s 142ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 124/500
2/2 [==============================] - 1s 434ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 125/500
2/2 [==============================] - 0s 111ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 126/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9235 - mse: 2.9235 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 127/500
2/2 [==============================] - 0s 116ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 128/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 129/500
2/2 [==============================] - 0s 110ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 130/500
2/2 [==============================] - 0s 108ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 131/500
2/2 [==============================] - 0s 139ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 132/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 133/500
2/2 [==============================] - 0s 108ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 134/500
2/2 [==============================] - 0s 109ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 135/500
2/2 [==============================] - 0s 271ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 136/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 137/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 138/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 139/500
2/2 [==============================] - 0s 110ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 140/500
2/2 [==============================] - 0s 253ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 141/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 142/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 143/500
2/2 [==============================] - 0s 113ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 144/500
2/2 [==============================] - 0s 299ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 145/500
2/2 [==============================] - 0s 112ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 146/500
2/2 [==============================] - 0s 109ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 147/500
2/2 [==============================] - 0s 113ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 148/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 149/500
2/2 [==============================] - 1s 693ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 150/500
2/2 [==============================] - 0s 111ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 151/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 152/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 153/500
2/2 [==============================] - 0s 313ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 154/500
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 155/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 156/500
2/2 [==============================] - 0s 384ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 157/500
2/2 [==============================] - 0s 135ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 158/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 159/500
2/2 [==============================] - 0s 137ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 160/500
2/2 [==============================] - 0s 365ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 161/500
2/2 [==============================] - 0s 145ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 162/500
2/2 [==============================] - 0s 130ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 163/500
2/2 [==============================] - 0s 359ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 164/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 165/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 166/500
2/2 [==============================] - 0s 408ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 167/500
2/2 [==============================] - 0s 121ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 168/500
2/2 [==============================] - 0s 136ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 169/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 170/500
2/2 [==============================] - 0s 130ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 171/500
2/2 [==============================] - 0s 143ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 172/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 173/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 174/500
2/2 [==============================] - 0s 217ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 175/500
2/2 [==============================] - 0s 203ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 176/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 177/500
2/2 [==============================] - 0s 210ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 178/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 179/500
2/2 [==============================] - 0s 138ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 180/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 181/500
2/2 [==============================] - 0s 123ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 182/500
2/2 [==============================] - 0s 134ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 183/500
2/2 [==============================] - 0s 232ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 184/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 185/500
2/2 [==============================] - 0s 135ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 186/500
2/2 [==============================] - 0s 147ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 187/500
2/2 [==============================] - 0s 334ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 188/500
2/2 [==============================] - 0s 116ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 189/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 190/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 191/500
2/2 [==============================] - 0s 248ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 192/500
2/2 [==============================] - 0s 141ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 193/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 194/500
2/2 [==============================] - 0s 333ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 195/500
2/2 [==============================] - 1s 703ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 196/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 197/500
2/2 [==============================] - 1s 773ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 198/500
2/2 [==============================] - 0s 132ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 199/500
2/2 [==============================] - 0s 113ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 200/500
2/2 [==============================] - 1s 760ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 201/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 202/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 203/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 204/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 205/500
2/2 [==============================] - 2s 2s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 206/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 207/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 208/500
2/2 [==============================] - 0s 136ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 209/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 210/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 211/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 212/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 213/500
2/2 [==============================] - 0s 314ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 214/500
2/2 [==============================] - 1s 776ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 215/500
2/2 [==============================] - 0s 142ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 216/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 217/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 218/500
2/2 [==============================] - 0s 301ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 219/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 220/500
2/2 [==============================] - 1s 559ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 221/500
2/2 [==============================] - 1s 739ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 222/500
2/2 [==============================] - 0s 130ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 223/500
2/2 [==============================] - 0s 208ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 224/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 225/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 226/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 227/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 228/500
2/2 [==============================] - 0s 135ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 229/500
2/2 [==============================] - 1s 856ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 230/500
2/2 [==============================] - 0s 380ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 231/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 232/500
2/2 [==============================] - 0s 116ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 233/500
2/2 [==============================] - 0s 358ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 234/500
2/2 [==============================] - 0s 136ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 235/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 236/500
2/2 [==============================] - 0s 377ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 237/500
2/2 [==============================] - 1s 755ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 238/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 239/500
2/2 [==============================] - 0s 147ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 240/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 241/500
2/2 [==============================] - 0s 290ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 242/500
2/2 [==============================] - 1s 760ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 243/500
2/2 [==============================] - 0s 135ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 244/500
2/2 [==============================] - 1s 751ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 245/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 246/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 247/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 248/500
2/2 [==============================] - 0s 298ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 249/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 250/500
2/2 [==============================] - 0s 121ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 251/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 252/500
2/2 [==============================] - 0s 136ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 253/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 254/500
2/2 [==============================] - 0s 123ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 255/500
2/2 [==============================] - 0s 139ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 256/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 257/500
2/2 [==============================] - 0s 276ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 258/500
2/2 [==============================] - 1s 693ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 259/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 260/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 261/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 262/500
2/2 [==============================] - 0s 130ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 263/500
2/2 [==============================] - 1s 920ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 264/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 265/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 266/500
2/2 [==============================] - 0s 123ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 267/500
2/2 [==============================] - 0s 146ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 268/500
2/2 [==============================] - 0s 138ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 269/500
2/2 [==============================] - 1s 714ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 270/500
2/2 [==============================] - 0s 134ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 271/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 272/500
2/2 [==============================] - 0s 114ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 273/500
2/2 [==============================] - 0s 261ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 274/500
2/2 [==============================] - 0s 115ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 275/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 276/500
2/2 [==============================] - 0s 114ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 277/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 278/500
2/2 [==============================] - 0s 237ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 279/500
2/2 [==============================] - 1s 765ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 280/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 281/500
2/2 [==============================] - 0s 116ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 282/500
2/2 [==============================] - 0s 121ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 283/500
2/2 [==============================] - 0s 326ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 284/500
2/2 [==============================] - 0s 153ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 285/500
2/2 [==============================] - 0s 121ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 286/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 287/500
2/2 [==============================] - 1s 904ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 288/500
2/2 [==============================] - 1s 773ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 289/500
2/2 [==============================] - 0s 135ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 290/500
2/2 [==============================] - 0s 135ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 291/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 292/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 293/500
2/2 [==============================] - 1s 852ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 294/500
2/2 [==============================] - 1s 697ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 295/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 296/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 297/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 298/500
2/2 [==============================] - 0s 377ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 299/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 300/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 301/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 302/500
2/2 [==============================] - 0s 285ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 303/500
2/2 [==============================] - 1s 723ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 304/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 305/500
2/2 [==============================] - 0s 141ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 306/500
2/2 [==============================] - 1s 747ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 307/500
2/2 [==============================] - 0s 135ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 308/500
2/2 [==============================] - 1s 758ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 309/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 310/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 311/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 312/500
2/2 [==============================] - 0s 390ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 313/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 314/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 315/500
2/2 [==============================] - 0s 141ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 316/500
2/2 [==============================] - 1s 798ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 317/500
2/2 [==============================] - 0s 376ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 318/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 319/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 320/500
2/2 [==============================] - 1s 398ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 321/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 322/500
2/2 [==============================] - 0s 136ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 323/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 324/500
2/2 [==============================] - 0s 355ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 325/500
2/2 [==============================] - 0s 123ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 326/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 327/500
2/2 [==============================] - 1s 399ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 328/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 329/500
2/2 [==============================] - 0s 145ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 330/500
2/2 [==============================] - 0s 223ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 331/500
2/2 [==============================] - 0s 150ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 332/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 333/500
2/2 [==============================] - 0s 133ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 334/500
2/2 [==============================] - 0s 242ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 335/500
2/2 [==============================] - 1s 747ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 336/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 337/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 338/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 339/500
2/2 [==============================] - 1s 402ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 340/500
2/2 [==============================] - 1s 706ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 341/500
2/2 [==============================] - 0s 132ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 342/500
2/2 [==============================] - 0s 139ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 343/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 344/500
2/2 [==============================] - 0s 303ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 345/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 346/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 347/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 348/500
2/2 [==============================] - 0s 251ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 349/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 350/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 351/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 352/500
2/2 [==============================] - 0s 264ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 353/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 354/500
2/2 [==============================] - 0s 121ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 355/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 356/500
2/2 [==============================] - 0s 235ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 357/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 358/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 359/500
2/2 [==============================] - 0s 278ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 360/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 361/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 362/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 363/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 364/500
2/2 [==============================] - 0s 117ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 365/500
2/2 [==============================] - 0s 132ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 366/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 367/500
2/2 [==============================] - 0s 260ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 368/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 369/500
2/2 [==============================] - 1s 760ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 370/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 371/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 372/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 373/500
2/2 [==============================] - 0s 133ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 374/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 375/500
2/2 [==============================] - 1s 743ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 376/500
2/2 [==============================] - 0s 137ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 377/500
2/2 [==============================] - 1s 713ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 378/500
2/2 [==============================] - 0s 130ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 379/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 380/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 381/500
2/2 [==============================] - 0s 282ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 382/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 383/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 384/500
2/2 [==============================] - 0s 133ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 385/500
2/2 [==============================] - 0s 267ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 386/500
2/2 [==============================] - 1s 761ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 387/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 388/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 389/500
2/2 [==============================] - 1s 762ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 390/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 391/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 392/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 393/500
2/2 [==============================] - 0s 157ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 394/500
2/2 [==============================] - 1s 845ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 395/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 396/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 397/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 398/500
2/2 [==============================] - 0s 116ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 399/500
2/2 [==============================] - 0s 253ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 400/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 401/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 402/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 403/500
2/2 [==============================] - 0s 137ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 404/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 405/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 406/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 407/500
2/2 [==============================] - 0s 284ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 408/500
2/2 [==============================] - 1s 735ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 409/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 410/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 411/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 412/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 413/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 414/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 415/500
2/2 [==============================] - 0s 132ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 416/500
2/2 [==============================] - 1s 403ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 417/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 418/500
2/2 [==============================] - 0s 121ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 419/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 420/500
2/2 [==============================] - 1s 429ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 421/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 422/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 423/500
2/2 [==============================] - 1s 951ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 424/500
2/2 [==============================] - 1s 739ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 425/500
2/2 [==============================] - 0s 123ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 426/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 427/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 428/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 429/500
2/2 [==============================] - 0s 132ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 430/500
2/2 [==============================] - 0s 121ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 431/500
2/2 [==============================] - 0s 270ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 432/500
2/2 [==============================] - 0s 135ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 433/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 434/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 435/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 436/500
2/2 [==============================] - 0s 281ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 437/500
2/2 [==============================] - 0s 118ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 438/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 439/500
2/2 [==============================] - 0s 320ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 440/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 441/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 442/500
2/2 [==============================] - 0s 396ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 443/500
2/2 [==============================] - 1s 654ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 444/500
2/2 [==============================] - 0s 124ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 445/500
2/2 [==============================] - 1s 898ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 446/500
2/2 [==============================] - 0s 215ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 447/500
2/2 [==============================] - 1s 476ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 448/500
2/2 [==============================] - 0s 229ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 449/500
2/2 [==============================] - 0s 197ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 450/500
2/2 [==============================] - 1s 884ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 451/500
2/2 [==============================] - 0s 359ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 452/500
2/2 [==============================] - 0s 138ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 453/500
2/2 [==============================] - 0s 120ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 454/500
2/2 [==============================] - 1s 405ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 455/500
2/2 [==============================] - 0s 125ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 456/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 457/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 458/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 459/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 460/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 461/500
2/2 [==============================] - 1s 410ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 462/500
2/2 [==============================] - 1s 757ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 463/500
2/2 [==============================] - 0s 122ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 464/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 465/500
2/2 [==============================] - 0s 133ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 466/500
2/2 [==============================] - 0s 135ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 467/500
2/2 [==============================] - 1s 706ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 468/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 469/500
2/2 [==============================] - 0s 156ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 470/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 471/500
2/2 [==============================] - 0s 129ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 472/500
2/2 [==============================] - 0s 306ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 473/500
2/2 [==============================] - 1s 695ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 474/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 475/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 476/500
2/2 [==============================] - 0s 133ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 477/500
2/2 [==============================] - 0s 381ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 478/500
2/2 [==============================] - 1s 728ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 479/500
2/2 [==============================] - 0s 142ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 480/500
2/2 [==============================] - 0s 126ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 481/500
2/2 [==============================] - 0s 139ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 482/500
2/2 [==============================] - 0s 137ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 483/500
2/2 [==============================] - 1s 1s/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 484/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 485/500
2/2 [==============================] - 0s 140ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 486/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 487/500
2/2 [==============================] - 0s 147ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 488/500
2/2 [==============================] - 0s 131ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 489/500
2/2 [==============================] - 0s 123ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 490/500
2/2 [==============================] - 0s 134ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 491/500
2/2 [==============================] - 0s 308ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 492/500
2/2 [==============================] - 0s 119ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 493/500
2/2 [==============================] - 0s 128ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 494/500
2/2 [==============================] - 0s 136ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 495/500
2/2 [==============================] - 0s 287ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 496/500
2/2 [==============================] - 0s 154ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 497/500
2/2 [==============================] - 0s 116ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 498/500
2/2 [==============================] - 0s 142ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 499/500
2/2 [==============================] - 0s 127ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Epoch 500/500
2/2 [==============================] - 0s 130ms/step - loss: 2.9234 - mse: 2.9234 - val_loss: 1.7656 - val_mse: 1.7656
Model MSE: 1.7655973434448242
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.3.-Milling">3.3. Milling<a class="anchor-link" href="#3.3.-Milling">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">NUMPY_INPUT_DATA_milling</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_MILLING</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">X_train_reg_milling</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_milling</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">],:,:,:]</span>
<span class="n">y_train_reg</span> <span class="o">=</span> <span class="n">y_target_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]]</span>
<span class="n">X_test_reg_milling</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_milling</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test_reg</span> <span class="o">=</span> <span class="n">y_target_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>
    
<span class="c1"># Define the model architecture</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
<span class="c1">#model.add(MaxPooling2D((2, 2)))</span>
<span class="c1"># model.add(Conv2D(128, (3, 3), activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;, padding=&#39;same&#39;))</span>
<span class="c1"># model.add(MaxPooling2D((2, 2)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="c1"># Compile the model</span>
<span class="c1">#opt = SGD(lr=0.001, momentum=0.9)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reg_milling</span><span class="p">,</span> <span class="n">y_train_reg</span><span class="p">,</span>
          <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test_reg_milling</span><span class="p">,</span> <span class="n">y_test_reg</span><span class="p">))</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_reg_milling</span><span class="p">,</span> <span class="n">y_test_reg</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model MSE:&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/500
2/2 [==============================] - 2s 1s/step - loss: 3.9580 - mse: 3.9580 - val_loss: 2.3737 - val_mse: 2.3737
Epoch 2/500
2/2 [==============================] - 1s 1s/step - loss: 3.9008 - mse: 3.9008 - val_loss: 2.3712 - val_mse: 2.3712
Epoch 3/500
2/2 [==============================] - 3s 2s/step - loss: 3.8989 - mse: 3.8989 - val_loss: 2.3702 - val_mse: 2.3702
Epoch 4/500
2/2 [==============================] - 0s 367ms/step - loss: 3.8965 - mse: 3.8965 - val_loss: 2.3686 - val_mse: 2.3686
Epoch 5/500
2/2 [==============================] - 1s 699ms/step - loss: 3.8941 - mse: 3.8941 - val_loss: 2.3670 - val_mse: 2.3670
Epoch 6/500
2/2 [==============================] - 0s 72ms/step - loss: 3.8919 - mse: 3.8919 - val_loss: 2.3653 - val_mse: 2.3653
Epoch 7/500
2/2 [==============================] - 0s 75ms/step - loss: 3.8896 - mse: 3.8896 - val_loss: 2.3637 - val_mse: 2.3637
Epoch 8/500
2/2 [==============================] - 1s 734ms/step - loss: 3.8873 - mse: 3.8873 - val_loss: 2.3620 - val_mse: 2.3620
Epoch 9/500
2/2 [==============================] - 0s 82ms/step - loss: 3.8849 - mse: 3.8849 - val_loss: 2.3604 - val_mse: 2.3604
Epoch 10/500
2/2 [==============================] - 0s 106ms/step - loss: 3.8826 - mse: 3.8826 - val_loss: 2.3587 - val_mse: 2.3587
Epoch 11/500
2/2 [==============================] - 0s 84ms/step - loss: 3.8800 - mse: 3.8800 - val_loss: 2.3571 - val_mse: 2.3571
Epoch 12/500
2/2 [==============================] - 0s 81ms/step - loss: 3.8777 - mse: 3.8777 - val_loss: 2.3554 - val_mse: 2.3554
Epoch 13/500
2/2 [==============================] - 0s 64ms/step - loss: 3.8753 - mse: 3.8753 - val_loss: 2.3537 - val_mse: 2.3537
Epoch 14/500
2/2 [==============================] - 0s 88ms/step - loss: 3.8729 - mse: 3.8729 - val_loss: 2.3521 - val_mse: 2.3521
Epoch 15/500
2/2 [==============================] - 0s 73ms/step - loss: 3.8705 - mse: 3.8705 - val_loss: 2.3504 - val_mse: 2.3504
Epoch 16/500
2/2 [==============================] - 0s 64ms/step - loss: 3.8680 - mse: 3.8680 - val_loss: 2.3487 - val_mse: 2.3487
Epoch 17/500
2/2 [==============================] - 0s 319ms/step - loss: 3.8656 - mse: 3.8656 - val_loss: 2.3471 - val_mse: 2.3471
Epoch 18/500
2/2 [==============================] - 0s 87ms/step - loss: 3.8632 - mse: 3.8632 - val_loss: 2.3454 - val_mse: 2.3454
Epoch 19/500
2/2 [==============================] - 0s 68ms/step - loss: 3.8609 - mse: 3.8609 - val_loss: 2.3437 - val_mse: 2.3437
Epoch 20/500
2/2 [==============================] - 0s 71ms/step - loss: 3.8585 - mse: 3.8585 - val_loss: 2.3420 - val_mse: 2.3420
Epoch 21/500
2/2 [==============================] - 0s 63ms/step - loss: 3.8559 - mse: 3.8559 - val_loss: 2.3403 - val_mse: 2.3403
Epoch 22/500
2/2 [==============================] - 0s 70ms/step - loss: 3.8536 - mse: 3.8536 - val_loss: 2.3386 - val_mse: 2.3386
Epoch 23/500
2/2 [==============================] - 0s 394ms/step - loss: 3.8512 - mse: 3.8512 - val_loss: 2.3369 - val_mse: 2.3369
Epoch 24/500
2/2 [==============================] - 1s 711ms/step - loss: 3.8487 - mse: 3.8487 - val_loss: 2.3352 - val_mse: 2.3352
Epoch 25/500
2/2 [==============================] - 0s 67ms/step - loss: 3.8462 - mse: 3.8462 - val_loss: 2.3335 - val_mse: 2.3335
Epoch 26/500
2/2 [==============================] - 0s 89ms/step - loss: 3.8438 - mse: 3.8438 - val_loss: 2.3318 - val_mse: 2.3318
Epoch 27/500
2/2 [==============================] - 0s 66ms/step - loss: 3.8412 - mse: 3.8412 - val_loss: 2.3301 - val_mse: 2.3301
Epoch 28/500
2/2 [==============================] - 0s 64ms/step - loss: 3.8388 - mse: 3.8388 - val_loss: 2.3284 - val_mse: 2.3284
Epoch 29/500
2/2 [==============================] - 0s 65ms/step - loss: 3.8361 - mse: 3.8361 - val_loss: 2.3267 - val_mse: 2.3267
Epoch 30/500
2/2 [==============================] - 0s 69ms/step - loss: 3.8339 - mse: 3.8339 - val_loss: 2.3250 - val_mse: 2.3250
Epoch 31/500
2/2 [==============================] - 0s 83ms/step - loss: 3.8313 - mse: 3.8313 - val_loss: 2.3233 - val_mse: 2.3233
Epoch 32/500
2/2 [==============================] - 0s 227ms/step - loss: 3.8289 - mse: 3.8289 - val_loss: 2.3215 - val_mse: 2.3215
Epoch 33/500
2/2 [==============================] - 0s 83ms/step - loss: 3.8264 - mse: 3.8264 - val_loss: 2.3198 - val_mse: 2.3198
Epoch 34/500
2/2 [==============================] - 0s 66ms/step - loss: 3.8241 - mse: 3.8241 - val_loss: 2.3181 - val_mse: 2.3181
Epoch 35/500
2/2 [==============================] - 0s 63ms/step - loss: 3.8213 - mse: 3.8213 - val_loss: 2.3163 - val_mse: 2.3163
Epoch 36/500
2/2 [==============================] - 0s 73ms/step - loss: 3.8188 - mse: 3.8188 - val_loss: 2.3146 - val_mse: 2.3146
Epoch 37/500
2/2 [==============================] - 0s 64ms/step - loss: 3.8164 - mse: 3.8164 - val_loss: 2.3129 - val_mse: 2.3129
Epoch 38/500
2/2 [==============================] - 0s 65ms/step - loss: 3.8138 - mse: 3.8138 - val_loss: 2.3111 - val_mse: 2.3111
Epoch 39/500
2/2 [==============================] - 0s 71ms/step - loss: 3.8112 - mse: 3.8112 - val_loss: 2.3094 - val_mse: 2.3094
Epoch 40/500
2/2 [==============================] - 0s 70ms/step - loss: 3.8089 - mse: 3.8089 - val_loss: 2.3077 - val_mse: 2.3077
Epoch 41/500
2/2 [==============================] - 0s 69ms/step - loss: 3.8061 - mse: 3.8061 - val_loss: 2.3059 - val_mse: 2.3059
Epoch 42/500
2/2 [==============================] - 0s 69ms/step - loss: 3.8038 - mse: 3.8038 - val_loss: 2.3042 - val_mse: 2.3042
Epoch 43/500
2/2 [==============================] - 0s 63ms/step - loss: 3.8010 - mse: 3.8010 - val_loss: 2.3024 - val_mse: 2.3024
Epoch 44/500
2/2 [==============================] - 0s 64ms/step - loss: 3.7987 - mse: 3.7987 - val_loss: 2.3007 - val_mse: 2.3007
Epoch 45/500
2/2 [==============================] - 0s 67ms/step - loss: 3.7960 - mse: 3.7960 - val_loss: 2.2989 - val_mse: 2.2989
Epoch 46/500
2/2 [==============================] - 0s 65ms/step - loss: 3.7936 - mse: 3.7936 - val_loss: 2.2972 - val_mse: 2.2972
Epoch 47/500
2/2 [==============================] - 0s 72ms/step - loss: 3.7911 - mse: 3.7911 - val_loss: 2.2954 - val_mse: 2.2954
Epoch 48/500
2/2 [==============================] - 0s 79ms/step - loss: 3.7883 - mse: 3.7883 - val_loss: 2.2937 - val_mse: 2.2937
Epoch 49/500
2/2 [==============================] - 0s 63ms/step - loss: 3.7857 - mse: 3.7857 - val_loss: 2.2919 - val_mse: 2.2919
Epoch 50/500
2/2 [==============================] - 0s 66ms/step - loss: 3.7833 - mse: 3.7833 - val_loss: 2.2902 - val_mse: 2.2902
Epoch 51/500
2/2 [==============================] - 0s 76ms/step - loss: 3.7809 - mse: 3.7809 - val_loss: 2.2884 - val_mse: 2.2884
Epoch 52/500
2/2 [==============================] - 0s 69ms/step - loss: 3.7782 - mse: 3.7782 - val_loss: 2.2866 - val_mse: 2.2866
Epoch 53/500
2/2 [==============================] - 0s 63ms/step - loss: 3.7756 - mse: 3.7756 - val_loss: 2.2848 - val_mse: 2.2848
Epoch 54/500
2/2 [==============================] - 0s 97ms/step - loss: 3.7728 - mse: 3.7728 - val_loss: 2.2831 - val_mse: 2.2831
Epoch 55/500
2/2 [==============================] - 0s 81ms/step - loss: 3.7705 - mse: 3.7705 - val_loss: 2.2813 - val_mse: 2.2813
Epoch 56/500
2/2 [==============================] - 0s 307ms/step - loss: 3.7679 - mse: 3.7679 - val_loss: 2.2795 - val_mse: 2.2795
Epoch 57/500
2/2 [==============================] - 0s 76ms/step - loss: 3.7652 - mse: 3.7652 - val_loss: 2.2778 - val_mse: 2.2778
Epoch 58/500
2/2 [==============================] - 0s 70ms/step - loss: 3.7628 - mse: 3.7628 - val_loss: 2.2760 - val_mse: 2.2760
Epoch 59/500
2/2 [==============================] - 0s 63ms/step - loss: 3.7600 - mse: 3.7600 - val_loss: 2.2742 - val_mse: 2.2742
Epoch 60/500
2/2 [==============================] - 0s 78ms/step - loss: 3.7573 - mse: 3.7573 - val_loss: 2.2724 - val_mse: 2.2724
Epoch 61/500
2/2 [==============================] - 0s 66ms/step - loss: 3.7548 - mse: 3.7548 - val_loss: 2.2707 - val_mse: 2.2707
Epoch 62/500
2/2 [==============================] - 0s 321ms/step - loss: 3.7522 - mse: 3.7522 - val_loss: 2.2689 - val_mse: 2.2689
Epoch 63/500
2/2 [==============================] - 0s 70ms/step - loss: 3.7497 - mse: 3.7497 - val_loss: 2.2671 - val_mse: 2.2671
Epoch 64/500
2/2 [==============================] - 0s 64ms/step - loss: 3.7472 - mse: 3.7472 - val_loss: 2.2653 - val_mse: 2.2653
Epoch 65/500
2/2 [==============================] - 0s 64ms/step - loss: 3.7443 - mse: 3.7443 - val_loss: 2.2635 - val_mse: 2.2635
Epoch 66/500
2/2 [==============================] - 0s 103ms/step - loss: 3.7418 - mse: 3.7418 - val_loss: 2.2617 - val_mse: 2.2617
Epoch 67/500
2/2 [==============================] - 0s 66ms/step - loss: 3.7390 - mse: 3.7390 - val_loss: 2.2600 - val_mse: 2.2600
Epoch 68/500
2/2 [==============================] - 0s 80ms/step - loss: 3.7365 - mse: 3.7365 - val_loss: 2.2582 - val_mse: 2.2582
Epoch 69/500
2/2 [==============================] - 0s 66ms/step - loss: 3.7339 - mse: 3.7339 - val_loss: 2.2564 - val_mse: 2.2564
Epoch 70/500
2/2 [==============================] - 0s 78ms/step - loss: 3.7312 - mse: 3.7312 - val_loss: 2.2546 - val_mse: 2.2546
Epoch 71/500
2/2 [==============================] - 0s 290ms/step - loss: 3.7288 - mse: 3.7288 - val_loss: 2.2528 - val_mse: 2.2528
Epoch 72/500
2/2 [==============================] - 0s 80ms/step - loss: 3.7262 - mse: 3.7262 - val_loss: 2.2510 - val_mse: 2.2510
Epoch 73/500
2/2 [==============================] - 0s 63ms/step - loss: 3.7232 - mse: 3.7232 - val_loss: 2.2492 - val_mse: 2.2492
Epoch 74/500
2/2 [==============================] - 0s 65ms/step - loss: 3.7205 - mse: 3.7205 - val_loss: 2.2475 - val_mse: 2.2475
Epoch 75/500
2/2 [==============================] - 0s 79ms/step - loss: 3.7183 - mse: 3.7183 - val_loss: 2.2457 - val_mse: 2.2457
Epoch 76/500
2/2 [==============================] - 0s 71ms/step - loss: 3.7155 - mse: 3.7155 - val_loss: 2.2439 - val_mse: 2.2439
Epoch 77/500
2/2 [==============================] - 0s 68ms/step - loss: 3.7127 - mse: 3.7127 - val_loss: 2.2421 - val_mse: 2.2421
Epoch 78/500
2/2 [==============================] - 0s 70ms/step - loss: 3.7103 - mse: 3.7103 - val_loss: 2.2403 - val_mse: 2.2403
Epoch 79/500
2/2 [==============================] - 0s 79ms/step - loss: 3.7076 - mse: 3.7076 - val_loss: 2.2385 - val_mse: 2.2385
Epoch 80/500
2/2 [==============================] - 0s 73ms/step - loss: 3.7048 - mse: 3.7048 - val_loss: 2.2367 - val_mse: 2.2367
Epoch 81/500
2/2 [==============================] - 0s 83ms/step - loss: 3.7021 - mse: 3.7021 - val_loss: 2.2349 - val_mse: 2.2349
Epoch 82/500
2/2 [==============================] - 0s 67ms/step - loss: 3.6996 - mse: 3.6996 - val_loss: 2.2331 - val_mse: 2.2331
Epoch 83/500
2/2 [==============================] - 0s 70ms/step - loss: 3.6969 - mse: 3.6969 - val_loss: 2.2313 - val_mse: 2.2313
Epoch 84/500
2/2 [==============================] - 0s 71ms/step - loss: 3.6942 - mse: 3.6942 - val_loss: 2.2296 - val_mse: 2.2296
Epoch 85/500
2/2 [==============================] - 1s 1s/step - loss: 3.6918 - mse: 3.6918 - val_loss: 2.2278 - val_mse: 2.2278
Epoch 86/500
2/2 [==============================] - 0s 65ms/step - loss: 3.6889 - mse: 3.6889 - val_loss: 2.2260 - val_mse: 2.2260
Epoch 87/500
2/2 [==============================] - 0s 71ms/step - loss: 3.6864 - mse: 3.6864 - val_loss: 2.2242 - val_mse: 2.2242
Epoch 88/500
2/2 [==============================] - 0s 70ms/step - loss: 3.6837 - mse: 3.6837 - val_loss: 2.2224 - val_mse: 2.2224
Epoch 89/500
2/2 [==============================] - 0s 71ms/step - loss: 3.6809 - mse: 3.6809 - val_loss: 2.2206 - val_mse: 2.2206
Epoch 90/500
2/2 [==============================] - 0s 64ms/step - loss: 3.6782 - mse: 3.6782 - val_loss: 2.2188 - val_mse: 2.2188
Epoch 91/500
2/2 [==============================] - 0s 311ms/step - loss: 3.6757 - mse: 3.6757 - val_loss: 2.2170 - val_mse: 2.2170
Epoch 92/500
2/2 [==============================] - 0s 67ms/step - loss: 3.6730 - mse: 3.6730 - val_loss: 2.2153 - val_mse: 2.2153
Epoch 93/500
2/2 [==============================] - 0s 65ms/step - loss: 3.6704 - mse: 3.6704 - val_loss: 2.2135 - val_mse: 2.2135
Epoch 94/500
2/2 [==============================] - 0s 82ms/step - loss: 3.6678 - mse: 3.6678 - val_loss: 2.2117 - val_mse: 2.2117
Epoch 95/500
2/2 [==============================] - 0s 65ms/step - loss: 3.6650 - mse: 3.6650 - val_loss: 2.2099 - val_mse: 2.2099
Epoch 96/500
2/2 [==============================] - 0s 65ms/step - loss: 3.6624 - mse: 3.6624 - val_loss: 2.2081 - val_mse: 2.2081
Epoch 97/500
2/2 [==============================] - 0s 65ms/step - loss: 3.6598 - mse: 3.6598 - val_loss: 2.2063 - val_mse: 2.2063
Epoch 98/500
2/2 [==============================] - 0s 72ms/step - loss: 3.6571 - mse: 3.6571 - val_loss: 2.2045 - val_mse: 2.2045
Epoch 99/500
2/2 [==============================] - 0s 84ms/step - loss: 3.6543 - mse: 3.6543 - val_loss: 2.2027 - val_mse: 2.2027
Epoch 100/500
2/2 [==============================] - 0s 83ms/step - loss: 3.6517 - mse: 3.6517 - val_loss: 2.2009 - val_mse: 2.2009
Epoch 101/500
2/2 [==============================] - 1s 1s/step - loss: 3.6492 - mse: 3.6492 - val_loss: 2.1991 - val_mse: 2.1991
Epoch 102/500
2/2 [==============================] - 0s 141ms/step - loss: 3.6464 - mse: 3.6464 - val_loss: 2.1973 - val_mse: 2.1973
Epoch 103/500
2/2 [==============================] - 0s 127ms/step - loss: 3.6436 - mse: 3.6436 - val_loss: 2.1956 - val_mse: 2.1956
Epoch 104/500
2/2 [==============================] - 0s 128ms/step - loss: 3.6409 - mse: 3.6409 - val_loss: 2.1938 - val_mse: 2.1938
Epoch 105/500
2/2 [==============================] - 1s 1s/step - loss: 3.6383 - mse: 3.6383 - val_loss: 2.1920 - val_mse: 2.1920
Epoch 106/500
2/2 [==============================] - 0s 67ms/step - loss: 3.6358 - mse: 3.6358 - val_loss: 2.1903 - val_mse: 2.1903
Epoch 107/500
2/2 [==============================] - 0s 65ms/step - loss: 3.6332 - mse: 3.6332 - val_loss: 2.1885 - val_mse: 2.1885
Epoch 108/500
2/2 [==============================] - 0s 94ms/step - loss: 3.6304 - mse: 3.6304 - val_loss: 2.1867 - val_mse: 2.1867
Epoch 109/500
2/2 [==============================] - 0s 63ms/step - loss: 3.6277 - mse: 3.6277 - val_loss: 2.1849 - val_mse: 2.1849
Epoch 110/500
2/2 [==============================] - 0s 95ms/step - loss: 3.6250 - mse: 3.6250 - val_loss: 2.1832 - val_mse: 2.1832
Epoch 111/500
2/2 [==============================] - 0s 71ms/step - loss: 3.6223 - mse: 3.6223 - val_loss: 2.1814 - val_mse: 2.1814
Epoch 112/500
2/2 [==============================] - 1s 872ms/step - loss: 3.6199 - mse: 3.6199 - val_loss: 2.1796 - val_mse: 2.1796
Epoch 113/500
2/2 [==============================] - 1s 912ms/step - loss: 3.6171 - mse: 3.6171 - val_loss: 2.1779 - val_mse: 2.1779
Epoch 114/500
2/2 [==============================] - 0s 377ms/step - loss: 3.6144 - mse: 3.6144 - val_loss: 2.1761 - val_mse: 2.1761
Epoch 115/500
2/2 [==============================] - 1s 675ms/step - loss: 3.6119 - mse: 3.6119 - val_loss: 2.1743 - val_mse: 2.1743
Epoch 116/500
2/2 [==============================] - 0s 65ms/step - loss: 3.6092 - mse: 3.6092 - val_loss: 2.1726 - val_mse: 2.1726
Epoch 117/500
2/2 [==============================] - 0s 68ms/step - loss: 3.6066 - mse: 3.6066 - val_loss: 2.1708 - val_mse: 2.1708
Epoch 118/500
2/2 [==============================] - 0s 82ms/step - loss: 3.6038 - mse: 3.6038 - val_loss: 2.1691 - val_mse: 2.1691
Epoch 119/500
2/2 [==============================] - 0s 66ms/step - loss: 3.6011 - mse: 3.6011 - val_loss: 2.1673 - val_mse: 2.1673
Epoch 120/500
2/2 [==============================] - 0s 63ms/step - loss: 3.5986 - mse: 3.5986 - val_loss: 2.1656 - val_mse: 2.1656
Epoch 121/500
2/2 [==============================] - 0s 64ms/step - loss: 3.5958 - mse: 3.5958 - val_loss: 2.1639 - val_mse: 2.1639
Epoch 122/500
2/2 [==============================] - 0s 88ms/step - loss: 3.5935 - mse: 3.5935 - val_loss: 2.1621 - val_mse: 2.1621
Epoch 123/500
2/2 [==============================] - 0s 83ms/step - loss: 3.5906 - mse: 3.5906 - val_loss: 2.1604 - val_mse: 2.1604
Epoch 124/500
2/2 [==============================] - 0s 350ms/step - loss: 3.5882 - mse: 3.5882 - val_loss: 2.1586 - val_mse: 2.1586
Epoch 125/500
2/2 [==============================] - 0s 68ms/step - loss: 3.5853 - mse: 3.5853 - val_loss: 2.1569 - val_mse: 2.1569
Epoch 126/500
2/2 [==============================] - 0s 74ms/step - loss: 3.5828 - mse: 3.5828 - val_loss: 2.1551 - val_mse: 2.1551
Epoch 127/500
2/2 [==============================] - 0s 72ms/step - loss: 3.5801 - mse: 3.5801 - val_loss: 2.1534 - val_mse: 2.1534
Epoch 128/500
2/2 [==============================] - 0s 69ms/step - loss: 3.5774 - mse: 3.5774 - val_loss: 2.1517 - val_mse: 2.1517
Epoch 129/500
2/2 [==============================] - 0s 223ms/step - loss: 3.5750 - mse: 3.5750 - val_loss: 2.1500 - val_mse: 2.1500
Epoch 130/500
2/2 [==============================] - 0s 86ms/step - loss: 3.5723 - mse: 3.5723 - val_loss: 2.1482 - val_mse: 2.1482
Epoch 131/500
2/2 [==============================] - 0s 68ms/step - loss: 3.5699 - mse: 3.5699 - val_loss: 2.1465 - val_mse: 2.1465
Epoch 132/500
2/2 [==============================] - 0s 80ms/step - loss: 3.5672 - mse: 3.5672 - val_loss: 2.1448 - val_mse: 2.1448
Epoch 133/500
2/2 [==============================] - 0s 71ms/step - loss: 3.5644 - mse: 3.5644 - val_loss: 2.1431 - val_mse: 2.1431
Epoch 134/500
2/2 [==============================] - 0s 72ms/step - loss: 3.5619 - mse: 3.5619 - val_loss: 2.1414 - val_mse: 2.1414
Epoch 135/500
2/2 [==============================] - 0s 66ms/step - loss: 3.5595 - mse: 3.5595 - val_loss: 2.1396 - val_mse: 2.1396
Epoch 136/500
2/2 [==============================] - 0s 66ms/step - loss: 3.5568 - mse: 3.5568 - val_loss: 2.1379 - val_mse: 2.1379
Epoch 137/500
2/2 [==============================] - 0s 71ms/step - loss: 3.5540 - mse: 3.5540 - val_loss: 2.1362 - val_mse: 2.1362
Epoch 138/500
2/2 [==============================] - 0s 66ms/step - loss: 3.5515 - mse: 3.5515 - val_loss: 2.1345 - val_mse: 2.1345
Epoch 139/500
2/2 [==============================] - 0s 65ms/step - loss: 3.5490 - mse: 3.5490 - val_loss: 2.1328 - val_mse: 2.1328
Epoch 140/500
2/2 [==============================] - 0s 68ms/step - loss: 3.5463 - mse: 3.5463 - val_loss: 2.1312 - val_mse: 2.1312
Epoch 141/500
2/2 [==============================] - 0s 70ms/step - loss: 3.5438 - mse: 3.5438 - val_loss: 2.1295 - val_mse: 2.1295
Epoch 142/500
2/2 [==============================] - 0s 270ms/step - loss: 3.5411 - mse: 3.5411 - val_loss: 2.1278 - val_mse: 2.1278
Epoch 143/500
2/2 [==============================] - 0s 67ms/step - loss: 3.5386 - mse: 3.5386 - val_loss: 2.1261 - val_mse: 2.1261
Epoch 144/500
2/2 [==============================] - 1s 748ms/step - loss: 3.5360 - mse: 3.5360 - val_loss: 2.1245 - val_mse: 2.1245
Epoch 145/500
2/2 [==============================] - 0s 65ms/step - loss: 3.5336 - mse: 3.5336 - val_loss: 2.1228 - val_mse: 2.1228
Epoch 146/500
2/2 [==============================] - 0s 98ms/step - loss: 3.5310 - mse: 3.5310 - val_loss: 2.1211 - val_mse: 2.1211
Epoch 147/500
2/2 [==============================] - 0s 70ms/step - loss: 3.5284 - mse: 3.5284 - val_loss: 2.1195 - val_mse: 2.1195
Epoch 148/500
2/2 [==============================] - 0s 66ms/step - loss: 3.5258 - mse: 3.5258 - val_loss: 2.1178 - val_mse: 2.1178
Epoch 149/500
2/2 [==============================] - 0s 67ms/step - loss: 3.5232 - mse: 3.5232 - val_loss: 2.1162 - val_mse: 2.1162
Epoch 150/500
2/2 [==============================] - 0s 66ms/step - loss: 3.5208 - mse: 3.5208 - val_loss: 2.1145 - val_mse: 2.1145
Epoch 151/500
2/2 [==============================] - 0s 70ms/step - loss: 3.5181 - mse: 3.5181 - val_loss: 2.1129 - val_mse: 2.1129
Epoch 152/500
2/2 [==============================] - 1s 963ms/step - loss: 3.5157 - mse: 3.5157 - val_loss: 2.1113 - val_mse: 2.1113
Epoch 153/500
2/2 [==============================] - 0s 84ms/step - loss: 3.5132 - mse: 3.5132 - val_loss: 2.1096 - val_mse: 2.1096
Epoch 154/500
2/2 [==============================] - 0s 75ms/step - loss: 3.5106 - mse: 3.5106 - val_loss: 2.1080 - val_mse: 2.1080
Epoch 155/500
2/2 [==============================] - 0s 65ms/step - loss: 3.5083 - mse: 3.5083 - val_loss: 2.1064 - val_mse: 2.1064
Epoch 156/500
2/2 [==============================] - 0s 71ms/step - loss: 3.5056 - mse: 3.5056 - val_loss: 2.1048 - val_mse: 2.1048
Epoch 157/500
2/2 [==============================] - 0s 71ms/step - loss: 3.5031 - mse: 3.5031 - val_loss: 2.1031 - val_mse: 2.1031
Epoch 158/500
2/2 [==============================] - 0s 71ms/step - loss: 3.5005 - mse: 3.5005 - val_loss: 2.1015 - val_mse: 2.1015
Epoch 159/500
2/2 [==============================] - 0s 63ms/step - loss: 3.4983 - mse: 3.4983 - val_loss: 2.0999 - val_mse: 2.0999
Epoch 160/500
2/2 [==============================] - 0s 66ms/step - loss: 3.4957 - mse: 3.4957 - val_loss: 2.0983 - val_mse: 2.0983
Epoch 161/500
2/2 [==============================] - 0s 65ms/step - loss: 3.4932 - mse: 3.4932 - val_loss: 2.0967 - val_mse: 2.0967
Epoch 162/500
2/2 [==============================] - 0s 84ms/step - loss: 3.4908 - mse: 3.4908 - val_loss: 2.0951 - val_mse: 2.0951
Epoch 163/500
2/2 [==============================] - 0s 64ms/step - loss: 3.4882 - mse: 3.4882 - val_loss: 2.0935 - val_mse: 2.0935
Epoch 164/500
2/2 [==============================] - 0s 66ms/step - loss: 3.4857 - mse: 3.4857 - val_loss: 2.0919 - val_mse: 2.0919
Epoch 165/500
2/2 [==============================] - 0s 70ms/step - loss: 3.4831 - mse: 3.4831 - val_loss: 2.0904 - val_mse: 2.0904
Epoch 166/500
2/2 [==============================] - 0s 64ms/step - loss: 3.4808 - mse: 3.4808 - val_loss: 2.0888 - val_mse: 2.0888
Epoch 167/500
2/2 [==============================] - 0s 69ms/step - loss: 3.4786 - mse: 3.4786 - val_loss: 2.0872 - val_mse: 2.0872
Epoch 168/500
2/2 [==============================] - 0s 370ms/step - loss: 3.4760 - mse: 3.4760 - val_loss: 2.0856 - val_mse: 2.0856
Epoch 169/500
2/2 [==============================] - 1s 770ms/step - loss: 3.4736 - mse: 3.4736 - val_loss: 2.0841 - val_mse: 2.0841
Epoch 170/500
2/2 [==============================] - 0s 65ms/step - loss: 3.4711 - mse: 3.4711 - val_loss: 2.0825 - val_mse: 2.0825
Epoch 171/500
2/2 [==============================] - 0s 77ms/step - loss: 3.4687 - mse: 3.4687 - val_loss: 2.0810 - val_mse: 2.0810
Epoch 172/500
2/2 [==============================] - 0s 64ms/step - loss: 3.4664 - mse: 3.4664 - val_loss: 2.0794 - val_mse: 2.0794
Epoch 173/500
2/2 [==============================] - 0s 65ms/step - loss: 3.4640 - mse: 3.4640 - val_loss: 2.0778 - val_mse: 2.0778
Epoch 174/500
2/2 [==============================] - 0s 77ms/step - loss: 3.4613 - mse: 3.4613 - val_loss: 2.0763 - val_mse: 2.0763
Epoch 175/500
2/2 [==============================] - 0s 77ms/step - loss: 3.4591 - mse: 3.4591 - val_loss: 2.0748 - val_mse: 2.0748
Epoch 176/500
2/2 [==============================] - 0s 65ms/step - loss: 3.4565 - mse: 3.4565 - val_loss: 2.0733 - val_mse: 2.0733
Epoch 177/500
2/2 [==============================] - 0s 247ms/step - loss: 3.4544 - mse: 3.4544 - val_loss: 2.0717 - val_mse: 2.0717
Epoch 178/500
2/2 [==============================] - 0s 64ms/step - loss: 3.4519 - mse: 3.4519 - val_loss: 2.0702 - val_mse: 2.0702
Epoch 179/500
2/2 [==============================] - 0s 65ms/step - loss: 3.4496 - mse: 3.4496 - val_loss: 2.0687 - val_mse: 2.0687
Epoch 180/500
2/2 [==============================] - 0s 65ms/step - loss: 3.4472 - mse: 3.4472 - val_loss: 2.0672 - val_mse: 2.0672
Epoch 181/500
2/2 [==============================] - 0s 85ms/step - loss: 3.4448 - mse: 3.4448 - val_loss: 2.0657 - val_mse: 2.0657
Epoch 182/500
2/2 [==============================] - 0s 87ms/step - loss: 3.4425 - mse: 3.4425 - val_loss: 2.0642 - val_mse: 2.0642
Epoch 183/500
2/2 [==============================] - 0s 287ms/step - loss: 3.4399 - mse: 3.4399 - val_loss: 2.0627 - val_mse: 2.0627
Epoch 184/500
2/2 [==============================] - 0s 68ms/step - loss: 3.4377 - mse: 3.4377 - val_loss: 2.0612 - val_mse: 2.0612
Epoch 185/500
2/2 [==============================] - 0s 72ms/step - loss: 3.4357 - mse: 3.4357 - val_loss: 2.0597 - val_mse: 2.0597
Epoch 186/500
2/2 [==============================] - 0s 80ms/step - loss: 3.4333 - mse: 3.4333 - val_loss: 2.0582 - val_mse: 2.0582
Epoch 187/500
2/2 [==============================] - 0s 70ms/step - loss: 3.4311 - mse: 3.4311 - val_loss: 2.0567 - val_mse: 2.0567
Epoch 188/500
2/2 [==============================] - 0s 69ms/step - loss: 3.4285 - mse: 3.4285 - val_loss: 2.0553 - val_mse: 2.0553
Epoch 189/500
2/2 [==============================] - 0s 72ms/step - loss: 3.4261 - mse: 3.4261 - val_loss: 2.0538 - val_mse: 2.0538
Epoch 190/500
2/2 [==============================] - 0s 70ms/step - loss: 3.4238 - mse: 3.4238 - val_loss: 2.0524 - val_mse: 2.0524
Epoch 191/500
2/2 [==============================] - 0s 66ms/step - loss: 3.4217 - mse: 3.4217 - val_loss: 2.0510 - val_mse: 2.0510
Epoch 192/500
2/2 [==============================] - 0s 72ms/step - loss: 3.4194 - mse: 3.4194 - val_loss: 2.0495 - val_mse: 2.0495
Epoch 193/500
2/2 [==============================] - 0s 66ms/step - loss: 3.4172 - mse: 3.4172 - val_loss: 2.0481 - val_mse: 2.0481
Epoch 194/500
2/2 [==============================] - 0s 66ms/step - loss: 3.4147 - mse: 3.4147 - val_loss: 2.0466 - val_mse: 2.0466
Epoch 195/500
2/2 [==============================] - 0s 65ms/step - loss: 3.4127 - mse: 3.4127 - val_loss: 2.0452 - val_mse: 2.0452
Epoch 196/500
2/2 [==============================] - 0s 68ms/step - loss: 3.4102 - mse: 3.4102 - val_loss: 2.0438 - val_mse: 2.0438
Epoch 197/500
2/2 [==============================] - 0s 78ms/step - loss: 3.4081 - mse: 3.4081 - val_loss: 2.0424 - val_mse: 2.0424
Epoch 198/500
2/2 [==============================] - 1s 1s/step - loss: 3.4058 - mse: 3.4058 - val_loss: 2.0410 - val_mse: 2.0410
Epoch 199/500
2/2 [==============================] - 1s 714ms/step - loss: 3.4037 - mse: 3.4037 - val_loss: 2.0396 - val_mse: 2.0396
Epoch 200/500
2/2 [==============================] - 0s 83ms/step - loss: 3.4015 - mse: 3.4015 - val_loss: 2.0382 - val_mse: 2.0382
Epoch 201/500
2/2 [==============================] - 0s 72ms/step - loss: 3.3992 - mse: 3.3992 - val_loss: 2.0368 - val_mse: 2.0368
Epoch 202/500
2/2 [==============================] - 0s 79ms/step - loss: 3.3970 - mse: 3.3970 - val_loss: 2.0354 - val_mse: 2.0354
Epoch 203/500
2/2 [==============================] - 0s 77ms/step - loss: 3.3948 - mse: 3.3948 - val_loss: 2.0340 - val_mse: 2.0340
Epoch 204/500
2/2 [==============================] - 0s 80ms/step - loss: 3.3926 - mse: 3.3926 - val_loss: 2.0326 - val_mse: 2.0326
Epoch 205/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3904 - mse: 3.3904 - val_loss: 2.0312 - val_mse: 2.0312
Epoch 206/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3882 - mse: 3.3882 - val_loss: 2.0299 - val_mse: 2.0299
Epoch 207/500
2/2 [==============================] - 1s 982ms/step - loss: 3.3862 - mse: 3.3862 - val_loss: 2.0285 - val_mse: 2.0285
Epoch 208/500
2/2 [==============================] - 0s 305ms/step - loss: 3.3839 - mse: 3.3839 - val_loss: 2.0272 - val_mse: 2.0272
Epoch 209/500
2/2 [==============================] - 0s 79ms/step - loss: 3.3816 - mse: 3.3816 - val_loss: 2.0258 - val_mse: 2.0258
Epoch 210/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3796 - mse: 3.3796 - val_loss: 2.0245 - val_mse: 2.0245
Epoch 211/500
2/2 [==============================] - 0s 67ms/step - loss: 3.3774 - mse: 3.3774 - val_loss: 2.0232 - val_mse: 2.0232
Epoch 212/500
2/2 [==============================] - 0s 68ms/step - loss: 3.3753 - mse: 3.3753 - val_loss: 2.0219 - val_mse: 2.0219
Epoch 213/500
2/2 [==============================] - 0s 67ms/step - loss: 3.3733 - mse: 3.3733 - val_loss: 2.0205 - val_mse: 2.0205
Epoch 214/500
2/2 [==============================] - 0s 69ms/step - loss: 3.3712 - mse: 3.3712 - val_loss: 2.0192 - val_mse: 2.0192
Epoch 215/500
2/2 [==============================] - 0s 69ms/step - loss: 3.3689 - mse: 3.3689 - val_loss: 2.0179 - val_mse: 2.0179
Epoch 216/500
2/2 [==============================] - 0s 71ms/step - loss: 3.3670 - mse: 3.3670 - val_loss: 2.0166 - val_mse: 2.0166
Epoch 217/500
2/2 [==============================] - 0s 72ms/step - loss: 3.3647 - mse: 3.3647 - val_loss: 2.0153 - val_mse: 2.0153
Epoch 218/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3627 - mse: 3.3627 - val_loss: 2.0140 - val_mse: 2.0140
Epoch 219/500
2/2 [==============================] - 0s 71ms/step - loss: 3.3608 - mse: 3.3608 - val_loss: 2.0127 - val_mse: 2.0127
Epoch 220/500
2/2 [==============================] - 0s 63ms/step - loss: 3.3586 - mse: 3.3586 - val_loss: 2.0114 - val_mse: 2.0114
Epoch 221/500
2/2 [==============================] - 0s 79ms/step - loss: 3.3566 - mse: 3.3566 - val_loss: 2.0102 - val_mse: 2.0102
Epoch 222/500
2/2 [==============================] - 0s 218ms/step - loss: 3.3545 - mse: 3.3545 - val_loss: 2.0089 - val_mse: 2.0089
Epoch 223/500
2/2 [==============================] - 0s 67ms/step - loss: 3.3527 - mse: 3.3527 - val_loss: 2.0076 - val_mse: 2.0076
Epoch 224/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3503 - mse: 3.3503 - val_loss: 2.0064 - val_mse: 2.0064
Epoch 225/500
2/2 [==============================] - 0s 90ms/step - loss: 3.3483 - mse: 3.3483 - val_loss: 2.0051 - val_mse: 2.0051
Epoch 226/500
2/2 [==============================] - 0s 79ms/step - loss: 3.3462 - mse: 3.3462 - val_loss: 2.0039 - val_mse: 2.0039
Epoch 227/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3444 - mse: 3.3444 - val_loss: 2.0026 - val_mse: 2.0026
Epoch 228/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3424 - mse: 3.3424 - val_loss: 2.0014 - val_mse: 2.0014
Epoch 229/500
2/2 [==============================] - 0s 67ms/step - loss: 3.3403 - mse: 3.3403 - val_loss: 2.0002 - val_mse: 2.0002
Epoch 230/500
2/2 [==============================] - 0s 72ms/step - loss: 3.3386 - mse: 3.3386 - val_loss: 1.9990 - val_mse: 1.9990
Epoch 231/500
2/2 [==============================] - 0s 343ms/step - loss: 3.3363 - mse: 3.3363 - val_loss: 1.9977 - val_mse: 1.9977
Epoch 232/500
2/2 [==============================] - 1s 696ms/step - loss: 3.3345 - mse: 3.3345 - val_loss: 1.9965 - val_mse: 1.9965
Epoch 233/500
2/2 [==============================] - 0s 83ms/step - loss: 3.3323 - mse: 3.3323 - val_loss: 1.9953 - val_mse: 1.9953
Epoch 234/500
2/2 [==============================] - 0s 67ms/step - loss: 3.3306 - mse: 3.3306 - val_loss: 1.9941 - val_mse: 1.9941
Epoch 235/500
2/2 [==============================] - 1s 725ms/step - loss: 3.3286 - mse: 3.3286 - val_loss: 1.9929 - val_mse: 1.9929
Epoch 236/500
2/2 [==============================] - 0s 79ms/step - loss: 3.3268 - mse: 3.3268 - val_loss: 1.9917 - val_mse: 1.9917
Epoch 237/500
2/2 [==============================] - 0s 65ms/step - loss: 3.3247 - mse: 3.3247 - val_loss: 1.9906 - val_mse: 1.9906
Epoch 238/500
2/2 [==============================] - 0s 70ms/step - loss: 3.3230 - mse: 3.3230 - val_loss: 1.9894 - val_mse: 1.9894
Epoch 239/500
2/2 [==============================] - 0s 75ms/step - loss: 3.3210 - mse: 3.3210 - val_loss: 1.9882 - val_mse: 1.9882
Epoch 240/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3190 - mse: 3.3190 - val_loss: 1.9870 - val_mse: 1.9870
Epoch 241/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3173 - mse: 3.3173 - val_loss: 1.9859 - val_mse: 1.9859
Epoch 242/500
2/2 [==============================] - 0s 66ms/step - loss: 3.3152 - mse: 3.3152 - val_loss: 1.9847 - val_mse: 1.9847
Epoch 243/500
2/2 [==============================] - 0s 68ms/step - loss: 3.3135 - mse: 3.3135 - val_loss: 1.9836 - val_mse: 1.9836
Epoch 244/500
2/2 [==============================] - 0s 65ms/step - loss: 3.3116 - mse: 3.3116 - val_loss: 1.9824 - val_mse: 1.9824
Epoch 245/500
2/2 [==============================] - 0s 67ms/step - loss: 3.3096 - mse: 3.3096 - val_loss: 1.9813 - val_mse: 1.9813
Epoch 246/500
2/2 [==============================] - 0s 277ms/step - loss: 3.3076 - mse: 3.3076 - val_loss: 1.9802 - val_mse: 1.9802
Epoch 247/500
2/2 [==============================] - 0s 96ms/step - loss: 3.3058 - mse: 3.3058 - val_loss: 1.9790 - val_mse: 1.9790
Epoch 248/500
2/2 [==============================] - 0s 73ms/step - loss: 3.3041 - mse: 3.3041 - val_loss: 1.9779 - val_mse: 1.9779
Epoch 249/500
2/2 [==============================] - 0s 83ms/step - loss: 3.3021 - mse: 3.3021 - val_loss: 1.9768 - val_mse: 1.9768
Epoch 250/500
2/2 [==============================] - 0s 71ms/step - loss: 3.3005 - mse: 3.3005 - val_loss: 1.9757 - val_mse: 1.9757
Epoch 251/500
2/2 [==============================] - 0s 85ms/step - loss: 3.2987 - mse: 3.2987 - val_loss: 1.9746 - val_mse: 1.9746
Epoch 252/500
2/2 [==============================] - 0s 67ms/step - loss: 3.2968 - mse: 3.2968 - val_loss: 1.9735 - val_mse: 1.9735
Epoch 253/500
2/2 [==============================] - 0s 68ms/step - loss: 3.2953 - mse: 3.2953 - val_loss: 1.9724 - val_mse: 1.9724
Epoch 254/500
2/2 [==============================] - 0s 82ms/step - loss: 3.2933 - mse: 3.2933 - val_loss: 1.9713 - val_mse: 1.9713
Epoch 255/500
2/2 [==============================] - 0s 100ms/step - loss: 3.2915 - mse: 3.2915 - val_loss: 1.9702 - val_mse: 1.9702
Epoch 256/500
2/2 [==============================] - 0s 65ms/step - loss: 3.2897 - mse: 3.2897 - val_loss: 1.9692 - val_mse: 1.9692
Epoch 257/500
2/2 [==============================] - 0s 72ms/step - loss: 3.2880 - mse: 3.2880 - val_loss: 1.9681 - val_mse: 1.9681
Epoch 258/500
2/2 [==============================] - 0s 71ms/step - loss: 3.2861 - mse: 3.2861 - val_loss: 1.9670 - val_mse: 1.9670
Epoch 259/500
2/2 [==============================] - 0s 65ms/step - loss: 3.2845 - mse: 3.2845 - val_loss: 1.9660 - val_mse: 1.9660
Epoch 260/500
2/2 [==============================] - 0s 66ms/step - loss: 3.2826 - mse: 3.2826 - val_loss: 1.9649 - val_mse: 1.9649
Epoch 261/500
2/2 [==============================] - 0s 78ms/step - loss: 3.2810 - mse: 3.2810 - val_loss: 1.9639 - val_mse: 1.9639
Epoch 262/500
2/2 [==============================] - 0s 77ms/step - loss: 3.2792 - mse: 3.2792 - val_loss: 1.9628 - val_mse: 1.9628
Epoch 263/500
2/2 [==============================] - 0s 82ms/step - loss: 3.2777 - mse: 3.2777 - val_loss: 1.9618 - val_mse: 1.9618
Epoch 264/500
2/2 [==============================] - 0s 373ms/step - loss: 3.2759 - mse: 3.2759 - val_loss: 1.9608 - val_mse: 1.9608
Epoch 265/500
2/2 [==============================] - 0s 68ms/step - loss: 3.2742 - mse: 3.2742 - val_loss: 1.9597 - val_mse: 1.9597
Epoch 266/500
2/2 [==============================] - 0s 72ms/step - loss: 3.2724 - mse: 3.2724 - val_loss: 1.9587 - val_mse: 1.9587
Epoch 267/500
2/2 [==============================] - 0s 79ms/step - loss: 3.2707 - mse: 3.2707 - val_loss: 1.9577 - val_mse: 1.9577
Epoch 268/500
2/2 [==============================] - 0s 72ms/step - loss: 3.2691 - mse: 3.2691 - val_loss: 1.9567 - val_mse: 1.9567
Epoch 269/500
2/2 [==============================] - 0s 76ms/step - loss: 3.2675 - mse: 3.2675 - val_loss: 1.9557 - val_mse: 1.9557
Epoch 270/500
2/2 [==============================] - 0s 79ms/step - loss: 3.2658 - mse: 3.2658 - val_loss: 1.9547 - val_mse: 1.9547
Epoch 271/500
2/2 [==============================] - 0s 85ms/step - loss: 3.2641 - mse: 3.2641 - val_loss: 1.9537 - val_mse: 1.9537
Epoch 272/500
2/2 [==============================] - 0s 64ms/step - loss: 3.2624 - mse: 3.2624 - val_loss: 1.9527 - val_mse: 1.9527
Epoch 273/500
2/2 [==============================] - 0s 87ms/step - loss: 3.2609 - mse: 3.2609 - val_loss: 1.9517 - val_mse: 1.9517
Epoch 274/500
2/2 [==============================] - 0s 71ms/step - loss: 3.2590 - mse: 3.2590 - val_loss: 1.9508 - val_mse: 1.9508
Epoch 275/500
2/2 [==============================] - 0s 66ms/step - loss: 3.2575 - mse: 3.2575 - val_loss: 1.9498 - val_mse: 1.9498
Epoch 276/500
2/2 [==============================] - 0s 72ms/step - loss: 3.2560 - mse: 3.2560 - val_loss: 1.9489 - val_mse: 1.9489
Epoch 277/500
2/2 [==============================] - 0s 66ms/step - loss: 3.2545 - mse: 3.2545 - val_loss: 1.9479 - val_mse: 1.9479
Epoch 278/500
2/2 [==============================] - 0s 65ms/step - loss: 3.2528 - mse: 3.2528 - val_loss: 1.9469 - val_mse: 1.9469
Epoch 279/500
2/2 [==============================] - 0s 87ms/step - loss: 3.2511 - mse: 3.2511 - val_loss: 1.9460 - val_mse: 1.9460
Epoch 280/500
2/2 [==============================] - 0s 73ms/step - loss: 3.2497 - mse: 3.2497 - val_loss: 1.9451 - val_mse: 1.9451
Epoch 281/500
2/2 [==============================] - 0s 88ms/step - loss: 3.2481 - mse: 3.2481 - val_loss: 1.9441 - val_mse: 1.9441
Epoch 282/500
2/2 [==============================] - 0s 377ms/step - loss: 3.2465 - mse: 3.2465 - val_loss: 1.9432 - val_mse: 1.9432
Epoch 283/500
2/2 [==============================] - 0s 67ms/step - loss: 3.2449 - mse: 3.2449 - val_loss: 1.9422 - val_mse: 1.9422
Epoch 284/500
2/2 [==============================] - 0s 69ms/step - loss: 3.2434 - mse: 3.2434 - val_loss: 1.9413 - val_mse: 1.9413
Epoch 285/500
2/2 [==============================] - 0s 68ms/step - loss: 3.2418 - mse: 3.2418 - val_loss: 1.9404 - val_mse: 1.9404
Epoch 286/500
2/2 [==============================] - 0s 91ms/step - loss: 3.2402 - mse: 3.2402 - val_loss: 1.9395 - val_mse: 1.9395
Epoch 287/500
2/2 [==============================] - 0s 70ms/step - loss: 3.2389 - mse: 3.2389 - val_loss: 1.9386 - val_mse: 1.9386
Epoch 288/500
2/2 [==============================] - 0s 86ms/step - loss: 3.2372 - mse: 3.2372 - val_loss: 1.9377 - val_mse: 1.9377
Epoch 289/500
2/2 [==============================] - 1s 1s/step - loss: 3.2356 - mse: 3.2356 - val_loss: 1.9368 - val_mse: 1.9368
Epoch 290/500
2/2 [==============================] - 0s 65ms/step - loss: 3.2343 - mse: 3.2343 - val_loss: 1.9359 - val_mse: 1.9359
Epoch 291/500
2/2 [==============================] - 0s 98ms/step - loss: 3.2328 - mse: 3.2328 - val_loss: 1.9350 - val_mse: 1.9350
Epoch 292/500
2/2 [==============================] - 0s 82ms/step - loss: 3.2313 - mse: 3.2313 - val_loss: 1.9341 - val_mse: 1.9341
Epoch 293/500
2/2 [==============================] - 0s 89ms/step - loss: 3.2299 - mse: 3.2299 - val_loss: 1.9332 - val_mse: 1.9332
Epoch 294/500
2/2 [==============================] - 0s 210ms/step - loss: 3.2283 - mse: 3.2283 - val_loss: 1.9324 - val_mse: 1.9324
Epoch 295/500
2/2 [==============================] - 0s 70ms/step - loss: 3.2268 - mse: 3.2268 - val_loss: 1.9315 - val_mse: 1.9315
Epoch 296/500
2/2 [==============================] - 0s 67ms/step - loss: 3.2254 - mse: 3.2254 - val_loss: 1.9307 - val_mse: 1.9307
Epoch 297/500
2/2 [==============================] - 0s 66ms/step - loss: 3.2240 - mse: 3.2240 - val_loss: 1.9298 - val_mse: 1.9298
Epoch 298/500
2/2 [==============================] - 0s 86ms/step - loss: 3.2226 - mse: 3.2226 - val_loss: 1.9289 - val_mse: 1.9289
Epoch 299/500
2/2 [==============================] - 0s 85ms/step - loss: 3.2210 - mse: 3.2210 - val_loss: 1.9281 - val_mse: 1.9281
Epoch 300/500
2/2 [==============================] - 0s 75ms/step - loss: 3.2197 - mse: 3.2197 - val_loss: 1.9272 - val_mse: 1.9272
Epoch 301/500
2/2 [==============================] - 0s 65ms/step - loss: 3.2182 - mse: 3.2182 - val_loss: 1.9264 - val_mse: 1.9264
Epoch 302/500
2/2 [==============================] - 0s 71ms/step - loss: 3.2166 - mse: 3.2166 - val_loss: 1.9256 - val_mse: 1.9256
Epoch 303/500
2/2 [==============================] - 1s 1s/step - loss: 3.2154 - mse: 3.2154 - val_loss: 1.9247 - val_mse: 1.9247
Epoch 304/500
2/2 [==============================] - 0s 83ms/step - loss: 3.2142 - mse: 3.2142 - val_loss: 1.9239 - val_mse: 1.9239
Epoch 305/500
2/2 [==============================] - 0s 80ms/step - loss: 3.2126 - mse: 3.2126 - val_loss: 1.9231 - val_mse: 1.9231
Epoch 306/500
2/2 [==============================] - 0s 67ms/step - loss: 3.2111 - mse: 3.2111 - val_loss: 1.9223 - val_mse: 1.9223
Epoch 307/500
2/2 [==============================] - 0s 67ms/step - loss: 3.2099 - mse: 3.2099 - val_loss: 1.9215 - val_mse: 1.9215
Epoch 308/500
2/2 [==============================] - 0s 71ms/step - loss: 3.2084 - mse: 3.2084 - val_loss: 1.9207 - val_mse: 1.9207
Epoch 309/500
2/2 [==============================] - 0s 82ms/step - loss: 3.2071 - mse: 3.2071 - val_loss: 1.9199 - val_mse: 1.9199
Epoch 310/500
2/2 [==============================] - 1s 868ms/step - loss: 3.2057 - mse: 3.2057 - val_loss: 1.9191 - val_mse: 1.9191
Epoch 311/500
2/2 [==============================] - 0s 309ms/step - loss: 3.2044 - mse: 3.2044 - val_loss: 1.9183 - val_mse: 1.9183
Epoch 312/500
2/2 [==============================] - 1s 75ms/step - loss: 3.2032 - mse: 3.2032 - val_loss: 1.9175 - val_mse: 1.9175
Epoch 313/500
2/2 [==============================] - 0s 88ms/step - loss: 3.2017 - mse: 3.2017 - val_loss: 1.9167 - val_mse: 1.9167
Epoch 314/500
2/2 [==============================] - 0s 67ms/step - loss: 3.2003 - mse: 3.2003 - val_loss: 1.9159 - val_mse: 1.9159
Epoch 315/500
2/2 [==============================] - 0s 73ms/step - loss: 3.1990 - mse: 3.1990 - val_loss: 1.9152 - val_mse: 1.9152
Epoch 316/500
2/2 [==============================] - 0s 67ms/step - loss: 3.1977 - mse: 3.1977 - val_loss: 1.9144 - val_mse: 1.9144
Epoch 317/500
2/2 [==============================] - 0s 88ms/step - loss: 3.1965 - mse: 3.1965 - val_loss: 1.9136 - val_mse: 1.9136
Epoch 318/500
2/2 [==============================] - 0s 67ms/step - loss: 3.1952 - mse: 3.1952 - val_loss: 1.9129 - val_mse: 1.9129
Epoch 319/500
2/2 [==============================] - 0s 93ms/step - loss: 3.1938 - mse: 3.1938 - val_loss: 1.9121 - val_mse: 1.9121
Epoch 320/500
2/2 [==============================] - 1s 838ms/step - loss: 3.1925 - mse: 3.1925 - val_loss: 1.9114 - val_mse: 1.9114
Epoch 321/500
2/2 [==============================] - 0s 353ms/step - loss: 3.1914 - mse: 3.1914 - val_loss: 1.9106 - val_mse: 1.9106
Epoch 322/500
2/2 [==============================] - 0s 79ms/step - loss: 3.1900 - mse: 3.1900 - val_loss: 1.9099 - val_mse: 1.9099
Epoch 323/500
2/2 [==============================] - 0s 83ms/step - loss: 3.1888 - mse: 3.1888 - val_loss: 1.9092 - val_mse: 1.9092
Epoch 324/500
2/2 [==============================] - 0s 67ms/step - loss: 3.1876 - mse: 3.1876 - val_loss: 1.9084 - val_mse: 1.9084
Epoch 325/500
2/2 [==============================] - 0s 85ms/step - loss: 3.1862 - mse: 3.1862 - val_loss: 1.9077 - val_mse: 1.9077
Epoch 326/500
2/2 [==============================] - 0s 323ms/step - loss: 3.1850 - mse: 3.1850 - val_loss: 1.9070 - val_mse: 1.9070
Epoch 327/500
2/2 [==============================] - 1s 654ms/step - loss: 3.1838 - mse: 3.1838 - val_loss: 1.9062 - val_mse: 1.9062
Epoch 328/500
2/2 [==============================] - 0s 99ms/step - loss: 3.1824 - mse: 3.1824 - val_loss: 1.9055 - val_mse: 1.9055
Epoch 329/500
2/2 [==============================] - 0s 96ms/step - loss: 3.1814 - mse: 3.1814 - val_loss: 1.9048 - val_mse: 1.9048
Epoch 330/500
2/2 [==============================] - 0s 80ms/step - loss: 3.1802 - mse: 3.1802 - val_loss: 1.9041 - val_mse: 1.9041
Epoch 331/500
2/2 [==============================] - 0s 81ms/step - loss: 3.1788 - mse: 3.1788 - val_loss: 1.9034 - val_mse: 1.9034
Epoch 332/500
2/2 [==============================] - 0s 70ms/step - loss: 3.1777 - mse: 3.1777 - val_loss: 1.9027 - val_mse: 1.9027
Epoch 333/500
2/2 [==============================] - 0s 67ms/step - loss: 3.1765 - mse: 3.1765 - val_loss: 1.9020 - val_mse: 1.9020
Epoch 334/500
2/2 [==============================] - 0s 66ms/step - loss: 3.1753 - mse: 3.1753 - val_loss: 1.9013 - val_mse: 1.9013
Epoch 335/500
2/2 [==============================] - 0s 82ms/step - loss: 3.1739 - mse: 3.1739 - val_loss: 1.9006 - val_mse: 1.9006
Epoch 336/500
2/2 [==============================] - 0s 353ms/step - loss: 3.1730 - mse: 3.1730 - val_loss: 1.8999 - val_mse: 1.8999
Epoch 337/500
2/2 [==============================] - 0s 70ms/step - loss: 3.1717 - mse: 3.1717 - val_loss: 1.8993 - val_mse: 1.8993
Epoch 338/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1706 - mse: 3.1706 - val_loss: 1.8986 - val_mse: 1.8986
Epoch 339/500
2/2 [==============================] - 0s 67ms/step - loss: 3.1695 - mse: 3.1695 - val_loss: 1.8979 - val_mse: 1.8979
Epoch 340/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1682 - mse: 3.1682 - val_loss: 1.8973 - val_mse: 1.8973
Epoch 341/500
2/2 [==============================] - 0s 355ms/step - loss: 3.1672 - mse: 3.1672 - val_loss: 1.8966 - val_mse: 1.8966
Epoch 342/500
2/2 [==============================] - 0s 76ms/step - loss: 3.1659 - mse: 3.1659 - val_loss: 1.8959 - val_mse: 1.8959
Epoch 343/500
2/2 [==============================] - 0s 73ms/step - loss: 3.1647 - mse: 3.1647 - val_loss: 1.8953 - val_mse: 1.8953
Epoch 344/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1637 - mse: 3.1637 - val_loss: 1.8946 - val_mse: 1.8946
Epoch 345/500
2/2 [==============================] - 0s 82ms/step - loss: 3.1626 - mse: 3.1626 - val_loss: 1.8940 - val_mse: 1.8940
Epoch 346/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1614 - mse: 3.1614 - val_loss: 1.8933 - val_mse: 1.8933
Epoch 347/500
2/2 [==============================] - 0s 69ms/step - loss: 3.1603 - mse: 3.1603 - val_loss: 1.8927 - val_mse: 1.8927
Epoch 348/500
2/2 [==============================] - 0s 95ms/step - loss: 3.1592 - mse: 3.1592 - val_loss: 1.8921 - val_mse: 1.8921
Epoch 349/500
2/2 [==============================] - 0s 67ms/step - loss: 3.1581 - mse: 3.1581 - val_loss: 1.8914 - val_mse: 1.8914
Epoch 350/500
2/2 [==============================] - 0s 69ms/step - loss: 3.1570 - mse: 3.1570 - val_loss: 1.8908 - val_mse: 1.8908
Epoch 351/500
2/2 [==============================] - 0s 67ms/step - loss: 3.1559 - mse: 3.1559 - val_loss: 1.8902 - val_mse: 1.8902
Epoch 352/500
2/2 [==============================] - 0s 84ms/step - loss: 3.1548 - mse: 3.1548 - val_loss: 1.8896 - val_mse: 1.8896
Epoch 353/500
2/2 [==============================] - 0s 107ms/step - loss: 3.1538 - mse: 3.1538 - val_loss: 1.8889 - val_mse: 1.8889
Epoch 354/500
2/2 [==============================] - 0s 370ms/step - loss: 3.1527 - mse: 3.1527 - val_loss: 1.8883 - val_mse: 1.8883
Epoch 355/500
2/2 [==============================] - 0s 73ms/step - loss: 3.1516 - mse: 3.1516 - val_loss: 1.8877 - val_mse: 1.8877
Epoch 356/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1505 - mse: 3.1505 - val_loss: 1.8871 - val_mse: 1.8871
Epoch 357/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1495 - mse: 3.1495 - val_loss: 1.8865 - val_mse: 1.8865
Epoch 358/500
2/2 [==============================] - 0s 80ms/step - loss: 3.1484 - mse: 3.1484 - val_loss: 1.8859 - val_mse: 1.8859
Epoch 359/500
2/2 [==============================] - 0s 83ms/step - loss: 3.1475 - mse: 3.1475 - val_loss: 1.8853 - val_mse: 1.8853
Epoch 360/500
2/2 [==============================] - 0s 82ms/step - loss: 3.1463 - mse: 3.1463 - val_loss: 1.8847 - val_mse: 1.8847
Epoch 361/500
2/2 [==============================] - 0s 297ms/step - loss: 3.1453 - mse: 3.1453 - val_loss: 1.8842 - val_mse: 1.8842
Epoch 362/500
2/2 [==============================] - 0s 86ms/step - loss: 3.1443 - mse: 3.1443 - val_loss: 1.8836 - val_mse: 1.8836
Epoch 363/500
2/2 [==============================] - 0s 81ms/step - loss: 3.1433 - mse: 3.1433 - val_loss: 1.8830 - val_mse: 1.8830
Epoch 364/500
2/2 [==============================] - 0s 69ms/step - loss: 3.1424 - mse: 3.1424 - val_loss: 1.8824 - val_mse: 1.8824
Epoch 365/500
2/2 [==============================] - 0s 82ms/step - loss: 3.1414 - mse: 3.1414 - val_loss: 1.8818 - val_mse: 1.8818
Epoch 366/500
2/2 [==============================] - 1s 890ms/step - loss: 3.1403 - mse: 3.1403 - val_loss: 1.8813 - val_mse: 1.8813
Epoch 367/500
2/2 [==============================] - 0s 99ms/step - loss: 3.1393 - mse: 3.1393 - val_loss: 1.8807 - val_mse: 1.8807
Epoch 368/500
2/2 [==============================] - 0s 71ms/step - loss: 3.1383 - mse: 3.1383 - val_loss: 1.8801 - val_mse: 1.8801
Epoch 369/500
2/2 [==============================] - 0s 81ms/step - loss: 3.1373 - mse: 3.1373 - val_loss: 1.8796 - val_mse: 1.8796
Epoch 370/500
2/2 [==============================] - 0s 73ms/step - loss: 3.1364 - mse: 3.1364 - val_loss: 1.8790 - val_mse: 1.8790
Epoch 371/500
2/2 [==============================] - 0s 241ms/step - loss: 3.1354 - mse: 3.1354 - val_loss: 1.8784 - val_mse: 1.8784
Epoch 372/500
2/2 [==============================] - 0s 71ms/step - loss: 3.1344 - mse: 3.1344 - val_loss: 1.8779 - val_mse: 1.8779
Epoch 373/500
2/2 [==============================] - 1s 743ms/step - loss: 3.1333 - mse: 3.1333 - val_loss: 1.8773 - val_mse: 1.8773
Epoch 374/500
2/2 [==============================] - 0s 71ms/step - loss: 3.1324 - mse: 3.1324 - val_loss: 1.8768 - val_mse: 1.8768
Epoch 375/500
2/2 [==============================] - 0s 70ms/step - loss: 3.1315 - mse: 3.1315 - val_loss: 1.8763 - val_mse: 1.8763
Epoch 376/500
2/2 [==============================] - 0s 92ms/step - loss: 3.1305 - mse: 3.1305 - val_loss: 1.8757 - val_mse: 1.8757
Epoch 377/500
2/2 [==============================] - 0s 78ms/step - loss: 3.1296 - mse: 3.1296 - val_loss: 1.8752 - val_mse: 1.8752
Epoch 378/500
2/2 [==============================] - 0s 71ms/step - loss: 3.1287 - mse: 3.1287 - val_loss: 1.8747 - val_mse: 1.8747
Epoch 379/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1278 - mse: 3.1278 - val_loss: 1.8741 - val_mse: 1.8741
Epoch 380/500
2/2 [==============================] - 0s 90ms/step - loss: 3.1267 - mse: 3.1267 - val_loss: 1.8736 - val_mse: 1.8736
Epoch 381/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1260 - mse: 3.1260 - val_loss: 1.8731 - val_mse: 1.8731
Epoch 382/500
2/2 [==============================] - 1s 722ms/step - loss: 3.1250 - mse: 3.1250 - val_loss: 1.8726 - val_mse: 1.8726
Epoch 383/500
2/2 [==============================] - 0s 70ms/step - loss: 3.1240 - mse: 3.1240 - val_loss: 1.8720 - val_mse: 1.8720
Epoch 384/500
2/2 [==============================] - 0s 84ms/step - loss: 3.1231 - mse: 3.1231 - val_loss: 1.8715 - val_mse: 1.8715
Epoch 385/500
2/2 [==============================] - 0s 94ms/step - loss: 3.1222 - mse: 3.1222 - val_loss: 1.8710 - val_mse: 1.8710
Epoch 386/500
2/2 [==============================] - 0s 79ms/step - loss: 3.1212 - mse: 3.1212 - val_loss: 1.8705 - val_mse: 1.8705
Epoch 387/500
2/2 [==============================] - 0s 87ms/step - loss: 3.1204 - mse: 3.1204 - val_loss: 1.8700 - val_mse: 1.8700
Epoch 388/500
2/2 [==============================] - 0s 79ms/step - loss: 3.1196 - mse: 3.1196 - val_loss: 1.8695 - val_mse: 1.8695
Epoch 389/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1186 - mse: 3.1186 - val_loss: 1.8690 - val_mse: 1.8690
Epoch 390/500
2/2 [==============================] - 1s 612ms/step - loss: 3.1178 - mse: 3.1178 - val_loss: 1.8685 - val_mse: 1.8685
Epoch 391/500
2/2 [==============================] - 0s 82ms/step - loss: 3.1169 - mse: 3.1169 - val_loss: 1.8680 - val_mse: 1.8680
Epoch 392/500
2/2 [==============================] - 0s 86ms/step - loss: 3.1161 - mse: 3.1161 - val_loss: 1.8675 - val_mse: 1.8675
Epoch 393/500
2/2 [==============================] - 0s 78ms/step - loss: 3.1152 - mse: 3.1152 - val_loss: 1.8670 - val_mse: 1.8670
Epoch 394/500
2/2 [==============================] - 0s 72ms/step - loss: 3.1143 - mse: 3.1143 - val_loss: 1.8666 - val_mse: 1.8666
Epoch 395/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1135 - mse: 3.1135 - val_loss: 1.8661 - val_mse: 1.8661
Epoch 396/500
2/2 [==============================] - 0s 88ms/step - loss: 3.1125 - mse: 3.1125 - val_loss: 1.8656 - val_mse: 1.8656
Epoch 397/500
2/2 [==============================] - 1s 882ms/step - loss: 3.1117 - mse: 3.1117 - val_loss: 1.8651 - val_mse: 1.8651
Epoch 398/500
2/2 [==============================] - 0s 328ms/step - loss: 3.1109 - mse: 3.1109 - val_loss: 1.8647 - val_mse: 1.8647
Epoch 399/500
2/2 [==============================] - 1s 80ms/step - loss: 3.1101 - mse: 3.1101 - val_loss: 1.8642 - val_mse: 1.8642
Epoch 400/500
2/2 [==============================] - 0s 70ms/step - loss: 3.1092 - mse: 3.1092 - val_loss: 1.8637 - val_mse: 1.8637
Epoch 401/500
2/2 [==============================] - 1s 681ms/step - loss: 3.1084 - mse: 3.1084 - val_loss: 1.8633 - val_mse: 1.8633
Epoch 402/500
2/2 [==============================] - 0s 79ms/step - loss: 3.1076 - mse: 3.1076 - val_loss: 1.8628 - val_mse: 1.8628
Epoch 403/500
2/2 [==============================] - 0s 79ms/step - loss: 3.1068 - mse: 3.1068 - val_loss: 1.8623 - val_mse: 1.8623
Epoch 404/500
2/2 [==============================] - 1s 675ms/step - loss: 3.1060 - mse: 3.1060 - val_loss: 1.8619 - val_mse: 1.8619
Epoch 405/500
2/2 [==============================] - 0s 88ms/step - loss: 3.1051 - mse: 3.1051 - val_loss: 1.8614 - val_mse: 1.8614
Epoch 406/500
2/2 [==============================] - 0s 81ms/step - loss: 3.1043 - mse: 3.1043 - val_loss: 1.8610 - val_mse: 1.8610
Epoch 407/500
2/2 [==============================] - 0s 74ms/step - loss: 3.1035 - mse: 3.1035 - val_loss: 1.8605 - val_mse: 1.8605
Epoch 408/500
2/2 [==============================] - 0s 77ms/step - loss: 3.1028 - mse: 3.1028 - val_loss: 1.8601 - val_mse: 1.8601
Epoch 409/500
2/2 [==============================] - 0s 68ms/step - loss: 3.1019 - mse: 3.1019 - val_loss: 1.8596 - val_mse: 1.8596
Epoch 410/500
2/2 [==============================] - 0s 82ms/step - loss: 3.1011 - mse: 3.1011 - val_loss: 1.8592 - val_mse: 1.8592
Epoch 411/500
2/2 [==============================] - 0s 86ms/step - loss: 3.1003 - mse: 3.1003 - val_loss: 1.8588 - val_mse: 1.8588
Epoch 412/500
2/2 [==============================] - 0s 90ms/step - loss: 3.0996 - mse: 3.0996 - val_loss: 1.8583 - val_mse: 1.8583
Epoch 413/500
2/2 [==============================] - 1s 683ms/step - loss: 3.0988 - mse: 3.0988 - val_loss: 1.8579 - val_mse: 1.8579
Epoch 414/500
2/2 [==============================] - 0s 72ms/step - loss: 3.0981 - mse: 3.0981 - val_loss: 1.8575 - val_mse: 1.8575
Epoch 415/500
2/2 [==============================] - 0s 80ms/step - loss: 3.0973 - mse: 3.0973 - val_loss: 1.8570 - val_mse: 1.8570
Epoch 416/500
2/2 [==============================] - 0s 71ms/step - loss: 3.0965 - mse: 3.0965 - val_loss: 1.8566 - val_mse: 1.8566
Epoch 417/500
2/2 [==============================] - 0s 76ms/step - loss: 3.0958 - mse: 3.0958 - val_loss: 1.8562 - val_mse: 1.8562
Epoch 418/500
2/2 [==============================] - 0s 72ms/step - loss: 3.0950 - mse: 3.0950 - val_loss: 1.8558 - val_mse: 1.8558
Epoch 419/500
2/2 [==============================] - 0s 69ms/step - loss: 3.0943 - mse: 3.0943 - val_loss: 1.8554 - val_mse: 1.8554
Epoch 420/500
2/2 [==============================] - 0s 353ms/step - loss: 3.0935 - mse: 3.0935 - val_loss: 1.8549 - val_mse: 1.8549
Epoch 421/500
2/2 [==============================] - 0s 78ms/step - loss: 3.0927 - mse: 3.0927 - val_loss: 1.8545 - val_mse: 1.8545
Epoch 422/500
2/2 [==============================] - 0s 70ms/step - loss: 3.0920 - mse: 3.0920 - val_loss: 1.8541 - val_mse: 1.8541
Epoch 423/500
2/2 [==============================] - 0s 73ms/step - loss: 3.0913 - mse: 3.0913 - val_loss: 1.8537 - val_mse: 1.8537
Epoch 424/500
2/2 [==============================] - 0s 67ms/step - loss: 3.0905 - mse: 3.0905 - val_loss: 1.8533 - val_mse: 1.8533
Epoch 425/500
2/2 [==============================] - 0s 69ms/step - loss: 3.0898 - mse: 3.0898 - val_loss: 1.8529 - val_mse: 1.8529
Epoch 426/500
2/2 [==============================] - 0s 82ms/step - loss: 3.0891 - mse: 3.0891 - val_loss: 1.8525 - val_mse: 1.8525
Epoch 427/500
2/2 [==============================] - 0s 278ms/step - loss: 3.0884 - mse: 3.0884 - val_loss: 1.8521 - val_mse: 1.8521
Epoch 428/500
2/2 [==============================] - 0s 81ms/step - loss: 3.0876 - mse: 3.0876 - val_loss: 1.8517 - val_mse: 1.8517
Epoch 429/500
2/2 [==============================] - 0s 87ms/step - loss: 3.0869 - mse: 3.0869 - val_loss: 1.8513 - val_mse: 1.8513
Epoch 430/500
2/2 [==============================] - 0s 84ms/step - loss: 3.0863 - mse: 3.0863 - val_loss: 1.8509 - val_mse: 1.8509
Epoch 431/500
2/2 [==============================] - 0s 89ms/step - loss: 3.0856 - mse: 3.0856 - val_loss: 1.8505 - val_mse: 1.8505
Epoch 432/500
2/2 [==============================] - 0s 76ms/step - loss: 3.0849 - mse: 3.0849 - val_loss: 1.8501 - val_mse: 1.8501
Epoch 433/500
2/2 [==============================] - 0s 267ms/step - loss: 3.0841 - mse: 3.0841 - val_loss: 1.8498 - val_mse: 1.8498
Epoch 434/500
2/2 [==============================] - 0s 83ms/step - loss: 3.0834 - mse: 3.0834 - val_loss: 1.8494 - val_mse: 1.8494
Epoch 435/500
2/2 [==============================] - 0s 88ms/step - loss: 3.0828 - mse: 3.0828 - val_loss: 1.8490 - val_mse: 1.8490
Epoch 436/500
2/2 [==============================] - 0s 83ms/step - loss: 3.0820 - mse: 3.0820 - val_loss: 1.8486 - val_mse: 1.8486
Epoch 437/500
2/2 [==============================] - 0s 102ms/step - loss: 3.0814 - mse: 3.0814 - val_loss: 1.8483 - val_mse: 1.8483
Epoch 438/500
2/2 [==============================] - 0s 96ms/step - loss: 3.0807 - mse: 3.0807 - val_loss: 1.8479 - val_mse: 1.8479
Epoch 439/500
2/2 [==============================] - 0s 409ms/step - loss: 3.0801 - mse: 3.0801 - val_loss: 1.8475 - val_mse: 1.8475
Epoch 440/500
2/2 [==============================] - 0s 74ms/step - loss: 3.0793 - mse: 3.0793 - val_loss: 1.8471 - val_mse: 1.8471
Epoch 441/500
2/2 [==============================] - 0s 88ms/step - loss: 3.0787 - mse: 3.0787 - val_loss: 1.8468 - val_mse: 1.8468
Epoch 442/500
2/2 [==============================] - 0s 83ms/step - loss: 3.0780 - mse: 3.0780 - val_loss: 1.8464 - val_mse: 1.8464
Epoch 443/500
2/2 [==============================] - 0s 100ms/step - loss: 3.0773 - mse: 3.0773 - val_loss: 1.8461 - val_mse: 1.8461
Epoch 444/500
2/2 [==============================] - 0s 86ms/step - loss: 3.0768 - mse: 3.0768 - val_loss: 1.8457 - val_mse: 1.8457
Epoch 445/500
2/2 [==============================] - 0s 88ms/step - loss: 3.0760 - mse: 3.0760 - val_loss: 1.8453 - val_mse: 1.8453
Epoch 446/500
2/2 [==============================] - 0s 71ms/step - loss: 3.0755 - mse: 3.0755 - val_loss: 1.8450 - val_mse: 1.8450
Epoch 447/500
2/2 [==============================] - 0s 92ms/step - loss: 3.0748 - mse: 3.0748 - val_loss: 1.8446 - val_mse: 1.8446
Epoch 448/500
2/2 [==============================] - 0s 79ms/step - loss: 3.0742 - mse: 3.0742 - val_loss: 1.8443 - val_mse: 1.8443
Epoch 449/500
2/2 [==============================] - 0s 69ms/step - loss: 3.0735 - mse: 3.0735 - val_loss: 1.8439 - val_mse: 1.8439
Epoch 450/500
2/2 [==============================] - 0s 351ms/step - loss: 3.0729 - mse: 3.0729 - val_loss: 1.8436 - val_mse: 1.8436
Epoch 451/500
2/2 [==============================] - 0s 69ms/step - loss: 3.0722 - mse: 3.0722 - val_loss: 1.8432 - val_mse: 1.8432
Epoch 452/500
2/2 [==============================] - 0s 69ms/step - loss: 3.0716 - mse: 3.0716 - val_loss: 1.8429 - val_mse: 1.8429
Epoch 453/500
2/2 [==============================] - 0s 67ms/step - loss: 3.0710 - mse: 3.0710 - val_loss: 1.8425 - val_mse: 1.8425
Epoch 454/500
2/2 [==============================] - 0s 76ms/step - loss: 3.0704 - mse: 3.0704 - val_loss: 1.8422 - val_mse: 1.8422
Epoch 455/500
2/2 [==============================] - 0s 235ms/step - loss: 3.0697 - mse: 3.0697 - val_loss: 1.8418 - val_mse: 1.8418
Epoch 456/500
2/2 [==============================] - 0s 70ms/step - loss: 3.0691 - mse: 3.0691 - val_loss: 1.8415 - val_mse: 1.8415
Epoch 457/500
2/2 [==============================] - 0s 87ms/step - loss: 3.0685 - mse: 3.0685 - val_loss: 1.8412 - val_mse: 1.8412
Epoch 458/500
2/2 [==============================] - 0s 92ms/step - loss: 3.0680 - mse: 3.0680 - val_loss: 1.8408 - val_mse: 1.8408
Epoch 459/500
2/2 [==============================] - 0s 73ms/step - loss: 3.0673 - mse: 3.0673 - val_loss: 1.8405 - val_mse: 1.8405
Epoch 460/500
2/2 [==============================] - 0s 74ms/step - loss: 3.0666 - mse: 3.0666 - val_loss: 1.8402 - val_mse: 1.8402
Epoch 461/500
2/2 [==============================] - 0s 71ms/step - loss: 3.0660 - mse: 3.0660 - val_loss: 1.8399 - val_mse: 1.8399
Epoch 462/500
2/2 [==============================] - 0s 84ms/step - loss: 3.0655 - mse: 3.0655 - val_loss: 1.8395 - val_mse: 1.8395
Epoch 463/500
2/2 [==============================] - 0s 381ms/step - loss: 3.0649 - mse: 3.0649 - val_loss: 1.8392 - val_mse: 1.8392
Epoch 464/500
2/2 [==============================] - 0s 70ms/step - loss: 3.0643 - mse: 3.0643 - val_loss: 1.8389 - val_mse: 1.8389
Epoch 465/500
2/2 [==============================] - 0s 86ms/step - loss: 3.0638 - mse: 3.0638 - val_loss: 1.8386 - val_mse: 1.8386
Epoch 466/500
2/2 [==============================] - 0s 89ms/step - loss: 3.0632 - mse: 3.0632 - val_loss: 1.8382 - val_mse: 1.8382
Epoch 467/500
2/2 [==============================] - 0s 93ms/step - loss: 3.0625 - mse: 3.0625 - val_loss: 1.8379 - val_mse: 1.8379
Epoch 468/500
2/2 [==============================] - 0s 93ms/step - loss: 3.0619 - mse: 3.0619 - val_loss: 1.8376 - val_mse: 1.8376
Epoch 469/500
2/2 [==============================] - 0s 71ms/step - loss: 3.0614 - mse: 3.0614 - val_loss: 1.8373 - val_mse: 1.8373
Epoch 470/500
2/2 [==============================] - 0s 71ms/step - loss: 3.0608 - mse: 3.0608 - val_loss: 1.8370 - val_mse: 1.8370
Epoch 471/500
2/2 [==============================] - 0s 72ms/step - loss: 3.0603 - mse: 3.0603 - val_loss: 1.8367 - val_mse: 1.8367
Epoch 472/500
2/2 [==============================] - 0s 98ms/step - loss: 3.0598 - mse: 3.0598 - val_loss: 1.8364 - val_mse: 1.8364
Epoch 473/500
2/2 [==============================] - 0s 71ms/step - loss: 3.0591 - mse: 3.0591 - val_loss: 1.8361 - val_mse: 1.8361
Epoch 474/500
2/2 [==============================] - 0s 70ms/step - loss: 3.0586 - mse: 3.0586 - val_loss: 1.8358 - val_mse: 1.8358
Epoch 475/500
2/2 [==============================] - 0s 93ms/step - loss: 3.0580 - mse: 3.0580 - val_loss: 1.8355 - val_mse: 1.8355
Epoch 476/500
2/2 [==============================] - 0s 68ms/step - loss: 3.0575 - mse: 3.0575 - val_loss: 1.8352 - val_mse: 1.8352
Epoch 477/500
2/2 [==============================] - 0s 82ms/step - loss: 3.0569 - mse: 3.0569 - val_loss: 1.8349 - val_mse: 1.8349
Epoch 478/500
2/2 [==============================] - 0s 99ms/step - loss: 3.0564 - mse: 3.0564 - val_loss: 1.8346 - val_mse: 1.8346
Epoch 479/500
2/2 [==============================] - 0s 88ms/step - loss: 3.0558 - mse: 3.0558 - val_loss: 1.8343 - val_mse: 1.8343
Epoch 480/500
2/2 [==============================] - 0s 70ms/step - loss: 3.0553 - mse: 3.0553 - val_loss: 1.8340 - val_mse: 1.8340
Epoch 481/500
2/2 [==============================] - 0s 70ms/step - loss: 3.0547 - mse: 3.0547 - val_loss: 1.8337 - val_mse: 1.8337
Epoch 482/500
2/2 [==============================] - 0s 86ms/step - loss: 3.0542 - mse: 3.0542 - val_loss: 1.8334 - val_mse: 1.8334
Epoch 483/500
2/2 [==============================] - 0s 99ms/step - loss: 3.0537 - mse: 3.0537 - val_loss: 1.8331 - val_mse: 1.8331
Epoch 484/500
2/2 [==============================] - 0s 85ms/step - loss: 3.0532 - mse: 3.0532 - val_loss: 1.8328 - val_mse: 1.8328
Epoch 485/500
2/2 [==============================] - 0s 85ms/step - loss: 3.0526 - mse: 3.0526 - val_loss: 1.8325 - val_mse: 1.8325
Epoch 486/500
2/2 [==============================] - 0s 82ms/step - loss: 3.0521 - mse: 3.0521 - val_loss: 1.8322 - val_mse: 1.8322
Epoch 487/500
2/2 [==============================] - 0s 75ms/step - loss: 3.0516 - mse: 3.0516 - val_loss: 1.8320 - val_mse: 1.8320
Epoch 488/500
2/2 [==============================] - 0s 68ms/step - loss: 3.0511 - mse: 3.0511 - val_loss: 1.8317 - val_mse: 1.8317
Epoch 489/500
2/2 [==============================] - 0s 395ms/step - loss: 3.0506 - mse: 3.0506 - val_loss: 1.8314 - val_mse: 1.8314
Epoch 490/500
2/2 [==============================] - 0s 76ms/step - loss: 3.0500 - mse: 3.0500 - val_loss: 1.8311 - val_mse: 1.8311
Epoch 491/500
2/2 [==============================] - 0s 69ms/step - loss: 3.0496 - mse: 3.0496 - val_loss: 1.8308 - val_mse: 1.8308
Epoch 492/500
2/2 [==============================] - 0s 71ms/step - loss: 3.0490 - mse: 3.0490 - val_loss: 1.8306 - val_mse: 1.8306
Epoch 493/500
2/2 [==============================] - 0s 69ms/step - loss: 3.0485 - mse: 3.0485 - val_loss: 1.8303 - val_mse: 1.8303
Epoch 494/500
2/2 [==============================] - 0s 91ms/step - loss: 3.0480 - mse: 3.0480 - val_loss: 1.8300 - val_mse: 1.8300
Epoch 495/500
2/2 [==============================] - 0s 91ms/step - loss: 3.0475 - mse: 3.0475 - val_loss: 1.8297 - val_mse: 1.8297
Epoch 496/500
2/2 [==============================] - 0s 327ms/step - loss: 3.0470 - mse: 3.0470 - val_loss: 1.8295 - val_mse: 1.8295
Epoch 497/500
2/2 [==============================] - 0s 88ms/step - loss: 3.0465 - mse: 3.0465 - val_loss: 1.8292 - val_mse: 1.8292
Epoch 498/500
2/2 [==============================] - 0s 70ms/step - loss: 3.0460 - mse: 3.0460 - val_loss: 1.8290 - val_mse: 1.8290
Epoch 499/500
2/2 [==============================] - 0s 74ms/step - loss: 3.0455 - mse: 3.0455 - val_loss: 1.8287 - val_mse: 1.8287
Epoch 500/500
2/2 [==============================] - 0s 86ms/step - loss: 3.0450 - mse: 3.0450 - val_loss: 1.8284 - val_mse: 1.8284
Model MSE: 1.8284213542938232
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="4.-Classification">4. Classification<a class="anchor-link" href="#4.-Classification">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.1.-Pore-Count">4.1. Pore Count<a class="anchor-link" href="#4.1.-Pore-Count">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Specifying the response and converting it to 0,1 type</span>
<span class="n">y_class_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">72</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">72</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">y_target_count</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&lt;=</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">y_target_count</span><span class="p">):</span>
    <span class="n">y_class_count</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">else</span><span class="p">:</span> 
    <span class="n">y_class_count</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.1.1.-Combined">4.1.1. Combined<a class="anchor-link" href="#4.1.1.-Combined">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># CNN Model Architecture - Printing and Milling combined cycles</span>

<span class="n">NUMPY_INPUT_DATA</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_COMBINED</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


<span class="n">X_train_class</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">],:,:,:]</span>
<span class="n">y_train_class_count</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]]</span>
<span class="n">X_test_class</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test_class_count</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>


<span class="c1"># Define the K-fold Cross Validator</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># K-fold Cross Validation model evaluation</span>
<span class="n">fold_no</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">train_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train_class</span><span class="p">,</span> <span class="n">y_train_class_count</span><span class="p">):</span>
    
    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Define the model architecture</span>
    <span class="k">while</span><span class="p">(</span><span class="n">train_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">val_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">test_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="c1"># model.add(Conv2D(128, (3, 3), activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;, padding=&#39;same&#39;))</span>
        <span class="c1"># model.add(MaxPooling2D((2, 2)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
        <span class="c1"># Compile the model</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
        <span class="c1"># Generate a print</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Training for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>

        <span class="c1"># Fit data to model</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_class</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_class_count</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1">#train_acc_per_fold.append(history.history[&#39;accuracy&#39;])</span>
        <span class="c1">#train_loss_per_fold.append(history.history[&#39;loss&#39;])</span>
        <span class="c1">#summarize_diagnostics(fold_no, history)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;porosity_bin_model_fold_no_&#39;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">fold_no</span><span class="p">)</span> <span class="o">+</span><span class="s1">&#39;.h5&#39;</span><span class="p">)</span>
    
        <span class="c1"># Generate generalization metrics</span>
        <span class="n">train_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_class</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_class_count</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">val_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_class</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">y_train_class_count</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Val Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_class</span><span class="p">,</span> <span class="n">y_test_class_count</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_class</span><span class="p">),</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test data Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Increase fold number</span>
    <span class="n">fold_no</span> <span class="o">=</span> <span class="n">fold_no</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">train_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">val_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">test_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">test_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(SGD, self).__init__(name, **kwargs)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.1551690250635147; accuracy of 100.0%
Val Score for fold 1: loss of 0.8690500855445862; accuracy of 50.0%
Test data Score for fold 1: loss of 0.5195515751838684; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6916408538818359; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.706336498260498; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6934778094291687; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6337924599647522; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.8272218704223633; accuracy of 25.0%
Test data Score for fold 2: loss of 0.713830292224884; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.18952901661396027; accuracy of 96.42857313156128%
Val Score for fold 2: loss of 1.2456663846969604; accuracy of 50.0%
Test data Score for fold 2: loss of 0.7110634446144104; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 3 ...
Train Score for fold 3: loss of 0.06782612204551697; accuracy of 100.0%
Val Score for fold 3: loss of 1.3853983879089355; accuracy of 50.0%
Test data Score for fold 3: loss of 1.0271832942962646; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.6931697726249695; accuracy of 50.0%
Val Score for fold 4: loss of 0.6931698322296143; accuracy of 50.0%
Test data Score for fold 4: loss of 0.6931698322296143; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.1342322677373886; accuracy of 100.0%
Val Score for fold 5: loss of 1.208940863609314; accuracy of 37.5%
Test data Score for fold 5: loss of 0.5948800444602966; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.03162169083952904; accuracy of 100.0%
Val Score for fold 5: loss of 1.1881191730499268; accuracy of 37.5%
Test data Score for fold 5: loss of 0.718525230884552; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.6931523084640503; accuracy of 50.0%
Val Score for fold 5: loss of 0.6931523084640503; accuracy of 50.0%
Test data Score for fold 5: loss of 0.6931522488594055; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6928219795227051; accuracy of 51.78571343421936%
Val Score for fold 6: loss of 0.6958823204040527; accuracy of 37.5%
Test data Score for fold 6: loss of 0.6932045221328735; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.34448379278182983; accuracy of 96.42857313156128%
Val Score for fold 6: loss of 1.2168000936508179; accuracy of 25.0%
Test data Score for fold 6: loss of 0.7178999185562134; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.17883361876010895; accuracy of 100.0%
Val Score for fold 6: loss of 1.3631846904754639; accuracy of 37.5%
Test data Score for fold 6: loss of 0.6783928871154785; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.4875994026660919; accuracy of 85.71428656578064%
Val Score for fold 6: loss of 0.9931010007858276; accuracy of 25.0%
Test data Score for fold 6: loss of 0.614677369594574; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6208317875862122; accuracy of 80.35714030265808%
Val Score for fold 6: loss of 0.7254762649536133; accuracy of 37.5%
Test data Score for fold 6: loss of 0.6996977925300598; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6282801628112793; accuracy of 69.64285969734192%
Val Score for fold 6: loss of 0.7571699023246765; accuracy of 37.5%
Test data Score for fold 6: loss of 0.7073248028755188; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.4441359341144562; accuracy of 94.64285969734192%
Val Score for fold 6: loss of 0.8929853439331055; accuracy of 25.0%
Test data Score for fold 6: loss of 0.594577968120575; accuracy of 87.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.321581095457077; accuracy of 96.42857313156128%
Val Score for fold 6: loss of 0.837256669998169; accuracy of 37.5%
Test data Score for fold 6: loss of 0.6952840685844421; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.5956975221633911; accuracy of 66.07142686843872%
Val Score for fold 6: loss of 0.8111942410469055; accuracy of 62.5%
Test data Score for fold 6: loss of 0.7429800629615784; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6411533355712891; accuracy of 53.57142686843872%
Val Score for fold 7: loss of 0.8644028902053833; accuracy of 25.0%
Test data Score for fold 7: loss of 0.6829191446304321; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.23659968376159668; accuracy of 100.0%
Val Score for fold 7: loss of 1.0104857683181763; accuracy of 50.0%
Test data Score for fold 7: loss of 0.5838375091552734; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.2660819888114929; accuracy of 94.64285969734192%
Val Score for fold 8: loss of 0.8943505883216858; accuracy of 50.0%
Test data Score for fold 8: loss of 0.7754672169685364; accuracy of 50.0%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[35]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_test</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>


<span class="n">LX</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">[</span><span class="n">data_order</span><span class="p">,:,:,:]</span>
<span class="n">LY</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">]</span>

<span class="n">comb_count_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;porosity_bin_model_fold_no_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.h5&#39;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">LX</span><span class="p">)</span>
    <span class="c1"># LY = np.array([1 if a == 0 else 0 for a in Y])</span>
    <span class="n">pred_class</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class</span><span class="o">==</span><span class="n">LY</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct predictions in fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>  
    <span class="n">pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">pred_class_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred_test</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class_test</span><span class="o">==</span><span class="n">y_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct Test data predictions for fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>
    <span class="n">comb_count_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),</span><span class="n">comb_count_acc</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Accuracy Per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">comb_count_acc</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Average Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Combined Model Accuracy in Predicting Pore Count&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span><span class="n">labelpad</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>3/3 [==============================] - 0s 37ms/step
------------------------------------------------------------------------
Correct predictions in fold 1 ...
44
1/1 [==============================] - 0s 50ms/step
Correct Test data predictions for fold 1 ...
5
3/3 [==============================] - 0s 30ms/step
------------------------------------------------------------------------
Correct predictions in fold 2 ...
51
1/1 [==============================] - 0s 23ms/step
Correct Test data predictions for fold 2 ...
5
3/3 [==============================] - 0s 23ms/step
------------------------------------------------------------------------
Correct predictions in fold 3 ...
56
1/1 [==============================] - 0s 24ms/step
Correct Test data predictions for fold 3 ...
7
3/3 [==============================] - 0s 21ms/step
------------------------------------------------------------------------
Correct predictions in fold 4 ...
36
1/1 [==============================] - 0s 24ms/step
Correct Test data predictions for fold 4 ...
4
3/3 [==============================] - 0s 29ms/step
------------------------------------------------------------------------
Correct predictions in fold 5 ...
51
1/1 [==============================] - 0s 24ms/step
Correct Test data predictions for fold 5 ...
5
3/3 [==============================] - 0s 24ms/step
------------------------------------------------------------------------
Correct predictions in fold 6 ...
36
1/1 [==============================] - 0s 24ms/step
Correct Test data predictions for fold 6 ...
4
3/3 [==============================] - 0s 24ms/step
------------------------------------------------------------------------
Correct predictions in fold 7 ...
49
1/1 [==============================] - 0s 25ms/step
Correct Test data predictions for fold 7 ...
5
3/3 [==============================] - 0s 24ms/step
------------------------------------------------------------------------
Correct predictions in fold 8 ...
49
1/1 [==============================] - 0s 25ms/step
Correct Test data predictions for fold 8 ...
6
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.1.2.-Printing">4.1.2. Printing<a class="anchor-link" href="#4.1.2.-Printing">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">NUMPY_INPUT_DATA_printing</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_PRINTING</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">X_train_class_printing</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_printing</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">],:,:,:]</span>
<span class="n">y_train_class_count_printing</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]]</span>
<span class="n">X_test_class_printing</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_printing</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test_class_count_printing</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>

<span class="c1"># Define the K-fold Cross Validator</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># K-fold Cross Validation model evaluation</span>
<span class="n">fold_no</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">train_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train_class_printing</span><span class="p">,</span> <span class="n">y_train_class_count_printing</span><span class="p">):</span>
    
    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Define the model architecture</span>
    <span class="k">while</span><span class="p">(</span><span class="n">train_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">val_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">test_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="c1"># model.add(Conv2D(128, (3, 3), activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;, padding=&#39;same&#39;))</span>
        <span class="c1"># model.add(MaxPooling2D((2, 2)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
        <span class="c1"># Compile the model</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
        <span class="c1"># Generate a print</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Training for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>

        <span class="c1"># Fit data to model</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_class_printing</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_class_count_printing</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1">#train_acc_per_fold.append(history.history[&#39;accuracy&#39;])</span>
        <span class="c1">#train_loss_per_fold.append(history.history[&#39;loss&#39;])</span>
        <span class="c1">#summarize_diagnostics(fold_no, history)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;porosity_bin_model_printing_fold_no_&#39;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">fold_no</span><span class="p">)</span> <span class="o">+</span><span class="s1">&#39;.h5&#39;</span><span class="p">)</span>
    
        <span class="c1"># Generate generalization metrics</span>
        <span class="n">train_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_class_printing</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_class_count_printing</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">val_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_class_printing</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">y_train_class_count_printing</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Val Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_class_printing</span><span class="p">,</span> <span class="n">y_test_class_count_printing</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_class_printing</span><span class="p">),</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test data Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Increase fold number</span>
    <span class="n">fold_no</span> <span class="o">=</span> <span class="n">fold_no</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">train_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">val_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">test_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">test_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5278714895248413; accuracy of 83.92857313156128%
Val Score for fold 1: loss of 0.8516310453414917; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7429900765419006; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.26702362298965454; accuracy of 96.42857313156128%
Val Score for fold 1: loss of 1.2719933986663818; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7618809938430786; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.31042030453681946; accuracy of 98.21428656578064%
Val Score for fold 1: loss of 0.7906292676925659; accuracy of 50.0%
Test data Score for fold 1: loss of 0.868692934513092; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.1074131652712822; accuracy of 100.0%
Val Score for fold 1: loss of 1.1371512413024902; accuracy of 37.5%
Test data Score for fold 1: loss of 0.9258344769477844; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5013198852539062; accuracy of 85.71428656578064%
Val Score for fold 1: loss of 0.838769257068634; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7184321284294128; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5302872061729431; accuracy of 82.14285969734192%
Val Score for fold 1: loss of 0.6939454674720764; accuracy of 50.0%
Test data Score for fold 1: loss of 0.7660061717033386; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.25809910893440247; accuracy of 98.21428656578064%
Val Score for fold 2: loss of 1.0728106498718262; accuracy of 50.0%
Test data Score for fold 2: loss of 0.5667515993118286; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 3 ...
Train Score for fold 3: loss of 0.33151668310165405; accuracy of 94.64285969734192%
Val Score for fold 3: loss of 0.9529208540916443; accuracy of 25.0%
Test data Score for fold 3: loss of 0.6110011339187622; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 3 ...
Train Score for fold 3: loss of 0.5779157280921936; accuracy of 80.35714030265808%
Val Score for fold 3: loss of 0.7026060223579407; accuracy of 50.0%
Test data Score for fold 3: loss of 0.6270353198051453; accuracy of 87.5%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.35189226269721985; accuracy of 94.64285969734192%
Val Score for fold 4: loss of 0.7241064310073853; accuracy of 62.5%
Test data Score for fold 4: loss of 0.6274482011795044; accuracy of 87.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.6365664601325989; accuracy of 69.64285969734192%
Val Score for fold 5: loss of 0.7106785774230957; accuracy of 25.0%
Test data Score for fold 5: loss of 0.6657768487930298; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.5170407891273499; accuracy of 92.85714030265808%
Val Score for fold 5: loss of 0.7868812084197998; accuracy of 37.5%
Test data Score for fold 5: loss of 0.6944111585617065; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.4520149827003479; accuracy of 94.64285969734192%
Val Score for fold 5: loss of 0.7722468972206116; accuracy of 37.5%
Test data Score for fold 5: loss of 0.5594028234481812; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.5462005734443665; accuracy of 82.14285969734192%
Val Score for fold 5: loss of 0.7309755086898804; accuracy of 37.5%
Test data Score for fold 5: loss of 0.6566374897956848; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.3485143482685089; accuracy of 94.64285969734192%
Val Score for fold 5: loss of 0.6858375072479248; accuracy of 62.5%
Test data Score for fold 5: loss of 0.6536263227462769; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.24245309829711914; accuracy of 94.64285969734192%
Val Score for fold 6: loss of 1.225670337677002; accuracy of 25.0%
Test data Score for fold 6: loss of 0.9231651425361633; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.4665040969848633; accuracy of 89.28571343421936%
Val Score for fold 6: loss of 1.0528351068496704; accuracy of 12.5%
Test data Score for fold 6: loss of 0.6863638162612915; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6890109777450562; accuracy of 55.35714030265808%
Val Score for fold 6: loss of 0.7159824371337891; accuracy of 12.5%
Test data Score for fold 6: loss of 0.6930434107780457; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.42757648229599; accuracy of 91.07142686843872%
Val Score for fold 6: loss of 1.1057162284851074; accuracy of 12.5%
Test data Score for fold 6: loss of 0.8340681791305542; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.5328270792961121; accuracy of 76.78571343421936%
Val Score for fold 6: loss of 1.0385249853134155; accuracy of 25.0%
Test data Score for fold 6: loss of 0.7965408563613892; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.06290517002344131; accuracy of 100.0%
Val Score for fold 6: loss of 1.7408447265625; accuracy of 37.5%
Test data Score for fold 6: loss of 1.0150281190872192; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.513975203037262; accuracy of 73.21428656578064%
Val Score for fold 6: loss of 0.8501739501953125; accuracy of 37.5%
Test data Score for fold 6: loss of 0.6666467189788818; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.34693533182144165; accuracy of 100.0%
Val Score for fold 6: loss of 0.9598192572593689; accuracy of 12.5%
Test data Score for fold 6: loss of 0.7507139444351196; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.10689450800418854; accuracy of 100.0%
Val Score for fold 6: loss of 1.8797976970672607; accuracy of 12.5%
Test data Score for fold 6: loss of 0.683922529220581; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.27104851603507996; accuracy of 98.21428656578064%
Val Score for fold 6: loss of 1.114146113395691; accuracy of 25.0%
Test data Score for fold 6: loss of 0.7904467582702637; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.3674273192882538; accuracy of 91.07142686843872%
Val Score for fold 6: loss of 1.0026130676269531; accuracy of 25.0%
Test data Score for fold 6: loss of 0.8540709018707275; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.21016880869865417; accuracy of 98.21428656578064%
Val Score for fold 6: loss of 0.9311167597770691; accuracy of 25.0%
Test data Score for fold 6: loss of 0.5566108226776123; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6007698774337769; accuracy of 73.21428656578064%
Val Score for fold 6: loss of 0.8626047372817993; accuracy of 12.5%
Test data Score for fold 6: loss of 0.7129052877426147; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.2766740322113037; accuracy of 92.85714030265808%
Val Score for fold 6: loss of 0.8987012505531311; accuracy of 37.5%
Test data Score for fold 6: loss of 0.6979596614837646; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6889494061470032; accuracy of 55.35714030265808%
Val Score for fold 6: loss of 0.7331768274307251; accuracy of 12.5%
Test data Score for fold 6: loss of 0.6947009563446045; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.18277297914028168; accuracy of 100.0%
Val Score for fold 6: loss of 1.325347661972046; accuracy of 25.0%
Test data Score for fold 6: loss of 1.0006983280181885; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.29235056042671204; accuracy of 96.42857313156128%
Val Score for fold 6: loss of 1.0484663248062134; accuracy of 37.5%
Test data Score for fold 6: loss of 0.7747205495834351; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.1417655646800995; accuracy of 100.0%
Val Score for fold 6: loss of 1.5584218502044678; accuracy of 12.5%
Test data Score for fold 6: loss of 0.7386830449104309; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.620121419429779; accuracy of 58.92857313156128%
Val Score for fold 6: loss of 0.8255274891853333; accuracy of 12.5%
Test data Score for fold 6: loss of 0.7171908020973206; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.4954277575016022; accuracy of 82.14285969734192%
Val Score for fold 6: loss of 0.875032901763916; accuracy of 25.0%
Test data Score for fold 6: loss of 0.6938380002975464; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.4481385052204132; accuracy of 83.92857313156128%
Val Score for fold 6: loss of 1.1893806457519531; accuracy of 25.0%
Test data Score for fold 6: loss of 0.9250224828720093; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.48376068472862244; accuracy of 85.71428656578064%
Val Score for fold 6: loss of 1.007878065109253; accuracy of 12.5%
Test data Score for fold 6: loss of 0.614703893661499; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.4629373550415039; accuracy of 89.28571343421936%
Val Score for fold 6: loss of 0.7990655899047852; accuracy of 37.5%
Test data Score for fold 6: loss of 0.7394234538078308; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.29514437913894653; accuracy of 92.85714030265808%
Val Score for fold 6: loss of 1.1589922904968262; accuracy of 25.0%
Test data Score for fold 6: loss of 0.6524112820625305; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.3681890666484833; accuracy of 92.85714030265808%
Val Score for fold 6: loss of 1.0005254745483398; accuracy of 25.0%
Test data Score for fold 6: loss of 0.712372362613678; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.42441001534461975; accuracy of 85.71428656578064%
Val Score for fold 6: loss of 0.9538807272911072; accuracy of 25.0%
Test data Score for fold 6: loss of 0.7307662963867188; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.35838404297828674; accuracy of 91.07142686843872%
Val Score for fold 6: loss of 1.4951728582382202; accuracy of 25.0%
Test data Score for fold 6: loss of 0.9807207584381104; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.5426598787307739; accuracy of 75.0%
Val Score for fold 6: loss of 0.8961695432662964; accuracy of 12.5%
Test data Score for fold 6: loss of 0.7145677804946899; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.5098687410354614; accuracy of 82.14285969734192%
Val Score for fold 6: loss of 0.8815052509307861; accuracy of 25.0%
Test data Score for fold 6: loss of 0.6113371849060059; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.1710275411605835; accuracy of 100.0%
Val Score for fold 6: loss of 1.26741361618042; accuracy of 37.5%
Test data Score for fold 6: loss of 0.7514472603797913; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.4690820276737213; accuracy of 69.64285969734192%
Val Score for fold 6: loss of 1.1160297393798828; accuracy of 12.5%
Test data Score for fold 6: loss of 0.7076002359390259; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.20077382028102875; accuracy of 100.0%
Val Score for fold 6: loss of 0.9556925296783447; accuracy of 50.0%
Test data Score for fold 6: loss of 0.9946414828300476; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.3407291769981384; accuracy of 94.64285969734192%
Val Score for fold 7: loss of 0.8211126327514648; accuracy of 50.0%
Test data Score for fold 7: loss of 0.6805084943771362; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.6714630126953125; accuracy of 58.92857313156128%
Val Score for fold 8: loss of 0.7139532566070557; accuracy of 37.5%
Test data Score for fold 8: loss of 0.6689860224723816; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.510071337223053; accuracy of 85.71428656578064%
Val Score for fold 8: loss of 0.6994703412055969; accuracy of 50.0%
Test data Score for fold 8: loss of 0.5517135262489319; accuracy of 87.5%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LX</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_printing</span><span class="p">[</span><span class="n">data_order</span><span class="p">,:,:,:]</span>
<span class="n">LY</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">]</span> 

<span class="n">printing_count_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;porosity_bin_model_printing_fold_no_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.h5&#39;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">LX</span><span class="p">)</span>
    <span class="c1"># LY = np.array([1 if a == 0 else 0 for a in Y])</span>
    <span class="n">pred_class</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class</span><span class="o">==</span><span class="n">LY</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct predictions in fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>  
    <span class="n">pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_class_printing</span><span class="p">)</span>
    <span class="n">pred_class_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred_test</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class_test</span><span class="o">==</span><span class="n">y_test_class_count_printing</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct Test data predictions for fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>
    <span class="n">printing_count_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_class_printing</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),</span><span class="n">printing_count_acc</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Accuracy Per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">printing_count_acc</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Average Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Printing Model Accuracy in Predicting Pore Count&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span><span class="n">labelpad</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>3/3 [==============================] - 0s 21ms/step
------------------------------------------------------------------------
Correct predictions in fold 1 ...
52
1/1 [==============================] - 0s 32ms/step
Correct Test data predictions for fold 1 ...
7
3/3 [==============================] - 0s 37ms/step
------------------------------------------------------------------------
Correct predictions in fold 2 ...
47
1/1 [==============================] - 0s 23ms/step
Correct Test data predictions for fold 2 ...
4
3/3 [==============================] - 0s 18ms/step
------------------------------------------------------------------------
Correct predictions in fold 3 ...
52
1/1 [==============================] - 0s 25ms/step
Correct Test data predictions for fold 3 ...
5
3/3 [==============================] - 0s 17ms/step
------------------------------------------------------------------------
Correct predictions in fold 4 ...
47
1/1 [==============================] - 0s 29ms/step
Correct Test data predictions for fold 4 ...
3
3/3 [==============================] - 0s 17ms/step
------------------------------------------------------------------------
Correct predictions in fold 5 ...
44
1/1 [==============================] - 0s 24ms/step
Correct Test data predictions for fold 5 ...
6
3/3 [==============================] - 0s 18ms/step
------------------------------------------------------------------------
Correct predictions in fold 6 ...
57
1/1 [==============================] - 0s 23ms/step
Correct Test data predictions for fold 6 ...
7
3/3 [==============================] - 0s 18ms/step
------------------------------------------------------------------------
Correct predictions in fold 7 ...
36
1/1 [==============================] - 0s 21ms/step
Correct Test data predictions for fold 7 ...
4
3/3 [==============================] - 0s 22ms/step
------------------------------------------------------------------------
Correct predictions in fold 8 ...
52
1/1 [==============================] - 0s 22ms/step
Correct Test data predictions for fold 8 ...
3
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.1.3.-Milling">4.1.3. Milling<a class="anchor-link" href="#4.1.3.-Milling">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">NUMPY_INPUT_DATA_milling</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_MILLING</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">X_train_class_milling</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_milling</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">],:,:,:]</span>
<span class="n">y_train_class_count_milling</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]]</span>
<span class="n">X_test_class_milling</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_milling</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test_class_count_milling</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>

<span class="c1"># Define the K-fold Cross Validator</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># K-fold Cross Validation model evaluation</span>
<span class="n">fold_no</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">train_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train_class_milling</span><span class="p">,</span> <span class="n">y_train_class_count_milling</span><span class="p">):</span>
    
    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Define the model architecture</span>
    <span class="k">while</span><span class="p">(</span><span class="n">train_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">val_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">test_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
        <span class="c1">#model.add(MaxPooling2D((2, 2)))</span>
        <span class="c1"># model.add(Conv2D(128, (3, 3), activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;, padding=&#39;same&#39;))</span>
        <span class="c1"># model.add(MaxPooling2D((2, 2)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
        <span class="c1"># Compile the model</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
        <span class="c1"># Generate a print</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Training for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>

        <span class="c1"># Fit data to model</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_class_milling</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_class_count_milling</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1">#train_acc_per_fold.append(history.history[&#39;accuracy&#39;])</span>
        <span class="c1">#train_loss_per_fold.append(history.history[&#39;loss&#39;])</span>
        <span class="c1">#summarize_diagnostics(fold_no, history)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;porosity_bin_model_milling_fold_no_&#39;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">fold_no</span><span class="p">)</span> <span class="o">+</span><span class="s1">&#39;.h5&#39;</span><span class="p">)</span>
    
        <span class="c1"># Generate generalization metrics</span>
        <span class="n">train_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_class_milling</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_class_count_milling</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">val_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_class_milling</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">y_train_class_count_milling</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Val Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_class_milling</span><span class="p">,</span> <span class="n">y_test_class_count_milling</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_class_milling</span><span class="p">),</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test data Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Increase fold number</span>
    <span class="n">fold_no</span> <span class="o">=</span> <span class="n">fold_no</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">train_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">val_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">test_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">test_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6106141209602356; accuracy of 80.35714030265808%
Val Score for fold 1: loss of 0.7727962732315063; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7711377739906311; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6470349431037903; accuracy of 66.07142686843872%
Val Score for fold 1: loss of 0.8422647714614868; accuracy of 25.0%
Test data Score for fold 1: loss of 0.8029921054840088; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6908637285232544; accuracy of 55.35714030265808%
Val Score for fold 1: loss of 0.6992099285125732; accuracy of 37.5%
Test data Score for fold 1: loss of 0.6956983804702759; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5866607427597046; accuracy of 69.64285969734192%
Val Score for fold 1: loss of 0.841428816318512; accuracy of 25.0%
Test data Score for fold 1: loss of 0.8239862322807312; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5452311635017395; accuracy of 78.57142686843872%
Val Score for fold 1: loss of 0.9205478429794312; accuracy of 25.0%
Test data Score for fold 1: loss of 0.9114001989364624; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6496691107749939; accuracy of 71.42857313156128%
Val Score for fold 1: loss of 0.7372827529907227; accuracy of 0.0%
Test data Score for fold 1: loss of 0.7680816054344177; accuracy of 0.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6425331830978394; accuracy of 67.85714030265808%
Val Score for fold 1: loss of 0.7476400136947632; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7618950009346008; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6521527171134949; accuracy of 73.21428656578064%
Val Score for fold 1: loss of 0.7356120347976685; accuracy of 50.0%
Test data Score for fold 1: loss of 0.7488412261009216; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6685604453086853; accuracy of 66.07142686843872%
Val Score for fold 1: loss of 0.7221398949623108; accuracy of 37.5%
Test data Score for fold 1: loss of 0.6940704584121704; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6893876194953918; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7103327512741089; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6982656717300415; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6516189575195312; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7821180820465088; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7156004905700684; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6908078789710999; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.710087239742279; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6926852464675903; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6679661870002747; accuracy of 60.71428656578064%
Val Score for fold 1: loss of 0.7647814750671387; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7348296642303467; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6412030458450317; accuracy of 60.71428656578064%
Val Score for fold 1: loss of 0.8611724376678467; accuracy of 37.5%
Test data Score for fold 1: loss of 0.8433688282966614; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6364275813102722; accuracy of 60.71428656578064%
Val Score for fold 1: loss of 0.7947883605957031; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7934523820877075; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6649875640869141; accuracy of 69.64285969734192%
Val Score for fold 1: loss of 0.6944233179092407; accuracy of 50.0%
Test data Score for fold 1: loss of 0.7312779426574707; accuracy of 12.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6905368566513062; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7228310704231262; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6944341659545898; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.638454020023346; accuracy of 69.64285969734192%
Val Score for fold 1: loss of 0.7778302431106567; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7507836222648621; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6736855506896973; accuracy of 62.5%
Val Score for fold 1: loss of 0.7532627582550049; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7094619870185852; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5395520329475403; accuracy of 76.78571343421936%
Val Score for fold 1: loss of 0.7832170724868774; accuracy of 50.0%
Test data Score for fold 1: loss of 0.7880500555038452; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6781710386276245; accuracy of 64.28571343421936%
Val Score for fold 1: loss of 0.7017636299133301; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7030515074729919; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6851670145988464; accuracy of 60.71428656578064%
Val Score for fold 1: loss of 0.7068486213684082; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7041301727294922; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6618911027908325; accuracy of 64.28571343421936%
Val Score for fold 1: loss of 0.7412228584289551; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7476001977920532; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6918735504150391; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.70380699634552; accuracy of 25.0%
Test data Score for fold 1: loss of 0.693365216255188; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6795865893363953; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7323224544525146; accuracy of 25.0%
Test data Score for fold 1: loss of 0.702415943145752; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5959683656692505; accuracy of 69.64285969734192%
Val Score for fold 1: loss of 0.843643069267273; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7484146952629089; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6909918189048767; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7157286405563354; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6940839290618896; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6232184171676636; accuracy of 66.07142686843872%
Val Score for fold 1: loss of 0.807786226272583; accuracy of 37.5%
Test data Score for fold 1: loss of 0.774147629737854; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5988219380378723; accuracy of 78.57142686843872%
Val Score for fold 1: loss of 0.7674283981323242; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7448221445083618; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.657069742679596; accuracy of 62.5%
Val Score for fold 1: loss of 0.7491791248321533; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7384871244430542; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.629033088684082; accuracy of 66.07142686843872%
Val Score for fold 1: loss of 0.8455163836479187; accuracy of 25.0%
Test data Score for fold 1: loss of 0.794762134552002; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6904183030128479; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7067440748214722; accuracy of 25.0%
Test data Score for fold 1: loss of 0.693375289440155; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6605950593948364; accuracy of 55.35714030265808%
Val Score for fold 1: loss of 0.7947911024093628; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7735806703567505; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6754737496376038; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.8064626455307007; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7275465726852417; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.689265251159668; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7233202457427979; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7008016705513; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6909124255180359; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7162737846374512; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6941277384757996; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6434354186058044; accuracy of 71.42857313156128%
Val Score for fold 1: loss of 0.6742119789123535; accuracy of 75.0%
Test data Score for fold 1: loss of 0.7136666774749756; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.690811038017273; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.706501841545105; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6950554251670837; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6840123534202576; accuracy of 57.14285969734192%
Val Score for fold 1: loss of 0.7039179801940918; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7103968858718872; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6487630009651184; accuracy of 64.28571343421936%
Val Score for fold 1: loss of 0.8386833667755127; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7967461347579956; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6749652028083801; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.789546549320221; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7537011504173279; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6895013451576233; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7105182409286499; accuracy of 25.0%
Test data Score for fold 1: loss of 0.695514440536499; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6916189789772034; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7065414786338806; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6934879422187805; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5821002721786499; accuracy of 82.14285969734192%
Val Score for fold 1: loss of 0.7843102216720581; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7902112007141113; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6612259745597839; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.8176758289337158; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7547243237495422; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6900069117546082; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7276440858840942; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6920221447944641; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6607488989830017; accuracy of 64.28571343421936%
Val Score for fold 1: loss of 0.7823783755302429; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7346826791763306; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6466361880302429; accuracy of 78.57142686843872%
Val Score for fold 1: loss of 0.7841780781745911; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7322235107421875; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6870115399360657; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7319331169128418; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6990658640861511; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6374179124832153; accuracy of 64.28571343421936%
Val Score for fold 1: loss of 0.7611699104309082; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7452234029769897; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6409546732902527; accuracy of 66.07142686843872%
Val Score for fold 1: loss of 0.8310595154762268; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7819826602935791; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6487459540367126; accuracy of 67.85714030265808%
Val Score for fold 1: loss of 0.7306793928146362; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7059622406959534; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6538389921188354; accuracy of 64.28571343421936%
Val Score for fold 1: loss of 0.7434016466140747; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7305777668952942; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6811876893043518; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7565118074417114; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7207049131393433; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6907770037651062; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7127948999404907; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6937037110328674; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.690302848815918; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7078938484191895; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6947101950645447; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6710372567176819; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7486487627029419; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6965503692626953; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6917546391487122; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7050653696060181; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6934184432029724; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6787985563278198; accuracy of 58.92857313156128%
Val Score for fold 1: loss of 0.710746169090271; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7158634066581726; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6789929270744324; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7715907096862793; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7108344435691833; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5775601267814636; accuracy of 75.0%
Val Score for fold 1: loss of 0.8306152820587158; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7801150679588318; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6821932792663574; accuracy of 55.35714030265808%
Val Score for fold 1: loss of 0.7032014727592468; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6953858137130737; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.68993079662323; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7058424353599548; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6925947666168213; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6825631260871887; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7221893072128296; accuracy of 25.0%
Test data Score for fold 1: loss of 0.715805172920227; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6797880530357361; accuracy of 58.92857313156128%
Val Score for fold 1: loss of 0.7386932373046875; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7144871950149536; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.5861200094223022; accuracy of 82.14285969734192%
Val Score for fold 1: loss of 0.7425900101661682; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7895044088363647; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6913955807685852; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.709362804889679; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6936414837837219; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6869964003562927; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.728217601776123; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7004765868186951; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6752938628196716; accuracy of 60.71428656578064%
Val Score for fold 1: loss of 0.7079777717590332; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7100778222084045; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6916096806526184; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7066983580589294; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6934958100318909; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6915671229362488; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7072004675865173; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6935213208198547; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6768194437026978; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7315640449523926; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7044588923454285; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6735273599624634; accuracy of 67.85714030265808%
Val Score for fold 1: loss of 0.7141702175140381; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7086873054504395; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.67320317029953; accuracy of 57.14285969734192%
Val Score for fold 1: loss of 0.7328366637229919; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7202460765838623; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6771793365478516; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7392659187316895; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7241616249084473; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6892985701560974; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7360308170318604; accuracy of 25.0%
Test data Score for fold 1: loss of 0.6947062611579895; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6532863974571228; accuracy of 66.07142686843872%
Val Score for fold 1: loss of 0.8078594207763672; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7355325222015381; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6863310933113098; accuracy of 60.71428656578064%
Val Score for fold 1: loss of 0.7125235199928284; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7102962732315063; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6555115580558777; accuracy of 66.07142686843872%
Val Score for fold 1: loss of 0.7804999947547913; accuracy of 37.5%
Test data Score for fold 1: loss of 0.7709485292434692; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6442650556564331; accuracy of 62.5%
Val Score for fold 1: loss of 0.775653600692749; accuracy of 25.0%
Test data Score for fold 1: loss of 0.738907516002655; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6398299336433411; accuracy of 58.92857313156128%
Val Score for fold 1: loss of 0.8324378132820129; accuracy of 25.0%
Test data Score for fold 1: loss of 0.74476158618927; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6647721529006958; accuracy of 71.42857313156128%
Val Score for fold 1: loss of 0.708620548248291; accuracy of 50.0%
Test data Score for fold 1: loss of 0.695193886756897; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6485375761985779; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7781379222869873; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7472896575927734; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6822858452796936; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7245393991470337; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6920952200889587; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6195659637451172; accuracy of 69.64285969734192%
Val Score for fold 2: loss of 0.8534510135650635; accuracy of 50.0%
Test data Score for fold 2: loss of 0.7806767225265503; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6763395667076111; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7356302738189697; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6995336413383484; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6077513098716736; accuracy of 80.35714030265808%
Val Score for fold 2: loss of 0.7224453687667847; accuracy of 75.0%
Test data Score for fold 2: loss of 0.7393158674240112; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6747868657112122; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7762407064437866; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7341169118881226; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6814435720443726; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.750983476638794; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7189496755599976; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6866730451583862; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.731886088848114; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6998423933982849; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.641637921333313; accuracy of 62.5%
Val Score for fold 2: loss of 0.7857221364974976; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7637402415275574; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6821111440658569; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7386281490325928; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7011184096336365; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6889809370040894; accuracy of 55.35714030265808%
Val Score for fold 2: loss of 0.7066179513931274; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6968153119087219; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6916446685791016; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7062925696372986; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6934757232666016; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.676545262336731; accuracy of 73.21428656578064%
Val Score for fold 2: loss of 0.7200396060943604; accuracy of 37.5%
Test data Score for fold 2: loss of 0.7139032483100891; accuracy of 12.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6888437271118164; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7271547317504883; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6974780559539795; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6906143426895142; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7293288707733154; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6947988271713257; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6445317268371582; accuracy of 71.42857313156128%
Val Score for fold 2: loss of 0.7101826667785645; accuracy of 37.5%
Test data Score for fold 2: loss of 0.7504374980926514; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6112244725227356; accuracy of 73.21428656578064%
Val Score for fold 2: loss of 0.8806726932525635; accuracy of 37.5%
Test data Score for fold 2: loss of 0.8000524044036865; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6576257944107056; accuracy of 64.28571343421936%
Val Score for fold 2: loss of 0.7166414260864258; accuracy of 37.5%
Test data Score for fold 2: loss of 0.7179365158081055; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6694275736808777; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.728270411491394; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7268232703208923; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6912434697151184; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7114990949630737; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6937752962112427; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6901494264602661; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7217855453491211; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6959288716316223; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6915670037269592; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7072019577026367; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6935214996337891; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.46365126967430115; accuracy of 80.35714030265808%
Val Score for fold 2: loss of 1.1183475255966187; accuracy of 37.5%
Test data Score for fold 2: loss of 0.8663463592529297; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6769753694534302; accuracy of 64.28571343421936%
Val Score for fold 2: loss of 0.731342613697052; accuracy of 37.5%
Test data Score for fold 2: loss of 0.7163287997245789; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6606060862541199; accuracy of 58.92857313156128%
Val Score for fold 2: loss of 0.7451947927474976; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7288660407066345; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6298300623893738; accuracy of 62.5%
Val Score for fold 2: loss of 0.7795247435569763; accuracy of 37.5%
Test data Score for fold 2: loss of 0.6898784041404724; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6868728399276733; accuracy of 62.5%
Val Score for fold 2: loss of 0.7045893669128418; accuracy of 37.5%
Test data Score for fold 2: loss of 0.6978754997253418; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.5460328459739685; accuracy of 83.92857313156128%
Val Score for fold 2: loss of 0.764655351638794; accuracy of 62.5%
Test data Score for fold 2: loss of 0.7709559202194214; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6915287375450134; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7076656818389893; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6935458779335022; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6670761108398438; accuracy of 64.28571343421936%
Val Score for fold 2: loss of 0.7635310292243958; accuracy of 50.0%
Test data Score for fold 2: loss of 0.7643006443977356; accuracy of 12.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6893821358680725; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.716606616973877; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6969260573387146; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6660925149917603; accuracy of 57.14285969734192%
Val Score for fold 2: loss of 0.7292641401290894; accuracy of 37.5%
Test data Score for fold 2: loss of 0.7112652063369751; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6788650155067444; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7450035810470581; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7009686231613159; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.5836880803108215; accuracy of 73.21428656578064%
Val Score for fold 2: loss of 0.826716959476471; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7333334684371948; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.685919463634491; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7321641445159912; accuracy of 25.0%
Test data Score for fold 2: loss of 0.7082201242446899; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6917558312416077; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7050518989562988; accuracy of 25.0%
Test data Score for fold 2: loss of 0.6934179067611694; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6505423784255981; accuracy of 71.42857313156128%
Val Score for fold 2: loss of 0.7198492288589478; accuracy of 37.5%
Test data Score for fold 2: loss of 0.7085796594619751; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.69114750623703; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.7129836678504944; accuracy of 25.0%
Test data Score for fold 2: loss of 0.693877100944519; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.650996208190918; accuracy of 62.5%
Val Score for fold 2: loss of 0.7877106666564941; accuracy of 50.0%
Test data Score for fold 2: loss of 0.7755469083786011; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6030777096748352; accuracy of 73.21428656578064%
Val Score for fold 2: loss of 0.7847545146942139; accuracy of 50.0%
Test data Score for fold 2: loss of 0.7747875452041626; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 3 ...
Train Score for fold 3: loss of 0.6898100972175598; accuracy of 51.78571343421936%
Val Score for fold 3: loss of 0.6962331533432007; accuracy of 62.5%
Test data Score for fold 3: loss of 0.6947094202041626; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.6922809481620789; accuracy of 51.78571343421936%
Val Score for fold 4: loss of 0.7032910585403442; accuracy of 37.5%
Test data Score for fold 4: loss of 0.6931931972503662; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.6689240336418152; accuracy of 62.5%
Val Score for fold 4: loss of 0.7213845252990723; accuracy of 37.5%
Test data Score for fold 4: loss of 0.6866217851638794; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.6647787094116211; accuracy of 64.28571343421936%
Val Score for fold 4: loss of 0.728577733039856; accuracy of 50.0%
Test data Score for fold 4: loss of 0.729629635810852; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.692665696144104; accuracy of 51.78571343421936%
Val Score for fold 4: loss of 0.6978182196617126; accuracy of 37.5%
Test data Score for fold 4: loss of 0.6933097839355469; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.653641402721405; accuracy of 64.28571343421936%
Val Score for fold 4: loss of 0.7483628988265991; accuracy of 50.0%
Test data Score for fold 4: loss of 0.8076923489570618; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.6926421523094177; accuracy of 51.78571343421936%
Val Score for fold 4: loss of 0.6981906890869141; accuracy of 37.5%
Test data Score for fold 4: loss of 0.693335771560669; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.6821892857551575; accuracy of 62.5%
Val Score for fold 4: loss of 0.7107689380645752; accuracy of 50.0%
Test data Score for fold 4: loss of 0.7131406664848328; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.5866158604621887; accuracy of 71.42857313156128%
Val Score for fold 4: loss of 0.7540885210037231; accuracy of 37.5%
Test data Score for fold 4: loss of 0.8517178297042847; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.681916356086731; accuracy of 60.71428656578064%
Val Score for fold 4: loss of 0.7028732895851135; accuracy of 37.5%
Test data Score for fold 4: loss of 0.7246283292770386; accuracy of 12.5%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.6723365783691406; accuracy of 64.28571343421936%
Val Score for fold 4: loss of 0.7215367555618286; accuracy of 50.0%
Test data Score for fold 4: loss of 0.7052968740463257; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.6854072213172913; accuracy of 57.14285969734192%
Val Score for fold 5: loss of 0.7067264914512634; accuracy of 62.5%
Test data Score for fold 5: loss of 0.6973738670349121; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6768016815185547; accuracy of 58.92857313156128%
Val Score for fold 6: loss of 0.7034578323364258; accuracy of 37.5%
Test data Score for fold 6: loss of 0.6976710557937622; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6871148347854614; accuracy of 60.71428656578064%
Val Score for fold 6: loss of 0.7019076943397522; accuracy of 37.5%
Test data Score for fold 6: loss of 0.6907539367675781; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.5923805236816406; accuracy of 85.71428656578064%
Val Score for fold 6: loss of 0.707582950592041; accuracy of 50.0%
Test data Score for fold 6: loss of 0.7710193395614624; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6931533813476562; accuracy of 41.07142984867096%
Val Score for fold 6: loss of 0.6931612491607666; accuracy of 62.5%
Test data Score for fold 6: loss of 0.6935440897941589; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6931473016738892; accuracy of 50.0%
Val Score for fold 6: loss of 0.6931473016738892; accuracy of 50.0%
Test data Score for fold 6: loss of 0.6931473612785339; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.666571319103241; accuracy of 67.85714030265808%
Val Score for fold 7: loss of 0.743442177772522; accuracy of 25.0%
Test data Score for fold 7: loss of 0.7345471382141113; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6892172694206238; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.70118248462677; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6931973099708557; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6926089525222778; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.7028275728225708; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6935631632804871; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6219082474708557; accuracy of 67.85714030265808%
Val Score for fold 7: loss of 0.8168924450874329; accuracy of 37.5%
Test data Score for fold 7: loss of 0.7396506071090698; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6081314086914062; accuracy of 76.78571343421936%
Val Score for fold 7: loss of 0.8238381147384644; accuracy of 0.0%
Test data Score for fold 7: loss of 0.7556694746017456; accuracy of 12.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5030062794685364; accuracy of 82.14285969734192%
Val Score for fold 7: loss of 1.1316970586776733; accuracy of 12.5%
Test data Score for fold 7: loss of 0.8974584937095642; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6927676200866699; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.6964782476425171; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6932315230369568; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5394878387451172; accuracy of 82.14285969734192%
Val Score for fold 7: loss of 0.9806540012359619; accuracy of 12.5%
Test data Score for fold 7: loss of 0.8549805283546448; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6926568150520325; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.6979554891586304; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6933190822601318; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5372450351715088; accuracy of 85.71428656578064%
Val Score for fold 7: loss of 0.7545280456542969; accuracy of 37.5%
Test data Score for fold 7: loss of 0.7881665229797363; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6426214575767517; accuracy of 73.21428656578064%
Val Score for fold 7: loss of 0.7758567929267883; accuracy of 12.5%
Test data Score for fold 7: loss of 0.7271426916122437; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6257901191711426; accuracy of 73.21428656578064%
Val Score for fold 7: loss of 0.7160220146179199; accuracy of 50.0%
Test data Score for fold 7: loss of 0.7124202251434326; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6843468546867371; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.7138547897338867; accuracy of 37.5%
Test data Score for fold 7: loss of 0.7009475827217102; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6916060447692871; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.697135865688324; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6930532455444336; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6768884658813477; accuracy of 60.71428656578064%
Val Score for fold 7: loss of 0.681053876876831; accuracy of 62.5%
Test data Score for fold 7: loss of 0.7381200790405273; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6905850172042847; accuracy of 62.5%
Val Score for fold 7: loss of 0.7007242441177368; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6982839703559875; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6917610168457031; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.7035607099533081; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6942250728607178; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6544072031974792; accuracy of 62.5%
Val Score for fold 7: loss of 0.8683894872665405; accuracy of 0.0%
Test data Score for fold 7: loss of 0.7300496101379395; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6924763917922974; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.6961072683334351; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6923922300338745; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5473377108573914; accuracy of 83.92857313156128%
Val Score for fold 7: loss of 0.8529036641120911; accuracy of 25.0%
Test data Score for fold 7: loss of 0.7630611658096313; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6727812886238098; accuracy of 67.85714030265808%
Val Score for fold 7: loss of 0.7281307578086853; accuracy of 25.0%
Test data Score for fold 7: loss of 0.7129409313201904; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.59619140625; accuracy of 69.64285969734192%
Val Score for fold 7: loss of 0.9143738746643066; accuracy of 12.5%
Test data Score for fold 7: loss of 0.7705138325691223; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6926798820495605; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.6976087689399719; accuracy of 37.5%
Test data Score for fold 7: loss of 0.693295955657959; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6802729368209839; accuracy of 71.42857313156128%
Val Score for fold 7: loss of 0.7045414447784424; accuracy of 37.5%
Test data Score for fold 7: loss of 0.7063921689987183; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6307732462882996; accuracy of 73.21428656578064%
Val Score for fold 7: loss of 0.8046931028366089; accuracy of 25.0%
Test data Score for fold 7: loss of 0.748648464679718; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6099408268928528; accuracy of 69.64285969734192%
Val Score for fold 7: loss of 0.9088840484619141; accuracy of 25.0%
Test data Score for fold 7: loss of 0.7533990144729614; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6803312301635742; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.7451568841934204; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6961286664009094; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6909516453742981; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.7053755521774292; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6980500221252441; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6418590545654297; accuracy of 62.5%
Val Score for fold 7: loss of 0.7190548181533813; accuracy of 50.0%
Test data Score for fold 7: loss of 0.6533059477806091; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.6928730010986328; accuracy of 51.78571343421936%
Val Score for fold 8: loss of 0.6953727006912231; accuracy of 37.5%
Test data Score for fold 8: loss of 0.6931854486465454; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.67339688539505; accuracy of 64.28571343421936%
Val Score for fold 8: loss of 0.6603911519050598; accuracy of 62.5%
Test data Score for fold 8: loss of 0.7226284146308899; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.6845061182975769; accuracy of 51.78571343421936%
Val Score for fold 8: loss of 0.6890287399291992; accuracy of 50.0%
Test data Score for fold 8: loss of 0.7126851677894592; accuracy of 50.0%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LX</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_milling</span><span class="p">[</span><span class="n">data_order</span><span class="p">,:,:,:]</span>
<span class="n">LY</span> <span class="o">=</span> <span class="n">y_class_count</span><span class="p">[</span><span class="n">data_order</span><span class="p">]</span> 

<span class="n">milling_count_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;porosity_bin_model_milling_fold_no_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.h5&#39;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">LX</span><span class="p">)</span>
    <span class="c1"># LY = np.array([1 if a == 0 else 0 for a in Y])</span>
    <span class="n">pred_class</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class</span><span class="o">==</span><span class="n">LY</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct predictions in fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>  
    <span class="n">pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_class_milling</span><span class="p">)</span>
    <span class="n">pred_class_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred_test</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class_test</span><span class="o">==</span><span class="n">y_test_class_count_milling</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct Test data predictions for fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>
    <span class="n">milling_count_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_class_milling</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),</span> <span class="n">milling_count_acc</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Accuracy Per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span> <span class="n">milling_count_acc</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Average Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Milling Model Accuracy in Predicting Pore Count&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span><span class="n">labelpad</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>3/3 [==============================] - 0s 12ms/step
------------------------------------------------------------------------
Correct predictions in fold 1 ...
41
1/1 [==============================] - 0s 22ms/step
Correct Test data predictions for fold 1 ...
5
3/3 [==============================] - 0s 15ms/step
------------------------------------------------------------------------
Correct predictions in fold 2 ...
37
1/1 [==============================] - 0s 36ms/step
Correct Test data predictions for fold 2 ...
5
3/3 [==============================] - 0s 15ms/step
------------------------------------------------------------------------
Correct predictions in fold 3 ...
42
1/1 [==============================] - 0s 58ms/step
Correct Test data predictions for fold 3 ...
5
3/3 [==============================] - 0s 25ms/step
------------------------------------------------------------------------
Correct predictions in fold 4 ...
39
1/1 [==============================] - 0s 21ms/step
Correct Test data predictions for fold 4 ...
6
3/3 [==============================] - 0s 13ms/step
------------------------------------------------------------------------
Correct predictions in fold 5 ...
41
1/1 [==============================] - 0s 20ms/step
Correct Test data predictions for fold 5 ...
4
3/3 [==============================] - 0s 14ms/step
------------------------------------------------------------------------
Correct predictions in fold 6 ...
40
1/1 [==============================] - 0s 20ms/step
Correct Test data predictions for fold 6 ...
4
3/3 [==============================] - 0s 10ms/step
------------------------------------------------------------------------
Correct predictions in fold 7 ...
38
1/1 [==============================] - 0s 20ms/step
Correct Test data predictions for fold 7 ...
5
3/3 [==============================] - 0s 10ms/step
------------------------------------------------------------------------
Correct predictions in fold 8 ...
35
1/1 [==============================] - 0s 23ms/step
Correct Test data predictions for fold 8 ...
5
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.2.-%Area-Porosity">4.2. %Area Porosity<a class="anchor-link" href="#4.2.-%Area-Porosity">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y_class_area</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">72</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">72</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">y_target_area</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">&lt;=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_target_area</span><span class="p">):</span>
    <span class="n">y_class_area</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">else</span><span class="p">:</span> 
    <span class="n">y_class_area</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.2.1.-Combined">4.2.1. Combined<a class="anchor-link" href="#4.2.1.-Combined">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[24]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># CNN Model Architecture - Printing and Milling combined cycles</span>

<span class="n">NUMPY_INPUT_DATA</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_COMBINED</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


<span class="n">X_train_class</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">],:,:,:]</span>
<span class="n">y_train_class_area</span> <span class="o">=</span> <span class="n">y_class_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]]</span>
<span class="n">X_test_class</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test_class_area</span> <span class="o">=</span> <span class="n">y_class_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>


<span class="c1"># Define the K-fold Cross Validator</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># K-fold Cross Validation model evaluation</span>
<span class="n">fold_no</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">train_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train_class</span><span class="p">,</span> <span class="n">y_train_class_area</span><span class="p">):</span>
    
    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Define the model architecture</span>
    <span class="k">while</span><span class="p">(</span><span class="n">train_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">val_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">test_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="c1"># model.add(Conv2D(128, (3, 3), activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;, padding=&#39;same&#39;))</span>
        <span class="c1"># model.add(MaxPooling2D((2, 2)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
        <span class="c1"># Compile the model</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
        <span class="c1"># Generate a print</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Training for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>

        <span class="c1"># Fit data to model</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_class</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_class_area</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1">#train_acc_per_fold.append(history.history[&#39;accuracy&#39;])</span>
        <span class="c1">#train_loss_per_fold.append(history.history[&#39;loss&#39;])</span>
        <span class="c1">#summarize_diagnostics(fold_no, history)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;porosity_bin_model_fold_no_&#39;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">fold_no</span><span class="p">)</span> <span class="o">+</span><span class="s1">&#39;.h5&#39;</span><span class="p">)</span>
    
        <span class="c1"># Generate generalization metrics</span>
        <span class="n">train_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_class</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_class_area</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">val_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_class</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">y_train_class_area</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Val Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_class</span><span class="p">,</span> <span class="n">y_test_class_area</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_class</span><span class="p">),</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test data Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Increase fold number</span>
    <span class="n">fold_no</span> <span class="o">=</span> <span class="n">fold_no</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">train_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">val_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">test_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">test_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.687677264213562; accuracy of 57.14285969734192%
Val Score for fold 1: loss of 0.7283454537391663; accuracy of 12.5%
Test data Score for fold 1: loss of 0.6827971339225769; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.3820503354072571; accuracy of 91.07142686843872%
Val Score for fold 1: loss of 1.0448144674301147; accuracy of 25.0%
Test data Score for fold 1: loss of 0.9453872442245483; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.4612587094306946; accuracy of 87.5%
Val Score for fold 1: loss of 0.9010484218597412; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7945674657821655; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.29487180709838867; accuracy of 87.5%
Val Score for fold 1: loss of 1.7756106853485107; accuracy of 37.5%
Test data Score for fold 1: loss of 1.2418508529663086; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.2915889322757721; accuracy of 98.21428656578064%
Val Score for fold 1: loss of 1.6309282779693604; accuracy of 25.0%
Test data Score for fold 1: loss of 0.7759097814559937; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6874088644981384; accuracy of 57.14285969734192%
Val Score for fold 1: loss of 0.7305741310119629; accuracy of 12.5%
Test data Score for fold 1: loss of 0.6822291016578674; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.60747230052948; accuracy of 57.14285969734192%
Val Score for fold 1: loss of 0.9045239686965942; accuracy of 12.5%
Test data Score for fold 1: loss of 0.6599052548408508; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.015733417123556137; accuracy of 100.0%
Val Score for fold 1: loss of 1.2397315502166748; accuracy of 50.0%
Test data Score for fold 1: loss of 1.4140783548355103; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.08078222721815109; accuracy of 98.21428656578064%
Val Score for fold 1: loss of 1.1161530017852783; accuracy of 62.5%
Test data Score for fold 1: loss of 1.3122756481170654; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6758127212524414; accuracy of 57.14285969734192%
Val Score for fold 1: loss of 0.8139368295669556; accuracy of 12.5%
Test data Score for fold 1: loss of 0.6739339232444763; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6862614750862122; accuracy of 57.14285969734192%
Val Score for fold 1: loss of 0.7410622239112854; accuracy of 12.5%
Test data Score for fold 1: loss of 0.6796852946281433; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.39641666412353516; accuracy of 85.71428656578064%
Val Score for fold 1: loss of 0.7483630776405334; accuracy of 50.0%
Test data Score for fold 1: loss of 0.7238153219223022; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.11331833153963089; accuracy of 100.0%
Val Score for fold 2: loss of 0.6979819536209106; accuracy of 62.5%
Test data Score for fold 2: loss of 1.0410301685333252; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 3 ...
Train Score for fold 3: loss of 0.036951903253793716; accuracy of 100.0%
Val Score for fold 3: loss of 1.2088285684585571; accuracy of 50.0%
Test data Score for fold 3: loss of 0.6293065547943115; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.6926146149635315; accuracy of 51.78571343421936%
Val Score for fold 4: loss of 0.6933720111846924; accuracy of 50.0%
Test data Score for fold 4: loss of 0.6880700588226318; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.3184445798397064; accuracy of 100.0%
Val Score for fold 5: loss of 1.0255402326583862; accuracy of 50.0%
Test data Score for fold 5: loss of 0.832205057144165; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.03928792476654053; accuracy of 100.0%
Val Score for fold 5: loss of 0.8895904421806335; accuracy of 37.5%
Test data Score for fold 5: loss of 1.1944931745529175; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.15296010673046112; accuracy of 98.21428656578064%
Val Score for fold 5: loss of 1.0555601119995117; accuracy of 50.0%
Test data Score for fold 5: loss of 1.099642038345337; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.21631468832492828; accuracy of 100.0%
Val Score for fold 6: loss of 0.9261641502380371; accuracy of 50.0%
Test data Score for fold 6: loss of 1.148118257522583; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6921862363815308; accuracy of 51.78571343421936%
Val Score for fold 6: loss of 0.6937152743339539; accuracy of 50.0%
Test data Score for fold 6: loss of 0.6843677759170532; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.3711044192314148; accuracy of 91.07142686843872%
Val Score for fold 7: loss of 0.7138226628303528; accuracy of 75.0%
Test data Score for fold 7: loss of 0.8406233191490173; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.2761925756931305; accuracy of 92.85714030265808%
Val Score for fold 8: loss of 0.9883677959442139; accuracy of 50.0%
Test data Score for fold 8: loss of 1.0536574125289917; accuracy of 62.5%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[38]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LX</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA</span><span class="p">[</span><span class="n">data_order</span><span class="p">,:,:,:]</span>
<span class="n">LY</span> <span class="o">=</span> <span class="n">y_class_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">]</span>

<span class="n">comb_area_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;porosity_bin_model_fold_no_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.h5&#39;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">LX</span><span class="p">)</span>
    <span class="c1"># LY = np.array([1 if a == 0 else 0 for a in Y])</span>
    <span class="n">pred_class</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class</span><span class="o">==</span><span class="n">LY</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct predictions in fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>  
    <span class="n">pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">pred_class_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred_test</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class_test</span><span class="o">==</span><span class="n">y_test_class_area</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct Test data predictions for fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>
    <span class="n">comb_area_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_class_milling</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),</span> <span class="n">comb_area_acc</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Accuracy Per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span> <span class="n">comb_area_acc</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Average Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Combined Model Accuracy in Predicting %Area Porosity&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span><span class="n">labelpad</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>3/3 [==============================] - 0s 24ms/step
------------------------------------------------------------------------
Correct predictions in fold 1 ...
56
1/1 [==============================] - 0s 26ms/step
Correct Test data predictions for fold 1 ...
4
3/3 [==============================] - 0s 22ms/step
------------------------------------------------------------------------
Correct predictions in fold 2 ...
65
1/1 [==============================] - 0s 27ms/step
Correct Test data predictions for fold 2 ...
4
3/3 [==============================] - 0s 39ms/step
------------------------------------------------------------------------
Correct predictions in fold 3 ...
66
1/1 [==============================] - 0s 53ms/step
Correct Test data predictions for fold 3 ...
6
3/3 [==============================] - 0s 27ms/step
------------------------------------------------------------------------
Correct predictions in fold 4 ...
38
1/1 [==============================] - 0s 26ms/step
Correct Test data predictions for fold 4 ...
5
3/3 [==============================] - 0s 22ms/step
------------------------------------------------------------------------
Correct predictions in fold 5 ...
63
1/1 [==============================] - 0s 27ms/step
Correct Test data predictions for fold 5 ...
4
3/3 [==============================] - 0s 24ms/step
------------------------------------------------------------------------
Correct predictions in fold 6 ...
38
1/1 [==============================] - 0s 27ms/step
Correct Test data predictions for fold 6 ...
5
3/3 [==============================] - 0s 24ms/step
------------------------------------------------------------------------
Correct predictions in fold 7 ...
61
1/1 [==============================] - 0s 25ms/step
Correct Test data predictions for fold 7 ...
4
3/3 [==============================] - 0s 23ms/step
------------------------------------------------------------------------
Correct predictions in fold 8 ...
61
1/1 [==============================] - 0s 26ms/step
Correct Test data predictions for fold 8 ...
5
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.2.2.-Printing">4.2.2. Printing<a class="anchor-link" href="#4.2.2.-Printing">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">NUMPY_INPUT_DATA_printing</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_PRINTING</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">X_train_printing</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_printing</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">],:,:,:]</span>
<span class="n">y_train_area_printing</span> <span class="o">=</span> <span class="n">y_class_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]]</span>
<span class="n">X_test_printing</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_printing</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test_area_printing</span> <span class="o">=</span> <span class="n">y_class_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>

<span class="c1"># Define the K-fold Cross Validator</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># K-fold Cross Validation model evaluation</span>
<span class="n">fold_no</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">train_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train_printing</span><span class="p">,</span> <span class="n">y_train_area_printing</span><span class="p">):</span>
    
    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Define the model architecture</span>
    <span class="k">while</span><span class="p">(</span><span class="n">train_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">val_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">test_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="c1"># model.add(Conv2D(128, (3, 3), activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;, padding=&#39;same&#39;))</span>
        <span class="c1"># model.add(MaxPooling2D((2, 2)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
        <span class="c1"># Compile the model</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
        <span class="c1"># Generate a print</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Training for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>

        <span class="c1"># Fit data to model</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_printing</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_area_printing</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1">#train_acc_per_fold.append(history.history[&#39;accuracy&#39;])</span>
        <span class="c1">#train_loss_per_fold.append(history.history[&#39;loss&#39;])</span>
        <span class="c1">#summarize_diagnostics(fold_no, history)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;porosity_bin_model_printing_fold_no_&#39;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">fold_no</span><span class="p">)</span> <span class="o">+</span><span class="s1">&#39;.h5&#39;</span><span class="p">)</span>
    
        <span class="c1"># Generate generalization metrics</span>
        <span class="n">train_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_printing</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_area_printing</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">val_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_printing</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">y_train_area_printing</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Val Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_printing</span><span class="p">,</span> <span class="n">y_test_area_printing</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_printing</span><span class="p">),</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test data Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Increase fold number</span>
    <span class="n">fold_no</span> <span class="o">=</span> <span class="n">fold_no</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">train_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">val_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">test_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">test_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.15692302584648132; accuracy of 96.42857313156128%
Val Score for fold 1: loss of 1.55233633518219; accuracy of 50.0%
Test data Score for fold 1: loss of 1.1310837268829346; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.35553231835365295; accuracy of 91.07142686843872%
Val Score for fold 2: loss of 1.1012513637542725; accuracy of 12.5%
Test data Score for fold 2: loss of 0.9032222628593445; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6832218170166016; accuracy of 53.57142686843872%
Val Score for fold 2: loss of 0.6837044954299927; accuracy of 62.5%
Test data Score for fold 2: loss of 0.6872790455818176; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.43660488724708557; accuracy of 85.71428656578064%
Val Score for fold 2: loss of 0.8269270658493042; accuracy of 25.0%
Test data Score for fold 2: loss of 0.8462541103363037; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.5671233534812927; accuracy of 85.71428656578064%
Val Score for fold 2: loss of 0.7385601997375488; accuracy of 37.5%
Test data Score for fold 2: loss of 0.7339999079704285; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.3824131190776825; accuracy of 89.28571343421936%
Val Score for fold 2: loss of 1.059566617012024; accuracy of 12.5%
Test data Score for fold 2: loss of 0.7574639320373535; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.5709401369094849; accuracy of 82.14285969734192%
Val Score for fold 2: loss of 0.8222665786743164; accuracy of 50.0%
Test data Score for fold 2: loss of 0.7952601313591003; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.518172562122345; accuracy of 87.5%
Val Score for fold 2: loss of 0.7184032201766968; accuracy of 62.5%
Test data Score for fold 2: loss of 0.7706802487373352; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 3 ...
Train Score for fold 3: loss of 0.42730623483657837; accuracy of 92.85714030265808%
Val Score for fold 3: loss of 0.8709614276885986; accuracy of 37.5%
Test data Score for fold 3: loss of 0.7435660362243652; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 3 ...
Train Score for fold 3: loss of 0.2704724371433258; accuracy of 100.0%
Val Score for fold 3: loss of 0.5799652338027954; accuracy of 75.0%
Test data Score for fold 3: loss of 0.8079724311828613; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.489307165145874; accuracy of 83.92857313156128%
Val Score for fold 4: loss of 0.6394219994544983; accuracy of 75.0%
Test data Score for fold 4: loss of 0.7341663837432861; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.5519148111343384; accuracy of 87.5%
Val Score for fold 5: loss of 0.7511522173881531; accuracy of 37.5%
Test data Score for fold 5: loss of 0.6981039047241211; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.6605010628700256; accuracy of 55.35714030265808%
Val Score for fold 5: loss of 0.8079308867454529; accuracy of 25.0%
Test data Score for fold 5: loss of 0.6835151314735413; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.2761974632740021; accuracy of 98.21428656578064%
Val Score for fold 5: loss of 0.6049637794494629; accuracy of 62.5%
Test data Score for fold 5: loss of 0.8044059872627258; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.17367355525493622; accuracy of 98.21428656578064%
Val Score for fold 5: loss of 0.8684086799621582; accuracy of 37.5%
Test data Score for fold 5: loss of 0.9343697428703308; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.2397298365831375; accuracy of 98.21428656578064%
Val Score for fold 5: loss of 0.929162859916687; accuracy of 37.5%
Test data Score for fold 5: loss of 0.7101494073867798; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.2741621434688568; accuracy of 98.21428656578064%
Val Score for fold 5: loss of 0.845093846321106; accuracy of 37.5%
Test data Score for fold 5: loss of 0.6321392059326172; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.25608643889427185; accuracy of 94.64285969734192%
Val Score for fold 5: loss of 0.7737231254577637; accuracy of 37.5%
Test data Score for fold 5: loss of 0.7145697474479675; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.42522546648979187; accuracy of 83.92857313156128%
Val Score for fold 5: loss of 0.9226921200752258; accuracy of 25.0%
Test data Score for fold 5: loss of 0.837496280670166; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.6420689821243286; accuracy of 55.35714030265808%
Val Score for fold 5: loss of 0.823676586151123; accuracy of 25.0%
Test data Score for fold 5: loss of 0.696163535118103; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.2867526710033417; accuracy of 94.64285969734192%
Val Score for fold 5: loss of 0.9819618463516235; accuracy of 37.5%
Test data Score for fold 5: loss of 0.615638792514801; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.581277072429657; accuracy of 76.78571343421936%
Val Score for fold 5: loss of 0.6678395867347717; accuracy of 50.0%
Test data Score for fold 5: loss of 0.7371435761451721; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.34201309084892273; accuracy of 96.42857313156128%
Val Score for fold 6: loss of 0.5993279814720154; accuracy of 62.5%
Test data Score for fold 6: loss of 0.802495539188385; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6249426007270813; accuracy of 80.35714030265808%
Val Score for fold 7: loss of 0.6555240154266357; accuracy of 75.0%
Test data Score for fold 7: loss of 0.6930269002914429; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.692895233631134; accuracy of 51.78571343421936%
Val Score for fold 7: loss of 0.6931787729263306; accuracy of 50.0%
Test data Score for fold 7: loss of 0.6911934614181519; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.6414671540260315; accuracy of 62.5%
Val Score for fold 8: loss of 0.6730625033378601; accuracy of 75.0%
Test data Score for fold 8: loss of 0.729342520236969; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.2734525799751282; accuracy of 98.21428656578064%
Val Score for fold 8: loss of 0.6441981196403503; accuracy of 87.5%
Test data Score for fold 8: loss of 0.8743410110473633; accuracy of 50.0%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[39]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LX</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_printing</span><span class="p">[</span><span class="n">data_order</span><span class="p">,:,:,:]</span>
<span class="n">LY</span> <span class="o">=</span> <span class="n">y_class_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">]</span> 

<span class="n">printing_area_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;porosity_bin_model_printing_fold_no_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.h5&#39;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">LX</span><span class="p">)</span>
    <span class="c1"># LY = np.array([1 if a == 0 else 0 for a in Y])</span>
    <span class="n">pred_class</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class</span><span class="o">==</span><span class="n">LY</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct predictions in fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>  
    <span class="n">pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_printing</span><span class="p">)</span>
    <span class="n">pred_class_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred_test</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class_test</span><span class="o">==</span><span class="n">y_test_area_printing</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct Test data predictions for fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>
    <span class="n">printing_area_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_class_milling</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),</span> <span class="n">printing_area_acc</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Accuracy Per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span> <span class="n">printing_area_acc</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Average Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Printing Model Accuracy in Predicting %Area Porosity&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span><span class="n">labelpad</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>3/3 [==============================] - 0s 25ms/step
------------------------------------------------------------------------
Correct predictions in fold 1 ...
64
1/1 [==============================] - 0s 41ms/step
Correct Test data predictions for fold 1 ...
6
3/3 [==============================] - 0s 31ms/step
------------------------------------------------------------------------
Correct predictions in fold 2 ...
59
1/1 [==============================] - 0s 27ms/step
Correct Test data predictions for fold 2 ...
5
3/3 [==============================] - 0s 17ms/step
------------------------------------------------------------------------
Correct predictions in fold 3 ...
66
1/1 [==============================] - 0s 26ms/step
Correct Test data predictions for fold 3 ...
4
3/3 [==============================] - 0s 18ms/step
------------------------------------------------------------------------
Correct predictions in fold 4 ...
57
1/1 [==============================] - 0s 27ms/step
Correct Test data predictions for fold 4 ...
4
3/3 [==============================] - 0s 17ms/step
------------------------------------------------------------------------
Correct predictions in fold 5 ...
52
1/1 [==============================] - 0s 35ms/step
Correct Test data predictions for fold 5 ...
5
3/3 [==============================] - 0s 17ms/step
------------------------------------------------------------------------
Correct predictions in fold 6 ...
65
1/1 [==============================] - 0s 24ms/step
Correct Test data predictions for fold 6 ...
6
3/3 [==============================] - 0s 17ms/step
------------------------------------------------------------------------
Correct predictions in fold 7 ...
38
1/1 [==============================] - 0s 23ms/step
Correct Test data predictions for fold 7 ...
5
3/3 [==============================] - 0s 16ms/step
------------------------------------------------------------------------
Correct predictions in fold 8 ...
66
1/1 [==============================] - 0s 27ms/step
Correct Test data predictions for fold 8 ...
4
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="4.2.3.-Milling">4.2.3. Milling<a class="anchor-link" href="#4.2.3.-Milling">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[32]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">NUMPY_INPUT_DATA_milling</span> <span class="o">=</span> <span class="n">TENSOR_INPUT_DATA_MILLING</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">X_train_milling</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_milling</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">],:,:,:]</span>
<span class="n">y_train_area_milling</span> <span class="o">=</span> <span class="n">y_class_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]]</span>
<span class="n">X_test_milling</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_milling</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">],:,:,:]</span>
<span class="n">y_test_area_milling</span> <span class="o">=</span> <span class="n">y_class_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">[</span><span class="mi">64</span><span class="p">:</span><span class="mi">72</span><span class="p">]]</span>

<span class="c1"># Define the K-fold Cross Validator</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># K-fold Cross Validation model evaluation</span>
<span class="n">fold_no</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">train_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_acc_per_fold</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_loss_per_fold</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">kfold</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_train_milling</span><span class="p">,</span> <span class="n">y_train_area_milling</span><span class="p">):</span>
    
    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Define the model architecture</span>
    <span class="k">while</span><span class="p">(</span><span class="n">train_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">val_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">or</span> <span class="n">test_acc</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">15</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">))</span>
        <span class="c1">#model.add(MaxPooling2D((2, 2)))</span>
        <span class="c1"># model.add(Conv2D(128, (3, 3), activation=&#39;relu&#39;, kernel_initializer=&#39;he_uniform&#39;, padding=&#39;same&#39;))</span>
        <span class="c1"># model.add(MaxPooling2D((2, 2)))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    
        <span class="c1"># Compile the model</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
    
        <span class="c1"># Generate a print</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Training for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>

        <span class="c1"># Fit data to model</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_milling</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_area_milling</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1">#train_acc_per_fold.append(history.history[&#39;accuracy&#39;])</span>
        <span class="c1">#train_loss_per_fold.append(history.history[&#39;loss&#39;])</span>
        <span class="c1">#summarize_diagnostics(fold_no, history)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;porosity_bin_model_milling_fold_no_&#39;</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">fold_no</span><span class="p">)</span> <span class="o">+</span><span class="s1">&#39;.h5&#39;</span><span class="p">)</span>
    
        <span class="c1"># Generate generalization metrics</span>
        <span class="n">train_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_milling</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y_train_area_milling</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Train Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">val_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_milling</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">y_train_area_milling</span><span class="p">[</span><span class="n">val</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Val Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_milling</span><span class="p">,</span> <span class="n">y_test_area_milling</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test data Score for fold </span><span class="si">{</span><span class="n">fold_no</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">; </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1"> of </span><span class="si">{</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Increase fold number</span>
    <span class="n">fold_no</span> <span class="o">=</span> <span class="n">fold_no</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">train_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">val_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">test_acc_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">test_loss_per_fold</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6904529333114624; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7079496383666992; accuracy of 37.5%
Test data Score for fold 1: loss of 0.6805781722068787; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6414384841918945; accuracy of 78.57142686843872%
Val Score for fold 1: loss of 0.6210775971412659; accuracy of 87.5%
Test data Score for fold 1: loss of 0.7258933186531067; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.45664119720458984; accuracy of 82.14285969734192%
Val Score for fold 1: loss of 0.4588933289051056; accuracy of 87.5%
Test data Score for fold 1: loss of 0.8720085620880127; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6789451241493225; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7098104953765869; accuracy of 37.5%
Test data Score for fold 1: loss of 0.6949047446250916; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6896333694458008; accuracy of 53.57142686843872%
Val Score for fold 1: loss of 0.7126187086105347; accuracy of 37.5%
Test data Score for fold 1: loss of 0.6745729446411133; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 1 ...
Train Score for fold 1: loss of 0.6591517329216003; accuracy of 73.21428656578064%
Val Score for fold 1: loss of 0.6266354918479919; accuracy of 100.0%
Test data Score for fold 1: loss of 0.7037253379821777; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 2 ...
Train Score for fold 2: loss of 0.6478922963142395; accuracy of 62.5%
Val Score for fold 2: loss of 0.6088072061538696; accuracy of 75.0%
Test data Score for fold 2: loss of 0.7160946726799011; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 3 ...
Train Score for fold 3: loss of 0.6925125122070312; accuracy of 51.78571343421936%
Val Score for fold 3: loss of 0.7109785079956055; accuracy of 25.0%
Test data Score for fold 3: loss of 0.7022026777267456; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 3 ...
Train Score for fold 3: loss of 0.46335887908935547; accuracy of 75.0%
Val Score for fold 3: loss of 1.074594497680664; accuracy of 50.0%
Test data Score for fold 3: loss of 0.9264513850212097; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 4 ...
Train Score for fold 4: loss of 0.6819676756858826; accuracy of 60.71428656578064%
Val Score for fold 4: loss of 0.6826966404914856; accuracy of 50.0%
Test data Score for fold 4: loss of 0.6886678338050842; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 5 ...
Train Score for fold 5: loss of 0.687566339969635; accuracy of 60.71428656578064%
Val Score for fold 5: loss of 0.7020309567451477; accuracy of 50.0%
Test data Score for fold 5: loss of 0.6867308020591736; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.6169176697731018; accuracy of 92.85714030265808%
Val Score for fold 6: loss of 0.678524374961853; accuracy of 50.0%
Test data Score for fold 6: loss of 0.7054070830345154; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 6 ...
Train Score for fold 6: loss of 0.612544596195221; accuracy of 69.64285969734192%
Val Score for fold 6: loss of 0.674339771270752; accuracy of 75.0%
Test data Score for fold 6: loss of 0.7475438714027405; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6356680989265442; accuracy of 69.64285969734192%
Val Score for fold 7: loss of 0.758992612361908; accuracy of 37.5%
Test data Score for fold 7: loss of 0.726428747177124; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6036825180053711; accuracy of 62.5%
Val Score for fold 7: loss of 0.7877300977706909; accuracy of 37.5%
Test data Score for fold 7: loss of 0.7182773947715759; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6853713989257812; accuracy of 53.57142686843872%
Val Score for fold 7: loss of 0.7202908992767334; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6695985198020935; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5973615050315857; accuracy of 76.78571343421936%
Val Score for fold 7: loss of 0.7470191717147827; accuracy of 50.0%
Test data Score for fold 7: loss of 0.7835721373558044; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.611120343208313; accuracy of 57.14285969734192%
Val Score for fold 7: loss of 0.8126934766769409; accuracy of 50.0%
Test data Score for fold 7: loss of 0.8549216389656067; accuracy of 12.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6780043840408325; accuracy of 53.57142686843872%
Val Score for fold 7: loss of 0.7327873706817627; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6816304922103882; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6916865706443787; accuracy of 53.57142686843872%
Val Score for fold 7: loss of 0.6996350288391113; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6872707605361938; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.582060694694519; accuracy of 69.64285969734192%
Val Score for fold 7: loss of 0.8232721090316772; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6505962610244751; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5958488583564758; accuracy of 64.28571343421936%
Val Score for fold 7: loss of 0.7788218855857849; accuracy of 50.0%
Test data Score for fold 7: loss of 0.923830509185791; accuracy of 12.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6885042786598206; accuracy of 53.57142686843872%
Val Score for fold 7: loss of 0.7202337980270386; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6733317375183105; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5893881916999817; accuracy of 71.42857313156128%
Val Score for fold 7: loss of 0.7794511318206787; accuracy of 37.5%
Test data Score for fold 7: loss of 0.7336373329162598; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6850256323814392; accuracy of 53.57142686843872%
Val Score for fold 7: loss of 0.7061967849731445; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6705196499824524; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6915517449378967; accuracy of 53.57142686843872%
Val Score for fold 7: loss of 0.7004585266113281; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6866035461425781; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6266778707504272; accuracy of 67.85714030265808%
Val Score for fold 7: loss of 0.7343995571136475; accuracy of 25.0%
Test data Score for fold 7: loss of 0.675786018371582; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6559635400772095; accuracy of 66.07142686843872%
Val Score for fold 7: loss of 0.7447461485862732; accuracy of 25.0%
Test data Score for fold 7: loss of 0.7045490145683289; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6913989782333374; accuracy of 53.57142686843872%
Val Score for fold 7: loss of 0.7014776468276978; accuracy of 37.5%
Test data Score for fold 7: loss of 0.685799777507782; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.4951077997684479; accuracy of 76.78571343421936%
Val Score for fold 7: loss of 1.0049669742584229; accuracy of 25.0%
Test data Score for fold 7: loss of 0.8642417788505554; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6589986085891724; accuracy of 57.14285969734192%
Val Score for fold 7: loss of 0.7362009286880493; accuracy of 37.5%
Test data Score for fold 7: loss of 0.7119081020355225; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6270047426223755; accuracy of 71.42857313156128%
Val Score for fold 7: loss of 0.7576601505279541; accuracy of 37.5%
Test data Score for fold 7: loss of 0.7611038684844971; accuracy of 37.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5610519051551819; accuracy of 73.21428656578064%
Val Score for fold 7: loss of 0.8171308040618896; accuracy of 25.0%
Test data Score for fold 7: loss of 0.852671205997467; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6859182715415955; accuracy of 62.5%
Val Score for fold 7: loss of 0.7081766128540039; accuracy of 25.0%
Test data Score for fold 7: loss of 0.7034370303153992; accuracy of 25.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.6904760003089905; accuracy of 53.57142686843872%
Val Score for fold 7: loss of 0.7161990404129028; accuracy of 37.5%
Test data Score for fold 7: loss of 0.6781686544418335; accuracy of 62.5%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5528138875961304; accuracy of 73.21428656578064%
Val Score for fold 7: loss of 0.8796236515045166; accuracy of 25.0%
Test data Score for fold 7: loss of 0.8044255375862122; accuracy of 50.0%
------------------------------------------------------------------------
Training for fold 7 ...
Train Score for fold 7: loss of 0.5070955157279968; accuracy of 75.0%
Val Score for fold 7: loss of 0.8149232864379883; accuracy of 50.0%
Test data Score for fold 7: loss of 0.8573018312454224; accuracy of 75.0%
------------------------------------------------------------------------
Training for fold 8 ...
Train Score for fold 8: loss of 0.6062982678413391; accuracy of 69.64285969734192%
Val Score for fold 8: loss of 0.6861846446990967; accuracy of 50.0%
Test data Score for fold 8: loss of 0.7499884366989136; accuracy of 50.0%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[40]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LX</span> <span class="o">=</span> <span class="n">NUMPY_INPUT_DATA_milling</span><span class="p">[</span><span class="n">data_order</span><span class="p">,:,:,:]</span>
<span class="n">LY</span> <span class="o">=</span> <span class="n">y_class_area</span><span class="p">[</span><span class="n">data_order</span><span class="p">]</span> 

<span class="n">milling_area_acc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">):</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;porosity_bin_model_milling_fold_no_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.h5&#39;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">LX</span><span class="p">)</span>
    <span class="c1"># LY = np.array([1 if a == 0 else 0 for a in Y])</span>
    <span class="n">pred_class</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class</span><span class="o">==</span><span class="n">LY</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------------------------------------------------------------------------&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct predictions in fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>  
    <span class="n">pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_milling</span><span class="p">)</span>
    <span class="n">pred_class_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">pred_test</span><span class="p">]</span>
    <span class="n">correct_X_ind</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">pred_class_test</span><span class="o">==</span><span class="n">y_test_area_milling</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Correct Test data predictions for fold </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> ...&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">))</span>
    <span class="n">milling_area_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">correct_X_ind</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_class_milling</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),</span> <span class="n">milling_area_acc</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Accuracy Per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)),[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span> <span class="n">milling_area_acc</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">)],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Average Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Milling Model Accuracy in Predicting %Area Porosity&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span><span class="n">labelpad</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>3/3 [==============================] - 0s 12ms/step
------------------------------------------------------------------------
Correct predictions in fold 1 ...
53
1/1 [==============================] - 0s 25ms/step
Correct Test data predictions for fold 1 ...
4
3/3 [==============================] - 0s 10ms/step
------------------------------------------------------------------------
Correct predictions in fold 2 ...
45
1/1 [==============================] - 0s 25ms/step
Correct Test data predictions for fold 2 ...
4
3/3 [==============================] - 0s 12ms/step
------------------------------------------------------------------------
Correct predictions in fold 3 ...
50
1/1 [==============================] - 0s 22ms/step
Correct Test data predictions for fold 3 ...
4
3/3 [==============================] - 0s 10ms/step
------------------------------------------------------------------------
Correct predictions in fold 4 ...
43
1/1 [==============================] - 0s 23ms/step
Correct Test data predictions for fold 4 ...
5
3/3 [==============================] - 0s 10ms/step
------------------------------------------------------------------------
Correct predictions in fold 5 ...
43
1/1 [==============================] - 0s 21ms/step
Correct Test data predictions for fold 5 ...
5
3/3 [==============================] - 0s 13ms/step
------------------------------------------------------------------------
Correct predictions in fold 6 ...
50
1/1 [==============================] - 0s 20ms/step
Correct Test data predictions for fold 6 ...
5
3/3 [==============================] - 0s 10ms/step
------------------------------------------------------------------------
Correct predictions in fold 7 ...
52
1/1 [==============================] - 0s 21ms/step
Correct Test data predictions for fold 7 ...
6
3/3 [==============================] - 0s 15ms/step
------------------------------------------------------------------------
Correct predictions in fold 8 ...
47
1/1 [==============================] - 0s 21ms/step
Correct Test data predictions for fold 8 ...
4
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[60]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install nbconvert
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (5.6.1)
Requirement already satisfied: jinja2&gt;=2.4 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (2.11.3)
Requirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (1.5.0)
Requirement already satisfied: nbformat&gt;=4.4 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (5.7.0)
Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert) (5.0.1)
Requirement already satisfied: traitlets&gt;=4.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (5.6.0)
Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert) (2.6.1)
Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert) (0.6.0)
Requirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (0.8.4)
Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbconvert) (5.1.0)
Requirement already satisfied: entrypoints&gt;=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (0.4)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert) (0.7.1)
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2&gt;=2.4-&gt;nbconvert) (2.0.1)
Requirement already satisfied: jsonschema&gt;=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat&gt;=4.4-&gt;nbconvert) (4.3.3)
Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat&gt;=4.4-&gt;nbconvert) (2.16.2)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=4.4-&gt;nbconvert) (22.1.0)
Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=4.4-&gt;nbconvert) (0.19.2)
Requirement already satisfied: importlib-resources&gt;=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=4.4-&gt;nbconvert) (5.10.0)
Requirement already satisfied: zipp&gt;=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources&gt;=1.4.0-&gt;jsonschema&gt;=2.6-&gt;nbformat&gt;=4.4-&gt;nbconvert) (3.11.0)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.8/dist-packages (from bleach-&gt;nbconvert) (1.15.0)
Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach-&gt;nbconvert) (0.5.1)
Requirement already satisfied: platformdirs&gt;=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core-&gt;nbconvert) (2.5.4)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[62]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">shell</span> 
jupyter nbconvert --to HTML /content/ISEN613_Project_Notebook.ipynb
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[NbConvertApp] Converting notebook /content/ISEN613_Project_Notebook.ipynb to HTML
[NbConvertApp] Writing 917688 bytes to /content/ISEN613_Project_Notebook.html
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[62]:</div>




<div class="output_text output_subarea output_execute_result">
<pre></pre>
</div>

</div>

</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
